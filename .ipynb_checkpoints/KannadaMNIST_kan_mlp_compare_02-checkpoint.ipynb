{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d4d150-96b6-4a63-8bc9-9b20b62ab163",
   "metadata": {},
   "source": [
    "# Comparing MLP vs. KAN on Classification problem with a bit more input dimensions (Kannada MNIST)\n",
    "\n",
    "Original KAN example: https://github.com/KindXiaoming/pykan/blob/master/tutorials/Example_3_classfication.ipynb \\\n",
    "EfficientKAN by Blealtan: https://github.com/Blealtan/efficient-kan \\\n",
    "MLP in pytorch Referenced from: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html \\\n",
    "ConvolutionalKAN by AntonioTepsich: https://github.com/AntonioTepsich/Convolutional-KANs\n",
    "\n",
    "Test with Kannada MNIST dataset: https://github.com/vinayprabhu/Kannada_MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b0f2c9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ac3b61-ace6-422d-9457-05e00b3d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'efficient-kan-master', 'src')))\n",
    "\n",
    "from efficient_kan import KAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bd87f3-a8ec-48a9-9360-79d1a6100659",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'Convolutional-KANs-master')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'Convolutional-KANs-master', 'kan_convolutional')))\n",
    "\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional.KANLinear import KANLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c591dd6",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has CUDA: True\n",
      "device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print('Has CUDA:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('device name:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d67376",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e022d-b2df-4188-8788-dd3d86aca214",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999e35ca-fa49-4913-a381-769fa92a82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), 'Kannada_MNIST-master')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c775ef69-5284-4819-b75e-7ca6fb230c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load with numpy.load\n",
    "x_tr = np.load(join('Kannada_MNIST', 'data', 'output_tensors', 'MNIST_format', 'X_kannada_MNIST_train.npy'))\n",
    "y_tr = np.load(join('Kannada_MNIST', 'data', 'output_tensors', 'MNIST_format', 'y_kannada_MNIST_train.npy'))\n",
    "x_te = np.load(join('Kannada_MNIST', 'data', 'output_tensors', 'MNIST_format', 'X_kannada_MNIST_test.npy'))\n",
    "y_te = np.load(join('Kannada_MNIST', 'data', 'output_tensors', 'MNIST_format', 'y_kannada_MNIST_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873af6e1-6c1e-4e9f-b0d9-c3ffcc9c713b",
   "metadata": {},
   "source": [
    "##### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e1d798-d19d-491d-ab66-1623bcfd7353",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# normalie the dataset values to [0.0, 1.0]\n",
    "vmax = np.amax(x_tr)\n",
    "x_tr = x_tr / vmax\n",
    "x_te = x_te / vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f3ac74-f774-4aa0-9566-eeb2f0b5dc94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1709bf4-602a-4b6d-bf82-c862b1d4e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "x_tr_flattened = x_tr.reshape((x_tr.shape[0], x_tr.shape[1] * x_tr.shape[2]))\n",
    "x_te_flattened = x_te.reshape((x_te.shape[0], x_te.shape[1] * x_te.shape[2]))\n",
    "\n",
    "# conv color channel\n",
    "x_tr_channeled = x_tr.reshape((x_tr.shape[0], 1, x_tr.shape[1], x_tr.shape[2]))\n",
    "x_te_channeled = x_te.reshape((x_te.shape[0], 1, x_te.shape[1], x_te.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7fab300",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x_train_flattened = torch.tensor(np.array(x_tr_flattened))\n",
    "x_train_channeled = torch.tensor(np.array(x_tr_channeled))\n",
    "y_train = torch.tensor(np.array(y_tr))\n",
    "\n",
    "x_test_flattened  = torch.tensor(np.array(x_te_flattened))\n",
    "x_test_channeled  = torch.tensor(np.array(x_te_channeled))\n",
    "y_test  = torch.tensor(np.array(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2187dba",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ba19f4-a864-42bf-8ede-fa7411670255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_channeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3bb877b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# chop off a ratio of the train sets\n",
    "ratio_keep = 1.0\n",
    "\n",
    "num_train = x_tr.shape[0]\n",
    "num_test = x_te.shape[0]\n",
    "\n",
    "num_train_1 = int(num_train * ratio_keep)\n",
    "num_test_1  = int(num_test * ratio_keep)\n",
    "\n",
    "x_train_flattened = x_train_flattened[:num_train_1, :]\n",
    "x_train_channeled = x_train_channeled[:num_train_1, :]\n",
    "y_train = y_train[:num_train_1]\n",
    "\n",
    "x_test_flattened = x_test_flattened[:num_test_1, :]\n",
    "x_test_channeled = x_test_channeled[:num_test_1, :]\n",
    "y_test = y_test[:num_test_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4c83e-02d4-4ca2-bbe2-568336431765",
   "metadata": {},
   "source": [
    "##### Create a troch dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08d7590",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ec54e2-5797-4143-abbd-2f34d952bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716ef2e8-fb82-47e7-9583-89e2c1cd85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattened for fully connected\n",
    "train_set_flattened = TensorDataset(x_train_flattened.to(dtype=torch.float32), y_train)\n",
    "train_loader_flattened = DataLoader(train_set_flattened, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set_flattened = TensorDataset(x_test_flattened.to(dtype=torch.float32), y_test)\n",
    "test_loader_flattened = DataLoader(test_set_flattened, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# channeled for convolution\n",
    "train_set_channeled = TensorDataset(x_train_channeled.to(dtype=torch.float32), y_train)\n",
    "train_loader_channeled = DataLoader(train_set_channeled, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set_channeled = TensorDataset(x_test_channeled.to(dtype=torch.float32), y_test)\n",
    "test_loader_channeled = DataLoader(test_set_channeled, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c17bf8-aa2a-4242-bd05-9e8caa2a208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_flattened = {'train': train_loader_flattened, 'test': test_loader_flattened}\n",
    "dataset_channeled = {'train': train_loader_channeled, 'test': test_loader_channeled}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd564596-965f-4afc-bacd-94254e986b47",
   "metadata": {},
   "source": [
    "### Code for classical MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "759b8ae1-4e75-4392-b4ca-a85d5738ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    '''\n",
    "    width is the dimension of each layer, like [784, 20, 20, 10]\n",
    "    '''\n",
    "    def __init__(self, width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        stack = []\n",
    "        l = len(width)\n",
    "        for i in range(l-2):\n",
    "            stack.append(nn.Linear(width[i], width[i+1]))\n",
    "            stack.append(nn.ReLU())\n",
    "        stack.append(nn.Linear(width[l-2], width[l-1]))\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(*stack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc38fb-1f39-4a03-9bca-38810ba322f9",
   "metadata": {},
   "source": [
    "### Code for ConvolutionKAN\n",
    "copied from: https://github.com/AntonioTepsich/Convolutional-KANs/tree/master/architectures_28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcc651b5-57c9-4620-963e-1b70e38e7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvKAN_2conv(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(625, 64)\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c530bf6-ee8a-4d4f-9d87-bf1f9889beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvKAN_1conv(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(845, 64)\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d297c27-9173-4576-af6f-e06509c6484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KKAN_Convolutional_Network(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            625,\n",
    "            10,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0,1],\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.kan1(x) \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ac46581-3a8e-4d97-8b3a-df18e3e6dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "convkan_types_map = {0: ConvKAN_1conv, 1: ConvKAN_2conv, 2: KKAN_Convolutional_Network}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff23c7",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc24218-af0c-4f6b-b24c-4d88bc7949e9",
   "metadata": {},
   "source": [
    "##### utility funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2666675",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# see total number of params\n",
    "def get_num_params(model):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    pytorch_total_params_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    return pytorch_total_params, pytorch_total_params_trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d0906-8543-4b2f-a86d-cdc12c679d00",
   "metadata": {},
   "source": [
    "##### New util codes\n",
    "copied from: https://github.com/AntonioTepsich/Convolutional-KANs/blob/master/experiment_28x28.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e59fd1b-c13c-4215-9a10-746f893fb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_loader(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: the optimizer to use (e.g. SGD)\n",
    "        epoch: the current epoch\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: the average loss over the training set\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        # Get the loss\n",
    "        loss = criterion(output, target)\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    # print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "def test_batch_loader(model, device, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        test_loss: the average loss over the test set\n",
    "        accuracy: the accuracy of the model on the test set\n",
    "        precision: the precision of the model on the test set\n",
    "        recall: the recall of the model on the test set\n",
    "        f1: the f1 score of the model on the test set\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (target == predicted).sum().item()\n",
    "\n",
    "            # Collect all targets and predictions for metric calculations\n",
    "            all_targets.extend(target.view_as(predicted).cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Normalize test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Precision: {:.2f}, Recall: {:.2f}, F1 Score: {:.2f}\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset), accuracy, precision, recall, f1))\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5c3f5d-99b7-4c43-87d7-c77a8dd16ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(model, num_epochs, loss_fn, train_loader, test_loader, optimizer, scheduler=None):\n",
    "    res = {'train_loss': [], 'test_loss': [], 'test_acc': []}\n",
    "    for n in tqdm(range(num_epochs)):\n",
    "        train_loss = train_batch_loader(model, 'cuda', train_loader, optimizer, n, loss_fn)\n",
    "        # test_loss, test_acc, precision, recall, f1 = test_batch_loader(model, 'cuda', test_loader, loss_fn)\n",
    "        test_loss, test_acc = test_batch_loader(model, 'cuda', test_loader, loss_fn)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        res['train_loss'].append(train_loss)\n",
    "        res['test_loss'].append(test_loss)\n",
    "        res['test_acc'].append(test_acc)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce08650-5506-4aa4-bd63-c5c1e8f250b3",
   "metadata": {},
   "source": [
    "##### Create different types of models and train them\n",
    "We want to use the same optimization method, batch size, etc. to compare the different architectures fairly \\\n",
    "This might cause slower training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0685fc62-a62d-4549-a698-0dc3785dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create, train, then discard a model\n",
    "our objective is to figure out the efficacy of different shaped models\n",
    "'''\n",
    "def create_and_train(model_type, width, epochs, lr, batch_size=-1):\n",
    "    dset = dataset_flattened\n",
    "    \n",
    "    # create model\n",
    "    if model_type == 'mlp':\n",
    "        model = NeuralNetwork(width).to(device='cuda')\n",
    "    elif model_type == 'kan':\n",
    "        model = KAN(width, grid_size=3, spline_order=3).to(device='cuda')\n",
    "    elif model_type == 'convkan':\n",
    "        # TODO: change to use width\n",
    "        model = convkan_types_map[width]().to(device='cuda')\n",
    "        dset = dataset_channeled\n",
    "\n",
    "    # record num of params\n",
    "    num_params = get_num_params(model)\n",
    "    \n",
    "    # use categorical cross entropy loss\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    # learning rate and adam optimizer\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "    \n",
    "    # train as any vanilla pytorch model\n",
    "    start = time.time()\n",
    "    # results = train(model, epochs, loss_fn, dset, optimizer, batch_size=batch_size)\n",
    "    results = train_process(model, epochs, loss_fn, dset['train'], dset['test'], optimizer, scheduler=scheduler)\n",
    "    end = time.time()\n",
    "\n",
    "    # free the memory\n",
    "    model.cpu()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return {'model_type': model_type, 'width': width, 'num_params': num_params, 'train_result': results, 'train_time': (end - start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58594fae-d5eb-489b-821c-d861fb808836",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_shapes = [\n",
    "    [784, 10],\n",
    "    [784, 16, 10],\n",
    "    [784, 32, 10],\n",
    "    [784, 64, 10],\n",
    "    [784, 128, 10],\n",
    "    [784, 32, 32, 10],\n",
    "    [784, 64, 64, 10],\n",
    "]\n",
    "\n",
    "mlp_shapes = [\n",
    "    [784, 10],\n",
    "    [784, 16, 10],\n",
    "    [784, 32, 10],\n",
    "    [784, 64, 10],\n",
    "    [784, 128, 10],\n",
    "    [784, 256, 10],\n",
    "    [784, 32, 32, 10],\n",
    "    [784, 64, 64, 10],\n",
    "    [784, 128, 128, 10],\n",
    "    [784, 256, 256, 10],\n",
    "    [784, 512, 512, 10],\n",
    "]\n",
    "\n",
    "convkan_types = convkan_types_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "197de4ce-917d-4412-9921-7c70862572bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e723c67-ece7-4b31-bf02-4595d95cd170",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_ct = 40\n",
    "# epoch_ct = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee5be8f-7a97-480a-883e-23d92f65ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KAN shape: [784, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:58<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 58.399250507354736\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 16, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:09<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 69.96771931648254\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:09<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 69.33463788032532\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 65.70935487747192\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:04<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 64.86924600601196\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 32, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:21<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 81.87582612037659\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 64, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:19<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 79.96453857421875\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [09:58<00:00, 14.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 598.2149972915649\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [33:28<00:00, 50.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2008.9209742546082\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [34:22<00:00, 51.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2062.9953923225403\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:39<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 39.45659852027893\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 16, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:42<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 42.2247314453125\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.14489960670471\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.24175143241882\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.4507577419281\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 256, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.82247447967529\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 32, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.46668863296509\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 64, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:46<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 46.02969002723694\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 128, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 42.96457600593567\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 256, 256, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:46<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 46.5630042552948\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 512, 512, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.53667688369751\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for shape in kan_shapes:\n",
    "    print('Training KAN shape:', shape)\n",
    "    res = create_and_train('kan', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)\n",
    "\n",
    "for shape in convkan_types:\n",
    "    print('Training ConvKAN type:', shape)\n",
    "    res = create_and_train('convkan', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)\n",
    "\n",
    "for shape in mlp_shapes:\n",
    "    print('Training MLP shape:', shape)\n",
    "    res = create_and_train('mlp', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbcd1cc8-4d9b-441d-bc29-047761851f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'kan',\n",
       "  'width': [784, 10],\n",
       "  'num_params': (62720, 62720),\n",
       "  'train_result': {'train_loss': [0.7980083282957686,\n",
       "    0.24328900036659645,\n",
       "    0.1835830196421197,\n",
       "    0.16016169437702665,\n",
       "    0.14833411101965194,\n",
       "    0.14055227294881292,\n",
       "    0.13537070456337422,\n",
       "    0.13159505664668183,\n",
       "    0.1287590429820913,\n",
       "    0.12735162137987766,\n",
       "    0.12527445424744424,\n",
       "    0.12389721217307638,\n",
       "    0.1228071153639479,\n",
       "    0.12220719266445079,\n",
       "    0.12186507623880467,\n",
       "    0.1210720198110063,\n",
       "    0.12072227024968635,\n",
       "    0.12032043209418337,\n",
       "    0.12005500008768223,\n",
       "    0.12001411410722326,\n",
       "    0.11962780140815897,\n",
       "    0.11981961354613305,\n",
       "    0.1193346325228823,\n",
       "    0.11970881466218766,\n",
       "    0.11957866481326997,\n",
       "    0.11945026879932018,\n",
       "    0.11926764649279574,\n",
       "    0.11923031933764194,\n",
       "    0.11947257062222096,\n",
       "    0.11918197581742672,\n",
       "    0.11911670589383612,\n",
       "    0.11910820761893658,\n",
       "    0.11924815292054035,\n",
       "    0.11898542396882747,\n",
       "    0.1192425345962352,\n",
       "    0.11930765617401042,\n",
       "    0.11896159024314677,\n",
       "    0.119073837298028,\n",
       "    0.1192033181165127,\n",
       "    0.11912382895008046],\n",
       "   'test_loss': [0.0022359005481004716,\n",
       "    0.001720203447341919,\n",
       "    0.0015629444330930709,\n",
       "    0.0014771738916635514,\n",
       "    0.0014363969817757607,\n",
       "    0.0014177529767155648,\n",
       "    0.0013968433499336242,\n",
       "    0.0013725511506199836,\n",
       "    0.0013584312617778778,\n",
       "    0.0013598963722586631,\n",
       "    0.0013492833197116852,\n",
       "    0.001336566613614559,\n",
       "    0.0013417850270867348,\n",
       "    0.0013379943624138833,\n",
       "    0.0013341191321611405,\n",
       "    0.0013310258895158768,\n",
       "    0.0013309683009982108,\n",
       "    0.001329267656803131,\n",
       "    0.0013286279067397117,\n",
       "    0.0013271736070513726,\n",
       "    0.0013271144479513168,\n",
       "    0.0013262887075543403,\n",
       "    0.0013262393549084664,\n",
       "    0.0013253421559929848,\n",
       "    0.0013252486512064935,\n",
       "    0.0013249838426709175,\n",
       "    0.0013248957708477975,\n",
       "    0.00132477096170187,\n",
       "    0.0013247061938047408,\n",
       "    0.0013247072562575341,\n",
       "    0.0013245347157120704,\n",
       "    0.0013245066478848456,\n",
       "    0.0013244894921779632,\n",
       "    0.001324442994594574,\n",
       "    0.0013244171872735023,\n",
       "    0.0013244041383266448,\n",
       "    0.0013243811681866646,\n",
       "    0.0013243733614683151,\n",
       "    0.0013243587344884873,\n",
       "    0.001324348770081997],\n",
       "   'test_acc': [0.8496,\n",
       "    0.8752,\n",
       "    0.8835,\n",
       "    0.8878,\n",
       "    0.8904,\n",
       "    0.891,\n",
       "    0.8934,\n",
       "    0.8941,\n",
       "    0.8953,\n",
       "    0.8953,\n",
       "    0.896,\n",
       "    0.8971,\n",
       "    0.8974,\n",
       "    0.8965,\n",
       "    0.8974,\n",
       "    0.8973,\n",
       "    0.8973,\n",
       "    0.8975,\n",
       "    0.8976,\n",
       "    0.8976,\n",
       "    0.8978,\n",
       "    0.8978,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8978,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.898,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979,\n",
       "    0.8979]},\n",
       "  'train_time': 58.399250507354736},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 16, 10],\n",
       "  'num_params': (101632, 101632),\n",
       "  'train_result': {'train_loss': [0.7910715161485875,\n",
       "    0.19230231278120202,\n",
       "    0.14933829418522246,\n",
       "    0.1311249866764596,\n",
       "    0.12088750670564935,\n",
       "    0.11402257330557133,\n",
       "    0.10961089752455976,\n",
       "    0.10684413141075601,\n",
       "    0.10389490880547686,\n",
       "    0.10200672639494246,\n",
       "    0.10046653845842848,\n",
       "    0.09901602028849277,\n",
       "    0.09818594628509054,\n",
       "    0.09730457749138487,\n",
       "    0.09680078517883382,\n",
       "    0.09636975797884008,\n",
       "    0.09594162929248302,\n",
       "    0.09590831448106056,\n",
       "    0.09536330565176111,\n",
       "    0.09568525351425435,\n",
       "    0.0950958751617594,\n",
       "    0.09525207560113136,\n",
       "    0.09487017234589191,\n",
       "    0.09475389844242563,\n",
       "    0.09483884980386877,\n",
       "    0.09468087696648658,\n",
       "    0.09477923105054713,\n",
       "    0.09456143892825918,\n",
       "    0.09453105691899645,\n",
       "    0.09461228459122333,\n",
       "    0.09446737228872928,\n",
       "    0.09443201909356928,\n",
       "    0.09435793561662766,\n",
       "    0.09448574995423885,\n",
       "    0.09457190168347765,\n",
       "    0.0944568913826283,\n",
       "    0.09437541857044747,\n",
       "    0.0943746270810036,\n",
       "    0.0943416853930722,\n",
       "    0.09472959491800755],\n",
       "   'test_loss': [0.0019177024468779564,\n",
       "    0.0015624685406684876,\n",
       "    0.0014104311302304269,\n",
       "    0.0013295787304639817,\n",
       "    0.0013080929845571518,\n",
       "    0.001275037582218647,\n",
       "    0.001275524216890335,\n",
       "    0.0012597722098231315,\n",
       "    0.0012560305148363114,\n",
       "    0.001252068457007408,\n",
       "    0.0012554653465747833,\n",
       "    0.0012432116761803627,\n",
       "    0.0012313178598880768,\n",
       "    0.0012397355496883392,\n",
       "    0.0012449325308203697,\n",
       "    0.0012434806391596793,\n",
       "    0.001243765850365162,\n",
       "    0.0012363416492938996,\n",
       "    0.0012386883035302163,\n",
       "    0.0012369680523872375,\n",
       "    0.0012362331598997115,\n",
       "    0.0012368432268500327,\n",
       "    0.0012357927933335305,\n",
       "    0.0012350971579551697,\n",
       "    0.0012351708129048347,\n",
       "    0.0012346962362527847,\n",
       "    0.0012349421054124832,\n",
       "    0.0012349961504340172,\n",
       "    0.0012350008711218834,\n",
       "    0.0012348918452858924,\n",
       "    0.001235011376440525,\n",
       "    0.001234908264875412,\n",
       "    0.0012349974036216737,\n",
       "    0.0012349499091506004,\n",
       "    0.001234906329214573,\n",
       "    0.0012349327519536018,\n",
       "    0.0012349052995443343,\n",
       "    0.0012349065914750098,\n",
       "    0.0012348769426345826,\n",
       "    0.0012348770156502724],\n",
       "   'test_acc': [0.86,\n",
       "    0.8754,\n",
       "    0.8922,\n",
       "    0.8948,\n",
       "    0.8975,\n",
       "    0.9006,\n",
       "    0.9005,\n",
       "    0.9024,\n",
       "    0.9026,\n",
       "    0.9016,\n",
       "    0.9006,\n",
       "    0.9035,\n",
       "    0.9034,\n",
       "    0.9032,\n",
       "    0.9024,\n",
       "    0.9024,\n",
       "    0.9021,\n",
       "    0.9034,\n",
       "    0.903,\n",
       "    0.903,\n",
       "    0.9034,\n",
       "    0.9032,\n",
       "    0.9034,\n",
       "    0.9036,\n",
       "    0.9036,\n",
       "    0.9038,\n",
       "    0.9035,\n",
       "    0.9037,\n",
       "    0.9037,\n",
       "    0.9036,\n",
       "    0.9036,\n",
       "    0.9036,\n",
       "    0.9036,\n",
       "    0.9036,\n",
       "    0.9037,\n",
       "    0.9037,\n",
       "    0.9037,\n",
       "    0.9036,\n",
       "    0.9037,\n",
       "    0.9037]},\n",
       "  'train_time': 69.96771931648254},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 32, 10],\n",
       "  'num_params': (203264, 203264),\n",
       "  'train_result': {'train_loss': [0.6142573954894187,\n",
       "    0.1573827913783966,\n",
       "    0.1274587148364554,\n",
       "    0.11308805541472232,\n",
       "    0.10412152469792264,\n",
       "    0.09730898997885115,\n",
       "    0.0925147552122461,\n",
       "    0.08895601221221558,\n",
       "    0.08634813816306439,\n",
       "    0.08432691572828496,\n",
       "    0.08264099577481443,\n",
       "    0.08119366123004162,\n",
       "    0.0801525447279849,\n",
       "    0.07937752030631329,\n",
       "    0.07875425289285944,\n",
       "    0.07832882986899387,\n",
       "    0.07791434234761177,\n",
       "    0.07749046990053451,\n",
       "    0.0773579291523771,\n",
       "    0.0770333438715402,\n",
       "    0.07721931412816048,\n",
       "    0.07686434276401996,\n",
       "    0.07671229619770609,\n",
       "    0.07665909604030721,\n",
       "    0.07660566420948252,\n",
       "    0.07635484931475305,\n",
       "    0.07650602643001587,\n",
       "    0.07648383304476739,\n",
       "    0.07683480688707625,\n",
       "    0.07624591867974465,\n",
       "    0.07624104413738911,\n",
       "    0.0763835885898864,\n",
       "    0.07616777678436422,\n",
       "    0.07643723024174254,\n",
       "    0.07614169137433488,\n",
       "    0.07652381904264714,\n",
       "    0.07618676335253614,\n",
       "    0.07620417093659969,\n",
       "    0.07612835227492008,\n",
       "    0.07623803420586789],\n",
       "   'test_loss': [0.001664681613445282,\n",
       "    0.0014275956615805625,\n",
       "    0.001334730938076973,\n",
       "    0.0012788254395127297,\n",
       "    0.0012414228260517121,\n",
       "    0.0012106205388903617,\n",
       "    0.0011784296423196794,\n",
       "    0.0011934018976986409,\n",
       "    0.0011823436163365842,\n",
       "    0.0011613217175006866,\n",
       "    0.0011706506803631782,\n",
       "    0.001162449299544096,\n",
       "    0.001160439395159483,\n",
       "    0.0011639154873788356,\n",
       "    0.0011530347503721713,\n",
       "    0.0011505377039313317,\n",
       "    0.0011480673015117646,\n",
       "    0.0011489661507308483,\n",
       "    0.0011476609945297242,\n",
       "    0.0011427750647068024,\n",
       "    0.0011472445838153363,\n",
       "    0.0011455337010324001,\n",
       "    0.0011469288945198059,\n",
       "    0.0011469510942697526,\n",
       "    0.0011463361866772175,\n",
       "    0.001145855387300253,\n",
       "    0.0011460478223860263,\n",
       "    0.0011455879606306553,\n",
       "    0.0011457774005830287,\n",
       "    0.0011455846339464189,\n",
       "    0.0011457379214465618,\n",
       "    0.0011457784064114094,\n",
       "    0.001145723056793213,\n",
       "    0.001145660847425461,\n",
       "    0.001145536906272173,\n",
       "    0.0011455727569758892,\n",
       "    0.001145564514398575,\n",
       "    0.00114555494338274,\n",
       "    0.0011455766029655934,\n",
       "    0.0011455539748072624],\n",
       "   'test_acc': [0.8747,\n",
       "    0.8923,\n",
       "    0.8985,\n",
       "    0.9008,\n",
       "    0.9047,\n",
       "    0.9063,\n",
       "    0.9103,\n",
       "    0.9097,\n",
       "    0.9092,\n",
       "    0.9121,\n",
       "    0.9109,\n",
       "    0.9124,\n",
       "    0.9117,\n",
       "    0.9119,\n",
       "    0.9129,\n",
       "    0.9129,\n",
       "    0.9125,\n",
       "    0.9126,\n",
       "    0.9127,\n",
       "    0.9129,\n",
       "    0.913,\n",
       "    0.9129,\n",
       "    0.9125,\n",
       "    0.9125,\n",
       "    0.9126,\n",
       "    0.9125,\n",
       "    0.9125,\n",
       "    0.9127,\n",
       "    0.9127,\n",
       "    0.9127,\n",
       "    0.9126,\n",
       "    0.9125,\n",
       "    0.9128,\n",
       "    0.9128,\n",
       "    0.9128,\n",
       "    0.9128,\n",
       "    0.9128,\n",
       "    0.9128,\n",
       "    0.9128,\n",
       "    0.9128]},\n",
       "  'train_time': 69.33463788032532},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 64, 10],\n",
       "  'num_params': (406528, 406528),\n",
       "  'train_result': {'train_loss': [0.5031945567815862,\n",
       "    0.13915519917264899,\n",
       "    0.11510497460022885,\n",
       "    0.10306717626591946,\n",
       "    0.09493061372257293,\n",
       "    0.08857347795620878,\n",
       "    0.08354735574189653,\n",
       "    0.08022405749305765,\n",
       "    0.07737403099048645,\n",
       "    0.07535145243114613,\n",
       "    0.07345467335049143,\n",
       "    0.07204641790941675,\n",
       "    0.0709937592453145,\n",
       "    0.07018991053262924,\n",
       "    0.06951032496513204,\n",
       "    0.0689053715067975,\n",
       "    0.06851531094376077,\n",
       "    0.06816399976452614,\n",
       "    0.06782700348883233,\n",
       "    0.06761935129761695,\n",
       "    0.06737632579467398,\n",
       "    0.06727725826996438,\n",
       "    0.06727561089111135,\n",
       "    0.06724421301896268,\n",
       "    0.06717709505019036,\n",
       "    0.06693231271619493,\n",
       "    0.06692830759318585,\n",
       "    0.06702797186977051,\n",
       "    0.06689638530320309,\n",
       "    0.06690572336950201,\n",
       "    0.06673044212003972,\n",
       "    0.06684336098743246,\n",
       "    0.06679169353335462,\n",
       "    0.0667098952576201,\n",
       "    0.0666622735282525,\n",
       "    0.06685611370237583,\n",
       "    0.06684534723295811,\n",
       "    0.06680420727488842,\n",
       "    0.06684010687502141,\n",
       "    0.06665561228514987],\n",
       "   'test_loss': [0.0015194895133376122,\n",
       "    0.0013230647638440133,\n",
       "    0.0012743983879685403,\n",
       "    0.0012894684746861459,\n",
       "    0.0012468802504241466,\n",
       "    0.0012206449538469315,\n",
       "    0.0011776310555636884,\n",
       "    0.001172633070498705,\n",
       "    0.0011909755393862723,\n",
       "    0.001172523330897093,\n",
       "    0.0011758520618081092,\n",
       "    0.0011458885714411735,\n",
       "    0.001144426379352808,\n",
       "    0.0011566632613539695,\n",
       "    0.0011556742548942565,\n",
       "    0.0011615809552371502,\n",
       "    0.0011487019948661326,\n",
       "    0.001150998142361641,\n",
       "    0.0011427894353866577,\n",
       "    0.0011491735674440862,\n",
       "    0.0011457750126719474,\n",
       "    0.0011448587529361248,\n",
       "    0.0011463964991271496,\n",
       "    0.0011460336089134217,\n",
       "    0.0011456378862261772,\n",
       "    0.0011465102657675743,\n",
       "    0.001146031054854393,\n",
       "    0.001145743253082037,\n",
       "    0.0011453757807612418,\n",
       "    0.001145362277328968,\n",
       "    0.0011450445741415024,\n",
       "    0.0011449761122465133,\n",
       "    0.0011449992716312408,\n",
       "    0.0011449785321950912,\n",
       "    0.0011448780633509159,\n",
       "    0.0011448636688292026,\n",
       "    0.001144868578761816,\n",
       "    0.0011449008978903293,\n",
       "    0.0011449075415730476,\n",
       "    0.001144882495701313],\n",
       "   'test_acc': [0.884,\n",
       "    0.8968,\n",
       "    0.9016,\n",
       "    0.9017,\n",
       "    0.904,\n",
       "    0.9064,\n",
       "    0.9097,\n",
       "    0.909,\n",
       "    0.909,\n",
       "    0.911,\n",
       "    0.9098,\n",
       "    0.9122,\n",
       "    0.9121,\n",
       "    0.9122,\n",
       "    0.9114,\n",
       "    0.9105,\n",
       "    0.9123,\n",
       "    0.9112,\n",
       "    0.9132,\n",
       "    0.9119,\n",
       "    0.9123,\n",
       "    0.9126,\n",
       "    0.912,\n",
       "    0.912,\n",
       "    0.912,\n",
       "    0.9119,\n",
       "    0.9121,\n",
       "    0.912,\n",
       "    0.912,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121,\n",
       "    0.9121]},\n",
       "  'train_time': 65.70935487747192},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 128, 10],\n",
       "  'num_params': (813056, 813056),\n",
       "  'train_result': {'train_loss': [0.4193094975453742,\n",
       "    0.12747814985031777,\n",
       "    0.10658361721546092,\n",
       "    0.09434944374605696,\n",
       "    0.0853162686399957,\n",
       "    0.07805700892225859,\n",
       "    0.07326484790190738,\n",
       "    0.06864373959759448,\n",
       "    0.06546594880204251,\n",
       "    0.06285749651253858,\n",
       "    0.06091689844714834,\n",
       "    0.05929256649093425,\n",
       "    0.058143869961829894,\n",
       "    0.057061679867353846,\n",
       "    0.05635430574258591,\n",
       "    0.055637150012115215,\n",
       "    0.05519546297319392,\n",
       "    0.054823218718012594,\n",
       "    0.05442887130094336,\n",
       "    0.05426343514564189,\n",
       "    0.0538431760478527,\n",
       "    0.05392955916517592,\n",
       "    0.05365803506066825,\n",
       "    0.05345058067840464,\n",
       "    0.053431614686517005,\n",
       "    0.05331606776948939,\n",
       "    0.05346774181469958,\n",
       "    0.05322128471700435,\n",
       "    0.05349298377937459,\n",
       "    0.053148699361593166,\n",
       "    0.053208672960704945,\n",
       "    0.05310885752452181,\n",
       "    0.05308625431770974,\n",
       "    0.05315590130680419,\n",
       "    0.05329630091944908,\n",
       "    0.053104225336078635,\n",
       "    0.05307038298788223,\n",
       "    0.0532197823510208,\n",
       "    0.05305042626296586,\n",
       "    0.05303742385449561],\n",
       "   'test_loss': [0.0013873073786497116,\n",
       "    0.001243827123939991,\n",
       "    0.0012236733183264732,\n",
       "    0.00119102783203125,\n",
       "    0.0012104101330041885,\n",
       "    0.0011543129362165928,\n",
       "    0.0011406025052070618,\n",
       "    0.001141392432898283,\n",
       "    0.001122923593968153,\n",
       "    0.001114544777572155,\n",
       "    0.0011034074246883392,\n",
       "    0.001103207043558359,\n",
       "    0.0011131408572196961,\n",
       "    0.0010993813872337342,\n",
       "    0.001098932508379221,\n",
       "    0.0010900474935770035,\n",
       "    0.0010922657698392868,\n",
       "    0.0010886483572423457,\n",
       "    0.0010864335753023625,\n",
       "    0.0010857910804450512,\n",
       "    0.0010822657272219658,\n",
       "    0.001084072668105364,\n",
       "    0.0010831322878599168,\n",
       "    0.0010817352727055549,\n",
       "    0.00108457023575902,\n",
       "    0.0010848956748843192,\n",
       "    0.0010847616724669934,\n",
       "    0.0010842186369001865,\n",
       "    0.0010841038681566714,\n",
       "    0.0010843131504952907,\n",
       "    0.0010839054264128209,\n",
       "    0.0010838008746504783,\n",
       "    0.0010838870830833913,\n",
       "    0.0010839276626706123,\n",
       "    0.001083936920017004,\n",
       "    0.0010839123398065566,\n",
       "    0.0010838725462555886,\n",
       "    0.0010838401228189468,\n",
       "    0.0010838864766061307,\n",
       "    0.0010838515840470792],\n",
       "   'test_acc': [0.8909,\n",
       "    0.9035,\n",
       "    0.9054,\n",
       "    0.9076,\n",
       "    0.9077,\n",
       "    0.9106,\n",
       "    0.9137,\n",
       "    0.9125,\n",
       "    0.915,\n",
       "    0.9159,\n",
       "    0.9173,\n",
       "    0.9165,\n",
       "    0.916,\n",
       "    0.9169,\n",
       "    0.9172,\n",
       "    0.9181,\n",
       "    0.9175,\n",
       "    0.9177,\n",
       "    0.9182,\n",
       "    0.9182,\n",
       "    0.9181,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.918,\n",
       "    0.9182,\n",
       "    0.9181,\n",
       "    0.918,\n",
       "    0.918,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9179,\n",
       "    0.9178,\n",
       "    0.9178]},\n",
       "  'train_time': 64.86924600601196},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 32, 32, 10],\n",
       "  'num_params': (211456, 211456),\n",
       "  'train_result': {'train_loss': [0.6379329563138333,\n",
       "    0.1459106166946127,\n",
       "    0.11861267032775473,\n",
       "    0.10441335501505973,\n",
       "    0.09529939728214386,\n",
       "    0.08766284218810974,\n",
       "    0.0829540647962626,\n",
       "    0.07940619595824404,\n",
       "    0.07593201982214096,\n",
       "    0.07402566825138762,\n",
       "    0.07206029729481707,\n",
       "    0.07061746468410847,\n",
       "    0.06926153689781402,\n",
       "    0.06868917009139315,\n",
       "    0.06784640182047448,\n",
       "    0.06722707048137772,\n",
       "    0.06708121888656565,\n",
       "    0.0663312285742227,\n",
       "    0.0662443450711509,\n",
       "    0.06618905466129171,\n",
       "    0.06574867389145049,\n",
       "    0.06555799942542898,\n",
       "    0.06534738453461769,\n",
       "    0.0652443335173612,\n",
       "    0.0651607845137094,\n",
       "    0.06503988012988517,\n",
       "    0.06500937331547128,\n",
       "    0.06514372763798591,\n",
       "    0.06503872679586106,\n",
       "    0.06496181900196887,\n",
       "    0.0649781762998789,\n",
       "    0.06491253540078376,\n",
       "    0.06491426005959511,\n",
       "    0.06501496917706855,\n",
       "    0.0648583875691637,\n",
       "    0.06499180005110325,\n",
       "    0.06511140476040383,\n",
       "    0.06492219472185094,\n",
       "    0.06491887073250527,\n",
       "    0.06489930118810623],\n",
       "   'test_loss': [0.0016020119667053223,\n",
       "    0.0013725156374275683,\n",
       "    0.0013213158860802651,\n",
       "    0.001240887939184904,\n",
       "    0.0011981931820511818,\n",
       "    0.0011887260094285011,\n",
       "    0.0011870988942682744,\n",
       "    0.001177085891366005,\n",
       "    0.0011234913945198058,\n",
       "    0.0011241662099957467,\n",
       "    0.001141521056741476,\n",
       "    0.0011234235227108001,\n",
       "    0.001118238116800785,\n",
       "    0.00111397113353014,\n",
       "    0.0011035670384764672,\n",
       "    0.001119268549978733,\n",
       "    0.001110106698423624,\n",
       "    0.0011035150162875653,\n",
       "    0.0011068127825856209,\n",
       "    0.0011092883005738258,\n",
       "    0.001105157046020031,\n",
       "    0.0011034986801445484,\n",
       "    0.001102609346807003,\n",
       "    0.001103932649642229,\n",
       "    0.0011027312695980071,\n",
       "    0.0011018526300787925,\n",
       "    0.0011020304545760154,\n",
       "    0.0011016007587313652,\n",
       "    0.0011011481896042823,\n",
       "    0.0011005972027778625,\n",
       "    0.0011003964066505431,\n",
       "    0.0011006589241325856,\n",
       "    0.0011005454145371913,\n",
       "    0.0011006475687026977,\n",
       "    0.001100476100295782,\n",
       "    0.0011005949817597866,\n",
       "    0.001100600992143154,\n",
       "    0.0011006471052765847,\n",
       "    0.0011006133332848549,\n",
       "    0.0011006127648055554],\n",
       "   'test_acc': [0.8755,\n",
       "    0.8976,\n",
       "    0.9027,\n",
       "    0.9038,\n",
       "    0.907,\n",
       "    0.9088,\n",
       "    0.9071,\n",
       "    0.9084,\n",
       "    0.9136,\n",
       "    0.9125,\n",
       "    0.9111,\n",
       "    0.9138,\n",
       "    0.9143,\n",
       "    0.9148,\n",
       "    0.9158,\n",
       "    0.9138,\n",
       "    0.9143,\n",
       "    0.9161,\n",
       "    0.9158,\n",
       "    0.9161,\n",
       "    0.9168,\n",
       "    0.9168,\n",
       "    0.9169,\n",
       "    0.9166,\n",
       "    0.9169,\n",
       "    0.9169,\n",
       "    0.917,\n",
       "    0.9169,\n",
       "    0.9171,\n",
       "    0.9171,\n",
       "    0.917,\n",
       "    0.9171,\n",
       "    0.9171,\n",
       "    0.9171,\n",
       "    0.9169,\n",
       "    0.9171,\n",
       "    0.917,\n",
       "    0.9171,\n",
       "    0.9171,\n",
       "    0.917]},\n",
       "  'train_time': 81.87582612037659},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 64, 64, 10],\n",
       "  'num_params': (439296, 439296),\n",
       "  'train_result': {'train_loss': [0.48487703866781073,\n",
       "    0.12137020076525973,\n",
       "    0.09982223591588914,\n",
       "    0.08474235705080184,\n",
       "    0.07564188146844823,\n",
       "    0.0679030207481156,\n",
       "    0.06313468779021121,\n",
       "    0.05943212785777893,\n",
       "    0.05614923698470948,\n",
       "    0.05402047471638689,\n",
       "    0.052138680679366944,\n",
       "    0.05075137917190156,\n",
       "    0.04965849982851998,\n",
       "    0.048602179572620294,\n",
       "    0.04799966180023361,\n",
       "    0.04734294118478577,\n",
       "    0.04682589130912056,\n",
       "    0.04669993165484134,\n",
       "    0.046039023127486096,\n",
       "    0.045934158147491036,\n",
       "    0.04563548233201529,\n",
       "    0.04564713083128346,\n",
       "    0.04538282713595223,\n",
       "    0.045245537756288305,\n",
       "    0.04519851240230367,\n",
       "    0.04516072568899773,\n",
       "    0.04508302275170671,\n",
       "    0.04518181143843747,\n",
       "    0.04499317083824822,\n",
       "    0.044947410620590475,\n",
       "    0.04494267715180808,\n",
       "    0.044922040949793574,\n",
       "    0.04496402363193796,\n",
       "    0.04498003566280959,\n",
       "    0.04497948430795619,\n",
       "    0.04489916508739933,\n",
       "    0.044909576774436105,\n",
       "    0.04497266647187953,\n",
       "    0.04506398406513828,\n",
       "    0.04494242440275055],\n",
       "   'test_loss': [0.0014074475333094598,\n",
       "    0.0013486188381910324,\n",
       "    0.0012466235846281051,\n",
       "    0.0012276388317346574,\n",
       "    0.0011492912873625756,\n",
       "    0.0010991816475987434,\n",
       "    0.0011284723199903965,\n",
       "    0.001083807310461998,\n",
       "    0.0010986307315528393,\n",
       "    0.0010884151190519334,\n",
       "    0.0010876590006053447,\n",
       "    0.0010870168037712573,\n",
       "    0.0010660892821848392,\n",
       "    0.0010675252363085746,\n",
       "    0.001067182894051075,\n",
       "    0.0010659656248986722,\n",
       "    0.0010539360970258712,\n",
       "    0.001064632897824049,\n",
       "    0.0010433628253638744,\n",
       "    0.0010562375389039516,\n",
       "    0.0010537283830344677,\n",
       "    0.0010542885653674603,\n",
       "    0.0010571863777935505,\n",
       "    0.0010545940689742565,\n",
       "    0.001054339599609375,\n",
       "    0.0010545319885015487,\n",
       "    0.0010557779110968112,\n",
       "    0.001055502864718437,\n",
       "    0.001055830018222332,\n",
       "    0.0010552585370838643,\n",
       "    0.0010557102605700493,\n",
       "    0.0010552569717168809,\n",
       "    0.0010552707515656947,\n",
       "    0.001055278892070055,\n",
       "    0.0010553796909749508,\n",
       "    0.0010551772981882096,\n",
       "    0.0010553082972764968,\n",
       "    0.0010552248910069466,\n",
       "    0.0010553044259548187,\n",
       "    0.00105522782728076],\n",
       "   'test_acc': [0.8888,\n",
       "    0.8985,\n",
       "    0.9051,\n",
       "    0.9068,\n",
       "    0.9131,\n",
       "    0.918,\n",
       "    0.9167,\n",
       "    0.9189,\n",
       "    0.919,\n",
       "    0.9196,\n",
       "    0.9192,\n",
       "    0.9202,\n",
       "    0.921,\n",
       "    0.921,\n",
       "    0.9218,\n",
       "    0.9218,\n",
       "    0.9242,\n",
       "    0.9223,\n",
       "    0.9235,\n",
       "    0.9238,\n",
       "    0.9238,\n",
       "    0.9235,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9236,\n",
       "    0.9234,\n",
       "    0.9235,\n",
       "    0.9235,\n",
       "    0.9234,\n",
       "    0.9237,\n",
       "    0.9235,\n",
       "    0.9236,\n",
       "    0.9236,\n",
       "    0.9234,\n",
       "    0.9234,\n",
       "    0.9235,\n",
       "    0.9234,\n",
       "    0.9235,\n",
       "    0.9235,\n",
       "    0.9236]},\n",
       "  'train_time': 79.96453857421875},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 0,\n",
       "  'num_params': (55244, 55244),\n",
       "  'train_result': {'train_loss': [0.38837555317168543,\n",
       "    0.11311638052476214,\n",
       "    0.09686648492166336,\n",
       "    0.08763142281231728,\n",
       "    0.07990502199911056,\n",
       "    0.07423891014558204,\n",
       "    0.06986248869686684,\n",
       "    0.06646841333267536,\n",
       "    0.06381369454270981,\n",
       "    0.061985006116013576,\n",
       "    0.060291016521923084,\n",
       "    0.059101362811758165,\n",
       "    0.0579187338577306,\n",
       "    0.05730199058480719,\n",
       "    0.056526764196918364,\n",
       "    0.056011177448833244,\n",
       "    0.055538333096402756,\n",
       "    0.05542919383721149,\n",
       "    0.055322871864476104,\n",
       "    0.05487333139840593,\n",
       "    0.05472428036972563,\n",
       "    0.05463238488486473,\n",
       "    0.0544347060091318,\n",
       "    0.05467313008898116,\n",
       "    0.05449498897378749,\n",
       "    0.054192291842179094,\n",
       "    0.05460932671706727,\n",
       "    0.054082220210198394,\n",
       "    0.05432031169692252,\n",
       "    0.05408237746104281,\n",
       "    0.054337680648933066,\n",
       "    0.05419795778679087,\n",
       "    0.05411785025387368,\n",
       "    0.05408508437190284,\n",
       "    0.05426427373226653,\n",
       "    0.054210960472676345,\n",
       "    0.054363386055573504,\n",
       "    0.05396786947992254,\n",
       "    0.05400323541240489,\n",
       "    0.05396782103529636],\n",
       "   'test_loss': [0.0012683578006923199,\n",
       "    0.0011496289923787117,\n",
       "    0.0011359325043857097,\n",
       "    0.0010377195000648499,\n",
       "    0.0010140856422483921,\n",
       "    0.0009895217269659043,\n",
       "    0.0009638975515961647,\n",
       "    0.0009475114576518535,\n",
       "    0.0009170352675020695,\n",
       "    0.0009192998215556145,\n",
       "    0.0009155379951000214,\n",
       "    0.0008950723946094512,\n",
       "    0.0008873313218355179,\n",
       "    0.0008918936058878898,\n",
       "    0.0008861676916480064,\n",
       "    0.0008803549759089946,\n",
       "    0.0008762820810079574,\n",
       "    0.0008747749585658311,\n",
       "    0.0008763636756688357,\n",
       "    0.0008758968416601419,\n",
       "    0.0008747837562114,\n",
       "    0.0008738033324480057,\n",
       "    0.0008721509121358394,\n",
       "    0.0008728198740631342,\n",
       "    0.0008716621715575457,\n",
       "    0.0008710104770958424,\n",
       "    0.0008709642082452774,\n",
       "    0.0008707999717444181,\n",
       "    0.0008705384396016598,\n",
       "    0.0008705643959343434,\n",
       "    0.0008704926777631045,\n",
       "    0.000870571830868721,\n",
       "    0.0008705494266003371,\n",
       "    0.0008705189891159535,\n",
       "    0.0008705266065895558,\n",
       "    0.0008704688549041748,\n",
       "    0.0008704255204647779,\n",
       "    0.000870461742952466,\n",
       "    0.000870459171384573,\n",
       "    0.0008704516176134347],\n",
       "   'test_acc': [0.9014,\n",
       "    0.9113,\n",
       "    0.9143,\n",
       "    0.9204,\n",
       "    0.9229,\n",
       "    0.9254,\n",
       "    0.9296,\n",
       "    0.9305,\n",
       "    0.9325,\n",
       "    0.9326,\n",
       "    0.9328,\n",
       "    0.9334,\n",
       "    0.9341,\n",
       "    0.9342,\n",
       "    0.9347,\n",
       "    0.9354,\n",
       "    0.9357,\n",
       "    0.9354,\n",
       "    0.935,\n",
       "    0.9354,\n",
       "    0.9355,\n",
       "    0.9356,\n",
       "    0.9358,\n",
       "    0.9358,\n",
       "    0.9357,\n",
       "    0.9359,\n",
       "    0.9359,\n",
       "    0.9358,\n",
       "    0.9359,\n",
       "    0.9359,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936,\n",
       "    0.936]},\n",
       "  'train_time': 598.2149972915649},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 1,\n",
       "  'num_params': (41614, 41614),\n",
       "  'train_result': {'train_loss': [0.514239164711313,\n",
       "    0.09881445600631389,\n",
       "    0.0701238880132107,\n",
       "    0.056316784269949224,\n",
       "    0.04862101613444851,\n",
       "    0.04375572667476979,\n",
       "    0.04041251392757639,\n",
       "    0.03785787419356564,\n",
       "    0.03597477287093693,\n",
       "    0.03480055308801697,\n",
       "    0.03357157094919301,\n",
       "    0.03290447071987264,\n",
       "    0.032472434517075405,\n",
       "    0.03172522478518968,\n",
       "    0.031547320749055835,\n",
       "    0.030992654255254472,\n",
       "    0.030807049487261696,\n",
       "    0.03055228012554506,\n",
       "    0.030393331075840174,\n",
       "    0.03026287892952244,\n",
       "    0.03016923636673613,\n",
       "    0.030085091839762445,\n",
       "    0.030023222967506723,\n",
       "    0.03001038287469047,\n",
       "    0.03011589419255231,\n",
       "    0.02992075983078239,\n",
       "    0.02983105016198564,\n",
       "    0.030022201364106955,\n",
       "    0.030047817898795327,\n",
       "    0.029770221684048786,\n",
       "    0.029778488860168355,\n",
       "    0.029835445877719434,\n",
       "    0.029738481450786298,\n",
       "    0.029781368353027613,\n",
       "    0.029795527767310752,\n",
       "    0.029742152751126186,\n",
       "    0.02980483408145448,\n",
       "    0.029729782391656585,\n",
       "    0.029748816861513448,\n",
       "    0.0297330961503247],\n",
       "   'test_loss': [0.0011053371898829937,\n",
       "    0.0008506415523588657,\n",
       "    0.0007308935299515725,\n",
       "    0.0006566333632916212,\n",
       "    0.0006510597076267003,\n",
       "    0.0006080561108887196,\n",
       "    0.0005898406598716974,\n",
       "    0.0005631211243569851,\n",
       "    0.0005754184411838651,\n",
       "    0.0005700119692832232,\n",
       "    0.0005623275142163038,\n",
       "    0.0005519202660769224,\n",
       "    0.000561132725328207,\n",
       "    0.0005549387689679861,\n",
       "    0.0005567043785005808,\n",
       "    0.000548107273131609,\n",
       "    0.0005577119020745158,\n",
       "    0.0005564599892124534,\n",
       "    0.0005570163583382964,\n",
       "    0.0005521848304197193,\n",
       "    0.0005533882992342114,\n",
       "    0.0005507991461083292,\n",
       "    0.0005516319563612341,\n",
       "    0.0005526677057147026,\n",
       "    0.0005516262482851744,\n",
       "    0.000551952557079494,\n",
       "    0.0005521472403779626,\n",
       "    0.0005516677882522345,\n",
       "    0.0005515689576044678,\n",
       "    0.0005514110462740064,\n",
       "    0.0005514391588047146,\n",
       "    0.0005514799289405346,\n",
       "    0.0005515169756487012,\n",
       "    0.0005515197105705738,\n",
       "    0.0005514467356726527,\n",
       "    0.0005514566989615559,\n",
       "    0.0005514335088431836,\n",
       "    0.0005514306209981442,\n",
       "    0.0005514219734817743,\n",
       "    0.0005514055384323001],\n",
       "   'test_acc': [0.9164,\n",
       "    0.9328,\n",
       "    0.943,\n",
       "    0.9516,\n",
       "    0.9504,\n",
       "    0.9541,\n",
       "    0.956,\n",
       "    0.9579,\n",
       "    0.9576,\n",
       "    0.9578,\n",
       "    0.9589,\n",
       "    0.9589,\n",
       "    0.9583,\n",
       "    0.9577,\n",
       "    0.9585,\n",
       "    0.9595,\n",
       "    0.9585,\n",
       "    0.9586,\n",
       "    0.9586,\n",
       "    0.9591,\n",
       "    0.9589,\n",
       "    0.9591,\n",
       "    0.959,\n",
       "    0.9589,\n",
       "    0.9588,\n",
       "    0.9589,\n",
       "    0.9589,\n",
       "    0.959,\n",
       "    0.959,\n",
       "    0.959,\n",
       "    0.9591,\n",
       "    0.9591,\n",
       "    0.9591,\n",
       "    0.9592,\n",
       "    0.9591,\n",
       "    0.9592,\n",
       "    0.9592,\n",
       "    0.9592,\n",
       "    0.9592,\n",
       "    0.9592]},\n",
       "  'train_time': 2008.9209742546082},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 2,\n",
       "  'num_params': (94650, 94650),\n",
       "  'train_result': {'train_loss': [0.7436897803177225,\n",
       "    0.08904476501840226,\n",
       "    0.05725886714743807,\n",
       "    0.044701969782088666,\n",
       "    0.0378168721980554,\n",
       "    0.03342802307390152,\n",
       "    0.030606772659465355,\n",
       "    0.02846200762594,\n",
       "    0.02694405329988358,\n",
       "    0.025807900833798216,\n",
       "    0.024916164006324525,\n",
       "    0.024217236450219407,\n",
       "    0.023724838663288887,\n",
       "    0.023229105104791356,\n",
       "    0.02303380859976119,\n",
       "    0.022679092869796653,\n",
       "    0.02240302748978138,\n",
       "    0.022268466483008988,\n",
       "    0.02214983800782802,\n",
       "    0.02200911367470597,\n",
       "    0.021995602254854873,\n",
       "    0.02181871024733211,\n",
       "    0.02179857856653472,\n",
       "    0.02171138763784411,\n",
       "    0.021745161989584882,\n",
       "    0.021661458871862355,\n",
       "    0.021630628545709112,\n",
       "    0.021671344355699864,\n",
       "    0.021595511151517324,\n",
       "    0.021616627390872924,\n",
       "    0.021571177349207882,\n",
       "    0.021652852379261178,\n",
       "    0.021621004287946097,\n",
       "    0.021675501090097936,\n",
       "    0.021545609697065454,\n",
       "    0.021585509904283793,\n",
       "    0.021542598059440546,\n",
       "    0.021601475561235813,\n",
       "    0.021556701550775385,\n",
       "    0.021545673308378838],\n",
       "   'test_loss': [0.0010549359366297721,\n",
       "    0.0007542741589248181,\n",
       "    0.000636949185654521,\n",
       "    0.0005728627502918244,\n",
       "    0.0005601107444614172,\n",
       "    0.0005349266430363059,\n",
       "    0.0005173941239714622,\n",
       "    0.0004966186590492725,\n",
       "    0.0005008194230496884,\n",
       "    0.00048691171631217003,\n",
       "    0.0004875969510525465,\n",
       "    0.0004903123123571277,\n",
       "    0.00048437406551092864,\n",
       "    0.0004899705039337277,\n",
       "    0.0004807289581745863,\n",
       "    0.00047956946808844805,\n",
       "    0.0004792426643893123,\n",
       "    0.0004790740406140685,\n",
       "    0.000478420184366405,\n",
       "    0.0004775922177359462,\n",
       "    0.0004776145150884986,\n",
       "    0.00047695373389869926,\n",
       "    0.00047680384926497934,\n",
       "    0.0004768121855333447,\n",
       "    0.00047652709893882276,\n",
       "    0.000476401399075985,\n",
       "    0.0004762297188863158,\n",
       "    0.0004761408843100071,\n",
       "    0.0004760191498324275,\n",
       "    0.0004759642221033573,\n",
       "    0.00047593149170279504,\n",
       "    0.0004759123535826802,\n",
       "    0.00047583003994077443,\n",
       "    0.000475840680859983,\n",
       "    0.0004758005624637008,\n",
       "    0.0004757649665698409,\n",
       "    0.0004757687823846936,\n",
       "    0.00047577142026275395,\n",
       "    0.0004757669700309634,\n",
       "    0.0004757762039080262],\n",
       "   'test_acc': [0.9222,\n",
       "    0.9433,\n",
       "    0.9527,\n",
       "    0.9567,\n",
       "    0.9583,\n",
       "    0.9597,\n",
       "    0.9607,\n",
       "    0.9631,\n",
       "    0.9626,\n",
       "    0.964,\n",
       "    0.9637,\n",
       "    0.9636,\n",
       "    0.9638,\n",
       "    0.9637,\n",
       "    0.9639,\n",
       "    0.9639,\n",
       "    0.9642,\n",
       "    0.964,\n",
       "    0.964,\n",
       "    0.9643,\n",
       "    0.9642,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9643,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644,\n",
       "    0.9644]},\n",
       "  'train_time': 2062.9953923225403},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 10],\n",
       "  'num_params': (7850, 7850),\n",
       "  'train_result': {'train_loss': [0.747408431641599,\n",
       "    0.287365234595664,\n",
       "    0.22525787131583436,\n",
       "    0.19749203853784725,\n",
       "    0.18202404056457763,\n",
       "    0.17189729803420128,\n",
       "    0.1646717020171754,\n",
       "    0.15943861606907336,\n",
       "    0.15554386662675979,\n",
       "    0.15261520020505215,\n",
       "    0.15017111567740746,\n",
       "    0.14865203918294703,\n",
       "    0.14727986822737024,\n",
       "    0.1457452746464851,\n",
       "    0.14484870566966687,\n",
       "    0.1442702184015132,\n",
       "    0.1435729428174648,\n",
       "    0.1431183139694498,\n",
       "    0.14267013675354898,\n",
       "    0.14244997304804782,\n",
       "    0.14204091708710853,\n",
       "    0.14214854738179675,\n",
       "    0.1416937028791042,\n",
       "    0.14148031863126348,\n",
       "    0.1414711795905803,\n",
       "    0.14146899435114355,\n",
       "    0.14159122188674642,\n",
       "    0.14126738744213227,\n",
       "    0.14114894895477498,\n",
       "    0.14115208311283842,\n",
       "    0.14100625410358958,\n",
       "    0.1409936637003371,\n",
       "    0.14103508591651917,\n",
       "    0.14109559388870888,\n",
       "    0.14100154505131093,\n",
       "    0.14129390656313998,\n",
       "    0.1409119927185647,\n",
       "    0.14088901734732567,\n",
       "    0.14091632943204108,\n",
       "    0.14128688152166122],\n",
       "   'test_loss': [0.0024246371805667875,\n",
       "    0.001957836467027664,\n",
       "    0.0017652467876672745,\n",
       "    0.001674473948776722,\n",
       "    0.001605152179300785,\n",
       "    0.0015678719386458396,\n",
       "    0.0015365831673145294,\n",
       "    0.0015171459645032883,\n",
       "    0.0014969737946987152,\n",
       "    0.001485273802280426,\n",
       "    0.001475952735543251,\n",
       "    0.0014662445619702338,\n",
       "    0.001461044754087925,\n",
       "    0.001455462472140789,\n",
       "    0.001451307500898838,\n",
       "    0.0014480751648545266,\n",
       "    0.001445656357705593,\n",
       "    0.0014433535024523734,\n",
       "    0.0014413866087794303,\n",
       "    0.0014398247689008713,\n",
       "    0.0014387381583452225,\n",
       "    0.0014378880947828294,\n",
       "    0.001437190629541874,\n",
       "    0.0014365565270185471,\n",
       "    0.0014360546246170998,\n",
       "    0.0014357056945562363,\n",
       "    0.0014354148104786873,\n",
       "    0.0014351815819740295,\n",
       "    0.0014349777534604072,\n",
       "    0.0014348247244954108,\n",
       "    0.001434699796140194,\n",
       "    0.0014345963954925536,\n",
       "    0.001434510524570942,\n",
       "    0.0014344519346952437,\n",
       "    0.0014343982577323913,\n",
       "    0.001434356400370598,\n",
       "    0.0014343244016170502,\n",
       "    0.0014342958047986031,\n",
       "    0.0014342757657170295,\n",
       "    0.0014342607334256172],\n",
       "   'test_acc': [0.8481,\n",
       "    0.866,\n",
       "    0.8764,\n",
       "    0.8818,\n",
       "    0.8845,\n",
       "    0.8866,\n",
       "    0.8875,\n",
       "    0.8891,\n",
       "    0.891,\n",
       "    0.8915,\n",
       "    0.8921,\n",
       "    0.8928,\n",
       "    0.893,\n",
       "    0.8931,\n",
       "    0.8932,\n",
       "    0.8935,\n",
       "    0.8939,\n",
       "    0.8939,\n",
       "    0.8942,\n",
       "    0.8942,\n",
       "    0.8942,\n",
       "    0.8943,\n",
       "    0.8943,\n",
       "    0.8943,\n",
       "    0.8944,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8946,\n",
       "    0.8946,\n",
       "    0.8946,\n",
       "    0.8946,\n",
       "    0.8946,\n",
       "    0.8946]},\n",
       "  'train_time': 39.45659852027893},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 16, 10],\n",
       "  'num_params': (12730, 12730),\n",
       "  'train_result': {'train_loss': [0.7884766872258897,\n",
       "    0.20196265968236518,\n",
       "    0.15497787486999592,\n",
       "    0.13665462564280692,\n",
       "    0.12606584632650336,\n",
       "    0.11925435438752174,\n",
       "    0.11498778727143369,\n",
       "    0.11175521536076323,\n",
       "    0.10869703880966979,\n",
       "    0.10702008056513806,\n",
       "    0.10525188197163825,\n",
       "    0.10414174157888331,\n",
       "    0.1036432165731775,\n",
       "    0.10253349430066475,\n",
       "    0.10201857351559274,\n",
       "    0.10150276920262803,\n",
       "    0.10124781386966401,\n",
       "    0.10081378991933579,\n",
       "    0.1006566307329117,\n",
       "    0.10040717129694654,\n",
       "    0.1003698985944403,\n",
       "    0.10040384618208763,\n",
       "    0.10005063636505858,\n",
       "    0.09996540215104184,\n",
       "    0.10006166927992029,\n",
       "    0.0998233639020869,\n",
       "    0.09981189232240333,\n",
       "    0.0999742144124305,\n",
       "    0.09986526079951448,\n",
       "    0.09979863185831842,\n",
       "    0.09999228156310447,\n",
       "    0.09985533767241113,\n",
       "    0.09987871496284262,\n",
       "    0.09981929667769594,\n",
       "    0.09980034496872983,\n",
       "    0.09982280271484496,\n",
       "    0.09985184767778883,\n",
       "    0.09962567595091272,\n",
       "    0.09982735592317074,\n",
       "    0.09957110533847453],\n",
       "   'test_loss': [0.002008364915847778,\n",
       "    0.0015935713559389114,\n",
       "    0.0014720092341303824,\n",
       "    0.0014161205887794496,\n",
       "    0.0013571529984474182,\n",
       "    0.0013412184059619903,\n",
       "    0.0013246066391468048,\n",
       "    0.001308821591734886,\n",
       "    0.0012956441700458527,\n",
       "    0.0012982707157731055,\n",
       "    0.0012879387974739074,\n",
       "    0.0012873831734061241,\n",
       "    0.0012813431933522224,\n",
       "    0.001277824815362692,\n",
       "    0.001277281691879034,\n",
       "    0.0012744303897023201,\n",
       "    0.001273994505405426,\n",
       "    0.0012730921290814877,\n",
       "    0.0012726173289120198,\n",
       "    0.001272280690819025,\n",
       "    0.0012722808070480824,\n",
       "    0.0012717272587120534,\n",
       "    0.001271505618095398,\n",
       "    0.0012711852483451365,\n",
       "    0.0012711819350719451,\n",
       "    0.0012709391146898269,\n",
       "    0.0012706645086407661,\n",
       "    0.0012706906132400036,\n",
       "    0.001270537132024765,\n",
       "    0.0012705002807080746,\n",
       "    0.001270446866005659,\n",
       "    0.0012704050175845623,\n",
       "    0.0012703767821192742,\n",
       "    0.0012703399062156677,\n",
       "    0.0012703167989850045,\n",
       "    0.0012703090757131576,\n",
       "    0.0012702936500310897,\n",
       "    0.0012702785521745681,\n",
       "    0.0012702723249793052,\n",
       "    0.0012702556543052197],\n",
       "   'test_acc': [0.8603,\n",
       "    0.882,\n",
       "    0.8922,\n",
       "    0.8938,\n",
       "    0.8986,\n",
       "    0.8996,\n",
       "    0.9015,\n",
       "    0.9017,\n",
       "    0.9026,\n",
       "    0.9024,\n",
       "    0.9023,\n",
       "    0.9029,\n",
       "    0.903,\n",
       "    0.9019,\n",
       "    0.9026,\n",
       "    0.9028,\n",
       "    0.9033,\n",
       "    0.9031,\n",
       "    0.9032,\n",
       "    0.903,\n",
       "    0.9029,\n",
       "    0.9029,\n",
       "    0.9028,\n",
       "    0.9031,\n",
       "    0.903,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031,\n",
       "    0.9031]},\n",
       "  'train_time': 42.2247314453125},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 32, 10],\n",
       "  'num_params': (25450, 25450),\n",
       "  'train_result': {'train_loss': [0.6260220797772104,\n",
       "    0.16151467285891796,\n",
       "    0.12860714750404054,\n",
       "    0.11437788440826091,\n",
       "    0.10576101289467608,\n",
       "    0.09987322463000074,\n",
       "    0.09580740901700993,\n",
       "    0.09272720048085172,\n",
       "    0.09051481225389116,\n",
       "    0.08853776618204218,\n",
       "    0.08716830779263314,\n",
       "    0.08614556706173623,\n",
       "    0.0851651743212913,\n",
       "    0.0844176508169225,\n",
       "    0.08410877374575493,\n",
       "    0.08352082356652046,\n",
       "    0.08330874313857961,\n",
       "    0.08287345250236228,\n",
       "    0.08267169920529457,\n",
       "    0.08259711267941809,\n",
       "    0.08241534802983416,\n",
       "    0.0822960078399232,\n",
       "    0.08233510761501941,\n",
       "    0.08227843350552498,\n",
       "    0.08196161455137932,\n",
       "    0.08202355710115838,\n",
       "    0.08218148696295759,\n",
       "    0.08198117005064133,\n",
       "    0.08191993526638823,\n",
       "    0.08198814876377583,\n",
       "    0.0818126047862337,\n",
       "    0.08197306990623474,\n",
       "    0.0821563211923584,\n",
       "    0.0820402981277476,\n",
       "    0.0818154818120789,\n",
       "    0.08175739523102628,\n",
       "    0.08172792012387134,\n",
       "    0.08172698900737661,\n",
       "    0.0817993237458645,\n",
       "    0.08189109528952457],\n",
       "   'test_loss': [0.0016891719356179238,\n",
       "    0.0014191121846437453,\n",
       "    0.001324881425499916,\n",
       "    0.0012794137731194496,\n",
       "    0.001233875396847725,\n",
       "    0.0012259479507803917,\n",
       "    0.0012123870149254798,\n",
       "    0.0012105473220348358,\n",
       "    0.001192051012814045,\n",
       "    0.0011907679796218872,\n",
       "    0.0011868545413017274,\n",
       "    0.0011877364672720433,\n",
       "    0.001187473313510418,\n",
       "    0.0011777759484946728,\n",
       "    0.0011833920650184155,\n",
       "    0.0011794220261275767,\n",
       "    0.0011798817306756973,\n",
       "    0.001179565680027008,\n",
       "    0.0011785521820187569,\n",
       "    0.0011785498894751072,\n",
       "    0.0011785563118755817,\n",
       "    0.001178206107020378,\n",
       "    0.001177783627808094,\n",
       "    0.0011774383910000323,\n",
       "    0.0011771520979702473,\n",
       "    0.0011770063810050487,\n",
       "    0.0011769694983959197,\n",
       "    0.0011768601074814797,\n",
       "    0.0011768063098192216,\n",
       "    0.001176783637702465,\n",
       "    0.0011766440734267234,\n",
       "    0.0011766199357807637,\n",
       "    0.001176614996790886,\n",
       "    0.0011766008131206035,\n",
       "    0.0011765583895146847,\n",
       "    0.0011765484645962715,\n",
       "    0.001176518888771534,\n",
       "    0.0011765274256467818,\n",
       "    0.0011765166580677033,\n",
       "    0.001176509775221348],\n",
       "   'test_acc': [0.8776,\n",
       "    0.8958,\n",
       "    0.9019,\n",
       "    0.9026,\n",
       "    0.9056,\n",
       "    0.9064,\n",
       "    0.9081,\n",
       "    0.9078,\n",
       "    0.9097,\n",
       "    0.9096,\n",
       "    0.9094,\n",
       "    0.9099,\n",
       "    0.9104,\n",
       "    0.9105,\n",
       "    0.9101,\n",
       "    0.9106,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9105,\n",
       "    0.9105,\n",
       "    0.9104,\n",
       "    0.9105,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9105,\n",
       "    0.9105,\n",
       "    0.9105,\n",
       "    0.9105,\n",
       "    0.9105,\n",
       "    0.9105,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9105,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9104,\n",
       "    0.9104]},\n",
       "  'train_time': 43.14489960670471},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 64, 10],\n",
       "  'num_params': (50890, 50890),\n",
       "  'train_result': {'train_loss': [0.48496432507291753,\n",
       "    0.13670745406379092,\n",
       "    0.11237560876823487,\n",
       "    0.09996039685099684,\n",
       "    0.0920538621221451,\n",
       "    0.086511559499071,\n",
       "    0.08242897228040594,\n",
       "    0.07909338531341958,\n",
       "    0.07669334595507764,\n",
       "    0.0748525157729362,\n",
       "    0.07331852518180583,\n",
       "    0.0722485897864433,\n",
       "    0.0711699507417197,\n",
       "    0.07059956718473992,\n",
       "    0.06995779705491471,\n",
       "    0.06942307452096584,\n",
       "    0.06910976689071097,\n",
       "    0.06880288274681315,\n",
       "    0.06844640256876641,\n",
       "    0.06832939335640441,\n",
       "    0.06831836086162861,\n",
       "    0.06816836143744753,\n",
       "    0.06785867737328753,\n",
       "    0.06783539250968619,\n",
       "    0.0677645808918045,\n",
       "    0.06763170138794057,\n",
       "    0.06757208259498819,\n",
       "    0.06759275842378748,\n",
       "    0.06755445373660707,\n",
       "    0.06760195236098258,\n",
       "    0.0676738947233621,\n",
       "    0.06757582598861228,\n",
       "    0.06771372593939304,\n",
       "    0.06757508258711785,\n",
       "    0.06768267960783014,\n",
       "    0.06749547306210436,\n",
       "    0.06764048198436169,\n",
       "    0.06755134690790734,\n",
       "    0.06759973827036138,\n",
       "    0.06744228818632186],\n",
       "   'test_loss': [0.0015181216925382614,\n",
       "    0.0013163585886359216,\n",
       "    0.001255357900261879,\n",
       "    0.0012234921023249626,\n",
       "    0.0011879484429955483,\n",
       "    0.0011765063151717185,\n",
       "    0.001142337614297867,\n",
       "    0.0011440268389880657,\n",
       "    0.0011346863530576228,\n",
       "    0.0011311821542680264,\n",
       "    0.00112326740026474,\n",
       "    0.0011152045749127865,\n",
       "    0.0011182912670075894,\n",
       "    0.0011249515078961849,\n",
       "    0.001115670569241047,\n",
       "    0.0011134203650057315,\n",
       "    0.0011120926596224308,\n",
       "    0.0011162265934050084,\n",
       "    0.0011144535951316357,\n",
       "    0.0011127445198595525,\n",
       "    0.0011118010267615317,\n",
       "    0.0011123082622885704,\n",
       "    0.0011117235094308853,\n",
       "    0.001111323343217373,\n",
       "    0.0011113725520670414,\n",
       "    0.0011113529935479164,\n",
       "    0.0011112339168787002,\n",
       "    0.0011110857069492341,\n",
       "    0.0011109674230217934,\n",
       "    0.0011108720913529397,\n",
       "    0.0011108599066734315,\n",
       "    0.0011108389854431152,\n",
       "    0.0011108010090887547,\n",
       "    0.0011107320189476014,\n",
       "    0.00111075100004673,\n",
       "    0.0011107205018401145,\n",
       "    0.001110698765516281,\n",
       "    0.0011107055671513081,\n",
       "    0.001110698500275612,\n",
       "    0.0011106830559670926],\n",
       "   'test_acc': [0.8888,\n",
       "    0.9002,\n",
       "    0.9044,\n",
       "    0.9061,\n",
       "    0.9083,\n",
       "    0.9101,\n",
       "    0.9132,\n",
       "    0.9112,\n",
       "    0.913,\n",
       "    0.9126,\n",
       "    0.9135,\n",
       "    0.914,\n",
       "    0.9139,\n",
       "    0.9133,\n",
       "    0.9144,\n",
       "    0.9144,\n",
       "    0.9144,\n",
       "    0.9143,\n",
       "    0.9144,\n",
       "    0.9145,\n",
       "    0.9145,\n",
       "    0.9145,\n",
       "    0.9146,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9146,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147,\n",
       "    0.9147]},\n",
       "  'train_time': 44.24175143241882},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 128, 10],\n",
       "  'num_params': (101770, 101770),\n",
       "  'train_result': {'train_loss': [0.3820257916412455,\n",
       "    0.11871509030461311,\n",
       "    0.09673097079738657,\n",
       "    0.08409742847719091,\n",
       "    0.07558081292725624,\n",
       "    0.06983514184013326,\n",
       "    0.06528678599031681,\n",
       "    0.06206145307168048,\n",
       "    0.05930336978524289,\n",
       "    0.05742715338760234,\n",
       "    0.055724770036783625,\n",
       "    0.05477065789572736,\n",
       "    0.05360087586685698,\n",
       "    0.052825894341506856,\n",
       "    0.05201320961672575,\n",
       "    0.05154601543983246,\n",
       "    0.051169739909311555,\n",
       "    0.050973058832769695,\n",
       "    0.05072964202374854,\n",
       "    0.05050017052587676,\n",
       "    0.050159574363459934,\n",
       "    0.05005028533967251,\n",
       "    0.050007417322473324,\n",
       "    0.04985355464543434,\n",
       "    0.0498287993621953,\n",
       "    0.04971556836303244,\n",
       "    0.04965273773575083,\n",
       "    0.049721458257037277,\n",
       "    0.0496125533621996,\n",
       "    0.049594515617540545,\n",
       "    0.04973909954758401,\n",
       "    0.0496789956703148,\n",
       "    0.04961150600872141,\n",
       "    0.04959877960066846,\n",
       "    0.04970911313244637,\n",
       "    0.04960864913907457,\n",
       "    0.049472661688923836,\n",
       "    0.04955629312453118,\n",
       "    0.04965522942787155,\n",
       "    0.04974009947098316],\n",
       "   'test_loss': [0.00138646040558815,\n",
       "    0.0012621161103248597,\n",
       "    0.001157392606139183,\n",
       "    0.0011402314871549607,\n",
       "    0.001090805733203888,\n",
       "    0.001082814585417509,\n",
       "    0.0010774915456771852,\n",
       "    0.001056858827918768,\n",
       "    0.0010563725046813489,\n",
       "    0.001048617110401392,\n",
       "    0.0010385397590696812,\n",
       "    0.0010442619971930982,\n",
       "    0.0010471038952469826,\n",
       "    0.0010378746822476386,\n",
       "    0.0010395295575261116,\n",
       "    0.0010380959741771222,\n",
       "    0.0010374835856258868,\n",
       "    0.0010336062781512738,\n",
       "    0.0010341342002153397,\n",
       "    0.001035409129410982,\n",
       "    0.001034670466184616,\n",
       "    0.0010349743522703647,\n",
       "    0.0010340307869017124,\n",
       "    0.0010332074351608754,\n",
       "    0.0010335847355425359,\n",
       "    0.001033854479342699,\n",
       "    0.0010338728547096253,\n",
       "    0.0010336092062294482,\n",
       "    0.0010335455529391765,\n",
       "    0.0010335998393595218,\n",
       "    0.0010335620276629926,\n",
       "    0.001033501610159874,\n",
       "    0.001033542563021183,\n",
       "    0.0010334914453327656,\n",
       "    0.0010335058957338333,\n",
       "    0.0010334870539605617,\n",
       "    0.0010334936760365964,\n",
       "    0.001033471042662859,\n",
       "    0.0010334548026323317,\n",
       "    0.0010334574945271016],\n",
       "   'test_acc': [0.8949,\n",
       "    0.9048,\n",
       "    0.9115,\n",
       "    0.9121,\n",
       "    0.9162,\n",
       "    0.9177,\n",
       "    0.9177,\n",
       "    0.9187,\n",
       "    0.9201,\n",
       "    0.9202,\n",
       "    0.9213,\n",
       "    0.9221,\n",
       "    0.9207,\n",
       "    0.9221,\n",
       "    0.9217,\n",
       "    0.9214,\n",
       "    0.9217,\n",
       "    0.9222,\n",
       "    0.9224,\n",
       "    0.9222,\n",
       "    0.922,\n",
       "    0.922,\n",
       "    0.9221,\n",
       "    0.9223,\n",
       "    0.922,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221,\n",
       "    0.9221]},\n",
       "  'train_time': 44.4507577419281},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 256, 10],\n",
       "  'num_params': (203530, 203530),\n",
       "  'train_result': {'train_loss': [0.3123452694492137,\n",
       "    0.10272942296368011,\n",
       "    0.08080598356083353,\n",
       "    0.0670831550705306,\n",
       "    0.05878131144699898,\n",
       "    0.05266763253652669,\n",
       "    0.04827393676213761,\n",
       "    0.04499807838905365,\n",
       "    0.042338621061533056,\n",
       "    0.04021781267241595,\n",
       "    0.03865674077037801,\n",
       "    0.037565870551352805,\n",
       "    0.036407499296709576,\n",
       "    0.03571495080089315,\n",
       "    0.03511181979420337,\n",
       "    0.034614446973229976,\n",
       "    0.03413907258989329,\n",
       "    0.03400644489583817,\n",
       "    0.0336512536682347,\n",
       "    0.0334078654567612,\n",
       "    0.03334010368648996,\n",
       "    0.03305855772675986,\n",
       "    0.033008312077281325,\n",
       "    0.03296473159831255,\n",
       "    0.032824982048824745,\n",
       "    0.032756320704171,\n",
       "    0.03272581666787254,\n",
       "    0.03266840204992827,\n",
       "    0.03287734665927735,\n",
       "    0.03262924302686402,\n",
       "    0.03267741605163889,\n",
       "    0.03258915667996762,\n",
       "    0.03269235633234394,\n",
       "    0.03277629303567587,\n",
       "    0.03256230578619115,\n",
       "    0.03258800035778513,\n",
       "    0.03259698289664502,\n",
       "    0.03258855971804959,\n",
       "    0.03254783426986096,\n",
       "    0.032573523538860866],\n",
       "   'test_loss': [0.0013438649311661721,\n",
       "    0.001134609490633011,\n",
       "    0.0010875997975468635,\n",
       "    0.001040290803462267,\n",
       "    0.001038486484438181,\n",
       "    0.001004879342764616,\n",
       "    0.0009698319919407368,\n",
       "    0.0009687731996178627,\n",
       "    0.0009672226779162884,\n",
       "    0.0009670092925429344,\n",
       "    0.0009845838658511638,\n",
       "    0.0009631898604333401,\n",
       "    0.0009673781782388687,\n",
       "    0.0009651846073567867,\n",
       "    0.0009604490850120783,\n",
       "    0.0009626833595335483,\n",
       "    0.000959993039444089,\n",
       "    0.0009564377062022686,\n",
       "    0.000963479857519269,\n",
       "    0.0009603606518357993,\n",
       "    0.0009576822943985462,\n",
       "    0.0009559443611651659,\n",
       "    0.0009575475811958313,\n",
       "    0.0009572341714054346,\n",
       "    0.0009565879609435797,\n",
       "    0.0009561645992100238,\n",
       "    0.0009559318218380213,\n",
       "    0.0009560583230108022,\n",
       "    0.000956295108422637,\n",
       "    0.0009562317039817572,\n",
       "    0.0009561226446181536,\n",
       "    0.0009562386937439441,\n",
       "    0.0009562247414141894,\n",
       "    0.0009562462523579597,\n",
       "    0.000956190487742424,\n",
       "    0.0009561816092580556,\n",
       "    0.0009561379447579384,\n",
       "    0.0009561875365674496,\n",
       "    0.0009561744753271342,\n",
       "    0.0009561647962778807],\n",
       "   'test_acc': [0.9,\n",
       "    0.9107,\n",
       "    0.9171,\n",
       "    0.9185,\n",
       "    0.9203,\n",
       "    0.923,\n",
       "    0.9267,\n",
       "    0.9268,\n",
       "    0.9264,\n",
       "    0.9271,\n",
       "    0.9259,\n",
       "    0.9278,\n",
       "    0.9273,\n",
       "    0.928,\n",
       "    0.9283,\n",
       "    0.9284,\n",
       "    0.9281,\n",
       "    0.9287,\n",
       "    0.9283,\n",
       "    0.9286,\n",
       "    0.929,\n",
       "    0.9291,\n",
       "    0.929,\n",
       "    0.9292,\n",
       "    0.9292,\n",
       "    0.9292,\n",
       "    0.9292,\n",
       "    0.9293,\n",
       "    0.9294,\n",
       "    0.9294,\n",
       "    0.9294,\n",
       "    0.9294,\n",
       "    0.9295,\n",
       "    0.9295,\n",
       "    0.9295,\n",
       "    0.9295,\n",
       "    0.9295,\n",
       "    0.9295,\n",
       "    0.9295,\n",
       "    0.9295]},\n",
       "  'train_time': 44.82247447967529},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 32, 32, 10],\n",
       "  'num_params': (26506, 26506),\n",
       "  'train_result': {'train_loss': [0.6738637723187183,\n",
       "    0.14719068192421123,\n",
       "    0.11832943194090052,\n",
       "    0.10587285422581308,\n",
       "    0.09774217094354173,\n",
       "    0.09204677766624918,\n",
       "    0.08807648608976222,\n",
       "    0.08568443317521125,\n",
       "    0.08301604011274398,\n",
       "    0.08134573114679215,\n",
       "    0.07984699830412864,\n",
       "    0.07895012359986914,\n",
       "    0.07805615592985711,\n",
       "    0.0773346639139221,\n",
       "    0.07691283541473937,\n",
       "    0.07638534015004939,\n",
       "    0.07636609812207679,\n",
       "    0.07580116816816178,\n",
       "    0.07567366016830536,\n",
       "    0.07530947972802406,\n",
       "    0.07544855046621028,\n",
       "    0.07527867130776669,\n",
       "    0.07506508403953085,\n",
       "    0.07489812503311229,\n",
       "    0.07498561934904849,\n",
       "    0.07503959049886845,\n",
       "    0.07475015562265477,\n",
       "    0.0748377013793017,\n",
       "    0.07480623489840234,\n",
       "    0.07492693306759317,\n",
       "    0.07479610719737854,\n",
       "    0.07480968225826608,\n",
       "    0.07484599443826269,\n",
       "    0.07470155480377218,\n",
       "    0.074802021182915,\n",
       "    0.07474515295409141,\n",
       "    0.07481127592160347,\n",
       "    0.07465173311214497,\n",
       "    0.0746355183184781,\n",
       "    0.07485963296382986],\n",
       "   'test_loss': [0.0016709456115961074,\n",
       "    0.0013963279828429222,\n",
       "    0.0013524613663554192,\n",
       "    0.0012812103964388371,\n",
       "    0.0012674091599881648,\n",
       "    0.0012356477923691272,\n",
       "    0.001230774498730898,\n",
       "    0.0012065987020730973,\n",
       "    0.0012121766746044159,\n",
       "    0.0011959626890718938,\n",
       "    0.0012011850669980048,\n",
       "    0.00120063216984272,\n",
       "    0.0011893635749816894,\n",
       "    0.0011926006488502026,\n",
       "    0.0011994473278522492,\n",
       "    0.0011977843165397644,\n",
       "    0.0011908389568328858,\n",
       "    0.0011940979078412055,\n",
       "    0.0011923841081559658,\n",
       "    0.0011903640761971473,\n",
       "    0.0011913366720080376,\n",
       "    0.001191428603976965,\n",
       "    0.0011922973841428756,\n",
       "    0.0011919761441648007,\n",
       "    0.0011913928687572479,\n",
       "    0.0011914098739624023,\n",
       "    0.001191319264471531,\n",
       "    0.0011913421109318732,\n",
       "    0.0011913255527615547,\n",
       "    0.001191124800592661,\n",
       "    0.0011911747261881829,\n",
       "    0.0011911394149065019,\n",
       "    0.0011911598600447177,\n",
       "    0.0011911259412765503,\n",
       "    0.0011910766527056694,\n",
       "    0.001191125723719597,\n",
       "    0.0011911457858979702,\n",
       "    0.0011910701081156731,\n",
       "    0.0011910850778222085,\n",
       "    0.0011910881616175174],\n",
       "   'test_acc': [0.8772,\n",
       "    0.8932,\n",
       "    0.8981,\n",
       "    0.9008,\n",
       "    0.9029,\n",
       "    0.9067,\n",
       "    0.9074,\n",
       "    0.9074,\n",
       "    0.9079,\n",
       "    0.9097,\n",
       "    0.9098,\n",
       "    0.91,\n",
       "    0.9108,\n",
       "    0.9104,\n",
       "    0.9109,\n",
       "    0.9108,\n",
       "    0.9109,\n",
       "    0.9104,\n",
       "    0.911,\n",
       "    0.9115,\n",
       "    0.9111,\n",
       "    0.9112,\n",
       "    0.9109,\n",
       "    0.9111,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113,\n",
       "    0.9113]},\n",
       "  'train_time': 44.46668863296509},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 64, 64, 10],\n",
       "  'num_params': (55050, 55050),\n",
       "  'train_result': {'train_loss': [0.4834340582819695,\n",
       "    0.11487639633581993,\n",
       "    0.09263354330620867,\n",
       "    0.08018696316062136,\n",
       "    0.07244590452693879,\n",
       "    0.06646243258518107,\n",
       "    0.06189421618238408,\n",
       "    0.05853578083692713,\n",
       "    0.05616204240062135,\n",
       "    0.05407471405540375,\n",
       "    0.05267077534201931,\n",
       "    0.05153512855238737,\n",
       "    0.050646703171127655,\n",
       "    0.04986158085075465,\n",
       "    0.04910267740488052,\n",
       "    0.0486672709121349,\n",
       "    0.048217787078403414,\n",
       "    0.047929258050119626,\n",
       "    0.04776598183398551,\n",
       "    0.04743066975807256,\n",
       "    0.047428766384403756,\n",
       "    0.04740963556427271,\n",
       "    0.047227641591366304,\n",
       "    0.04703259751834768,\n",
       "    0.046929757316854406,\n",
       "    0.046883582521943336,\n",
       "    0.046803078459615406,\n",
       "    0.04682991830433937,\n",
       "    0.04687224284131476,\n",
       "    0.04673372986231079,\n",
       "    0.04674384521043047,\n",
       "    0.04668000880628824,\n",
       "    0.04671571767948409,\n",
       "    0.04668723903992709,\n",
       "    0.04677690623843289,\n",
       "    0.0467118329705393,\n",
       "    0.04664850068932518,\n",
       "    0.046635641046661014,\n",
       "    0.04679655022919178,\n",
       "    0.046709009061785454],\n",
       "   'test_loss': [0.0014290876179933547,\n",
       "    0.001266888626664877,\n",
       "    0.0011494622975587844,\n",
       "    0.0011455875545740128,\n",
       "    0.0011305862165987492,\n",
       "    0.001105167058110237,\n",
       "    0.001131634460389614,\n",
       "    0.0011095089361071587,\n",
       "    0.0011014994241297245,\n",
       "    0.0011028459943830968,\n",
       "    0.0010941198006272316,\n",
       "    0.0010872278943657874,\n",
       "    0.001115332556515932,\n",
       "    0.001095654109120369,\n",
       "    0.0010890977442264557,\n",
       "    0.0011031375244259835,\n",
       "    0.0010984835095703602,\n",
       "    0.0010929105803370476,\n",
       "    0.001096070832014084,\n",
       "    0.0010948626719415188,\n",
       "    0.0010934869959950448,\n",
       "    0.0010926604121923446,\n",
       "    0.0010955649048089982,\n",
       "    0.001094489260017872,\n",
       "    0.001094092759490013,\n",
       "    0.0010939770825207234,\n",
       "    0.0010947311408817768,\n",
       "    0.0010948088973760605,\n",
       "    0.0010946443922817707,\n",
       "    0.0010948032893240453,\n",
       "    0.0010945462845265866,\n",
       "    0.0010944414272904396,\n",
       "    0.0010943838082253933,\n",
       "    0.001094410838931799,\n",
       "    0.0010943876281380653,\n",
       "    0.0010944789968430997,\n",
       "    0.0010944733932614326,\n",
       "    0.0010944300301373004,\n",
       "    0.0010944073662161827,\n",
       "    0.0010944742850959302],\n",
       "   'test_acc': [0.8921,\n",
       "    0.9056,\n",
       "    0.9118,\n",
       "    0.9137,\n",
       "    0.9141,\n",
       "    0.9176,\n",
       "    0.9174,\n",
       "    0.919,\n",
       "    0.9188,\n",
       "    0.9202,\n",
       "    0.9197,\n",
       "    0.9216,\n",
       "    0.9194,\n",
       "    0.9207,\n",
       "    0.9207,\n",
       "    0.9204,\n",
       "    0.9207,\n",
       "    0.9208,\n",
       "    0.9207,\n",
       "    0.9205,\n",
       "    0.9204,\n",
       "    0.9208,\n",
       "    0.9202,\n",
       "    0.9203,\n",
       "    0.9202,\n",
       "    0.9205,\n",
       "    0.9202,\n",
       "    0.9203,\n",
       "    0.9204,\n",
       "    0.9203,\n",
       "    0.9204,\n",
       "    0.9203,\n",
       "    0.9203,\n",
       "    0.9204,\n",
       "    0.9204,\n",
       "    0.9204,\n",
       "    0.9204,\n",
       "    0.9204,\n",
       "    0.9204,\n",
       "    0.9204]},\n",
       "  'train_time': 46.02969002723694},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 128, 128, 10],\n",
       "  'num_params': (118282, 118282),\n",
       "  'train_result': {'train_loss': [0.3676220765773286,\n",
       "    0.10249723172251214,\n",
       "    0.08049390550623549,\n",
       "    0.06691500525921583,\n",
       "    0.05701680249197686,\n",
       "    0.05010544201160999,\n",
       "    0.04483196080682125,\n",
       "    0.04138767398259741,\n",
       "    0.038749506051077486,\n",
       "    0.03660017391864924,\n",
       "    0.03493541402425221,\n",
       "    0.033490543043676844,\n",
       "    0.03267091225357132,\n",
       "    0.03167493618390661,\n",
       "    0.03097674512958273,\n",
       "    0.030547019649059214,\n",
       "    0.03002891005908555,\n",
       "    0.02969802455738821,\n",
       "    0.029444196118794858,\n",
       "    0.02923000249615375,\n",
       "    0.029083740982682783,\n",
       "    0.028903016408390186,\n",
       "    0.02889420433722912,\n",
       "    0.02869007743379854,\n",
       "    0.028758892989618347,\n",
       "    0.02858395331757183,\n",
       "    0.028500038646954173,\n",
       "    0.028440697324719835,\n",
       "    0.028439578120695783,\n",
       "    0.02846604331614489,\n",
       "    0.028355680871754885,\n",
       "    0.028436024360200193,\n",
       "    0.028336422034400576,\n",
       "    0.02837365825085881,\n",
       "    0.02835828028222982,\n",
       "    0.028382780989433858,\n",
       "    0.028333040523005927,\n",
       "    0.0283348913106354,\n",
       "    0.02833780216726851,\n",
       "    0.028335703826172554],\n",
       "   'test_loss': [0.0013562401421368122,\n",
       "    0.0011888435274362563,\n",
       "    0.0011639309592545032,\n",
       "    0.0010944579519331454,\n",
       "    0.0010761026240885259,\n",
       "    0.001010631088912487,\n",
       "    0.0010234556533396243,\n",
       "    0.0010069460455328226,\n",
       "    0.0010006962057203055,\n",
       "    0.0009667543835937977,\n",
       "    0.000992735505476594,\n",
       "    0.0009813647776842117,\n",
       "    0.0009911256965249777,\n",
       "    0.0009981094632297753,\n",
       "    0.0009857377756386995,\n",
       "    0.0010039134703576564,\n",
       "    0.000995164005458355,\n",
       "    0.0009985645025968552,\n",
       "    0.0009915960740298033,\n",
       "    0.0009941075947135687,\n",
       "    0.000994320871308446,\n",
       "    0.0009961858544498682,\n",
       "    0.0009962455417960882,\n",
       "    0.0009962164502590894,\n",
       "    0.0009973124079406261,\n",
       "    0.0009970046620815993,\n",
       "    0.0009985639158636333,\n",
       "    0.0009979418497532606,\n",
       "    0.0009986984193325042,\n",
       "    0.0009985661812126636,\n",
       "    0.0009982313923537732,\n",
       "    0.0009981954447925091,\n",
       "    0.0009981070850044488,\n",
       "    0.000998077282309532,\n",
       "    0.0009980687588453292,\n",
       "    0.0009980278510600328,\n",
       "    0.0009980805967003106,\n",
       "    0.000998005748167634,\n",
       "    0.00099804816134274,\n",
       "    0.000998091372847557],\n",
       "   'test_acc': [0.9,\n",
       "    0.9087,\n",
       "    0.9133,\n",
       "    0.9178,\n",
       "    0.9199,\n",
       "    0.9257,\n",
       "    0.9252,\n",
       "    0.9253,\n",
       "    0.9261,\n",
       "    0.9292,\n",
       "    0.9279,\n",
       "    0.9287,\n",
       "    0.9295,\n",
       "    0.9291,\n",
       "    0.9301,\n",
       "    0.9296,\n",
       "    0.9299,\n",
       "    0.9294,\n",
       "    0.9302,\n",
       "    0.9296,\n",
       "    0.9296,\n",
       "    0.9299,\n",
       "    0.9299,\n",
       "    0.9299,\n",
       "    0.93,\n",
       "    0.9299,\n",
       "    0.9299,\n",
       "    0.9302,\n",
       "    0.9302,\n",
       "    0.93,\n",
       "    0.93,\n",
       "    0.9301,\n",
       "    0.93,\n",
       "    0.9299,\n",
       "    0.9299,\n",
       "    0.9299,\n",
       "    0.93,\n",
       "    0.9298,\n",
       "    0.9299,\n",
       "    0.93]},\n",
       "  'train_time': 42.96457600593567},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 256, 256, 10],\n",
       "  'num_params': (269322, 269322),\n",
       "  'train_result': {'train_loss': [0.2821611108773566,\n",
       "    0.08161268871515355,\n",
       "    0.05799955487092759,\n",
       "    0.044310890205521536,\n",
       "    0.034961564775477065,\n",
       "    0.028528367947945568,\n",
       "    0.024412113961149402,\n",
       "    0.020925664078404613,\n",
       "    0.01854450924797578,\n",
       "    0.016771145309618814,\n",
       "    0.01535917160576804,\n",
       "    0.014129453424879528,\n",
       "    0.013251221115562192,\n",
       "    0.012698452886035468,\n",
       "    0.012054893980793496,\n",
       "    0.011690185319117093,\n",
       "    0.01139547862905137,\n",
       "    0.011096745728455643,\n",
       "    0.010883461376850275,\n",
       "    0.01067744989760537,\n",
       "    0.010512075246252278,\n",
       "    0.010437816389380617,\n",
       "    0.01032318942635221,\n",
       "    0.010240120678506,\n",
       "    0.01030067910162851,\n",
       "    0.010110036870266528,\n",
       "    0.010083581585476691,\n",
       "    0.010058067418991568,\n",
       "    0.010019888875490808,\n",
       "    0.010027637280662485,\n",
       "    0.009992526958082268,\n",
       "    0.01012433367939864,\n",
       "    0.009985311263974042,\n",
       "    0.009944495985760016,\n",
       "    0.009976797186313792,\n",
       "    0.009945909204357799,\n",
       "    0.009925627095149235,\n",
       "    0.009923448765333345,\n",
       "    0.009959825273959878,\n",
       "    0.00991185240229552],\n",
       "   'test_loss': [0.001182477942854166,\n",
       "    0.0010708632923662662,\n",
       "    0.0009537308074533939,\n",
       "    0.0009310805294662714,\n",
       "    0.0009404082156717777,\n",
       "    0.0009475925032049417,\n",
       "    0.000909115144610405,\n",
       "    0.0009265225846320391,\n",
       "    0.0009047046925872564,\n",
       "    0.0009486917819827795,\n",
       "    0.0009305133022367954,\n",
       "    0.000942991342768073,\n",
       "    0.0009343143783509732,\n",
       "    0.0009580721992999315,\n",
       "    0.000975092227011919,\n",
       "    0.000956388745084405,\n",
       "    0.0009682312328368425,\n",
       "    0.0009633392710238695,\n",
       "    0.0009474468782544136,\n",
       "    0.0009674433376640081,\n",
       "    0.0009609480131417512,\n",
       "    0.0009548422828316688,\n",
       "    0.0009655155371874571,\n",
       "    0.0009682353910058736,\n",
       "    0.0009623413283377886,\n",
       "    0.0009625921811908483,\n",
       "    0.0009650371447205543,\n",
       "    0.0009654614869505167,\n",
       "    0.0009652205348014832,\n",
       "    0.0009657625544816255,\n",
       "    0.0009661090936511755,\n",
       "    0.0009663224950432778,\n",
       "    0.0009662310600280762,\n",
       "    0.000966382770985365,\n",
       "    0.0009662987682968378,\n",
       "    0.0009662250880151987,\n",
       "    0.0009662895508110523,\n",
       "    0.0009663043018430472,\n",
       "    0.0009663676403462887,\n",
       "    0.0009663869317620993],\n",
       "   'test_acc': [0.9082,\n",
       "    0.9185,\n",
       "    0.9275,\n",
       "    0.9298,\n",
       "    0.9338,\n",
       "    0.9334,\n",
       "    0.9365,\n",
       "    0.9367,\n",
       "    0.9384,\n",
       "    0.9373,\n",
       "    0.939,\n",
       "    0.9385,\n",
       "    0.9398,\n",
       "    0.9385,\n",
       "    0.9383,\n",
       "    0.9395,\n",
       "    0.9386,\n",
       "    0.9393,\n",
       "    0.9398,\n",
       "    0.9389,\n",
       "    0.9396,\n",
       "    0.9392,\n",
       "    0.9395,\n",
       "    0.9395,\n",
       "    0.9397,\n",
       "    0.9397,\n",
       "    0.9396,\n",
       "    0.9397,\n",
       "    0.9397,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398,\n",
       "    0.9398]},\n",
       "  'train_time': 46.5630042552948},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 512, 512, 10],\n",
       "  'num_params': (669706, 669706),\n",
       "  'train_result': {'train_loss': [0.2269810544683578,\n",
       "    0.07047884590289694,\n",
       "    0.04460599268291225,\n",
       "    0.03069205122425201,\n",
       "    0.022485094495672493,\n",
       "    0.016570980607115843,\n",
       "    0.0122876262668758,\n",
       "    0.009699715723461927,\n",
       "    0.008001166099603189,\n",
       "    0.006710915771768766,\n",
       "    0.005754359658966039,\n",
       "    0.005089166921444554,\n",
       "    0.004552928262707243,\n",
       "    0.0041936890350932135,\n",
       "    0.0038529687380279474,\n",
       "    0.0036087885989431055,\n",
       "    0.0034437351679290702,\n",
       "    0.003255466290036256,\n",
       "    0.003125123203325858,\n",
       "    0.0030261307816080592,\n",
       "    0.00294664755532954,\n",
       "    0.002875419515630904,\n",
       "    0.0028293012230201286,\n",
       "    0.0027643825775854527,\n",
       "    0.0027286973369476247,\n",
       "    0.0026968439510884753,\n",
       "    0.002674613403716184,\n",
       "    0.0026571590262663334,\n",
       "    0.002631840843365508,\n",
       "    0.0026179853829238165,\n",
       "    0.002606624214627602,\n",
       "    0.002597875369494741,\n",
       "    0.0025918803009343273,\n",
       "    0.00258703899837317,\n",
       "    0.0025812829329453883,\n",
       "    0.0025751424399749474,\n",
       "    0.002571571282943354,\n",
       "    0.002568306087298279,\n",
       "    0.0025653751869190566,\n",
       "    0.0025656308552765464],\n",
       "   'test_loss': [0.0012069253899157047,\n",
       "    0.0010269831232726575,\n",
       "    0.0009917455479502679,\n",
       "    0.0008702043317258358,\n",
       "    0.0008958527632057666,\n",
       "    0.0008114012591540813,\n",
       "    0.000837884433194995,\n",
       "    0.0008429096423089505,\n",
       "    0.000855162488669157,\n",
       "    0.0008992072522640228,\n",
       "    0.0009144596945494414,\n",
       "    0.0009204592067748309,\n",
       "    0.0009305940721184015,\n",
       "    0.0009211840469390154,\n",
       "    0.0009272994805127382,\n",
       "    0.0009393871117383242,\n",
       "    0.0009415369596332311,\n",
       "    0.0009403391312807799,\n",
       "    0.0009614027127623558,\n",
       "    0.0009468111351132393,\n",
       "    0.0009541281793266535,\n",
       "    0.0009552632067352533,\n",
       "    0.0009634913817048073,\n",
       "    0.0009622180946171284,\n",
       "    0.0009639189518988133,\n",
       "    0.0009667519204318523,\n",
       "    0.0009679144948720932,\n",
       "    0.0009681177321821451,\n",
       "    0.0009685218203812838,\n",
       "    0.0009687531027942896,\n",
       "    0.0009685113914310932,\n",
       "    0.0009694462146610022,\n",
       "    0.0009700091425329447,\n",
       "    0.0009702246706932783,\n",
       "    0.0009703551921993494,\n",
       "    0.0009703709915280342,\n",
       "    0.0009706352431327104,\n",
       "    0.0009707941271364689,\n",
       "    0.0009708295553922654,\n",
       "    0.0009709552876651287],\n",
       "   'test_acc': [0.9104,\n",
       "    0.9202,\n",
       "    0.9308,\n",
       "    0.9376,\n",
       "    0.941,\n",
       "    0.9454,\n",
       "    0.9462,\n",
       "    0.9464,\n",
       "    0.9467,\n",
       "    0.946,\n",
       "    0.9464,\n",
       "    0.9463,\n",
       "    0.947,\n",
       "    0.9468,\n",
       "    0.9477,\n",
       "    0.9471,\n",
       "    0.9477,\n",
       "    0.9477,\n",
       "    0.9474,\n",
       "    0.9478,\n",
       "    0.9469,\n",
       "    0.9482,\n",
       "    0.9472,\n",
       "    0.9476,\n",
       "    0.9471,\n",
       "    0.9474,\n",
       "    0.9473,\n",
       "    0.9473,\n",
       "    0.9472,\n",
       "    0.9476,\n",
       "    0.9474,\n",
       "    0.9475,\n",
       "    0.9474,\n",
       "    0.9476,\n",
       "    0.9476,\n",
       "    0.9476,\n",
       "    0.9476,\n",
       "    0.9475,\n",
       "    0.9476,\n",
       "    0.9476]},\n",
       "  'train_time': 43.53667688369751}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f7b08de-fbc2-442a-a948-620cd2023cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save results to file\n",
    "f = open('test_results_kannadaMNIST_2.pickle', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bf36a-3f62-43b8-958f-0a4d8aede913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a17310-d554-4137-8dbf-063cc0a4eced",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan_venv_2",
   "language": "python",
   "name": "pykan_venv_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
