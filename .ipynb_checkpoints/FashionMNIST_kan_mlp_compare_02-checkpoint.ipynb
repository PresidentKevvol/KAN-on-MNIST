{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d4d150-96b6-4a63-8bc9-9b20b62ab163",
   "metadata": {},
   "source": [
    "# Comparing MLP vs. KAN on Classification problem with a bit more input dimensions (Fashion MNIST)\n",
    "\n",
    "Original KAN example: https://github.com/KindXiaoming/pykan/blob/master/tutorials/Example_3_classfication.ipynb \\\n",
    "EfficientKAN by Blealtan: https://github.com/Blealtan/efficient-kan \\\n",
    "MLP in pytorch Referenced from: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html \\\n",
    "ConvolutionalKAN by AntonioTepsich: https://github.com/AntonioTepsich/Convolutional-KANs\n",
    "\n",
    "Test with Fashion MNIST dataset: https://github.com/zalandoresearch/fashion-mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b0f2c9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ac3b61-ace6-422d-9457-05e00b3d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'efficient-kan-master', 'src')))\n",
    "\n",
    "from efficient_kan import KAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bd87f3-a8ec-48a9-9360-79d1a6100659",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'Convolutional-KANs-master')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'Convolutional-KANs-master', 'kan_convolutional')))\n",
    "\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional.KANLinear import KANLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c591dd6",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has CUDA: True\n",
      "device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print('Has CUDA:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('device name:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d67376",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e022d-b2df-4188-8788-dd3d86aca214",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999e35ca-fa49-4913-a381-769fa92a82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), 'fashion-mnist-master', 'utils')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c775ef69-5284-4819-b75e-7ca6fb230c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load with utility code\n",
    "import mnist_reader\n",
    "x_tr, y_tr = mnist_reader.load_mnist(join('fashion-mnist', 'data', 'fashion'), kind='train')\n",
    "x_te, y_te = mnist_reader.load_mnist(join('fashion-mnist', 'data', 'fashion'), kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f3ac74-f774-4aa0-9566-eeb2f0b5dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr.reshape((x_tr.shape[0], 28, 28))\n",
    "x_te = x_te.reshape((x_te.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873af6e1-6c1e-4e9f-b0d9-c3ffcc9c713b",
   "metadata": {},
   "source": [
    "##### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e1d798-d19d-491d-ab66-1623bcfd7353",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# normalie the dataset values to [0.0, 1.0]\n",
    "vmax = np.amax(x_tr)\n",
    "x_tr = x_tr / vmax\n",
    "x_te = x_te / vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1709bf4-602a-4b6d-bf82-c862b1d4e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "x_tr_flattened = x_tr.reshape((x_tr.shape[0], x_tr.shape[1] * x_tr.shape[2]))\n",
    "x_te_flattened = x_te.reshape((x_te.shape[0], x_te.shape[1] * x_te.shape[2]))\n",
    "\n",
    "# conv color channel\n",
    "x_tr_channeled = x_tr.reshape((x_tr.shape[0], 1, x_tr.shape[1], x_tr.shape[2]))\n",
    "x_te_channeled = x_te.reshape((x_te.shape[0], 1, x_te.shape[1], x_te.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fab300",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x_train_flattened = torch.tensor(np.array(x_tr_flattened))\n",
    "x_train_channeled = torch.tensor(np.array(x_tr_channeled))\n",
    "y_train = torch.tensor(np.array(y_tr))\n",
    "\n",
    "x_test_flattened  = torch.tensor(np.array(x_te_flattened))\n",
    "x_test_channeled  = torch.tensor(np.array(x_te_channeled))\n",
    "y_test  = torch.tensor(np.array(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2187dba",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ba19f4-a864-42bf-8ede-fa7411670255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_channeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bb877b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# chop off a ratio of the train sets\n",
    "ratio_keep = 1.0\n",
    "\n",
    "num_train = x_tr.shape[0]\n",
    "num_test = x_te.shape[0]\n",
    "\n",
    "num_train_1 = int(num_train * ratio_keep)\n",
    "num_test_1  = int(num_test * ratio_keep)\n",
    "\n",
    "x_train_flattened = x_train_flattened[:num_train_1, :]\n",
    "x_train_channeled = x_train_channeled[:num_train_1, :]\n",
    "y_train = y_train[:num_train_1]\n",
    "\n",
    "x_test_flattened = x_test_flattened[:num_test_1, :]\n",
    "x_test_channeled = x_test_channeled[:num_test_1, :]\n",
    "y_test = y_test[:num_test_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4c83e-02d4-4ca2-bbe2-568336431765",
   "metadata": {},
   "source": [
    "##### Create a troch dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08d7590",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11ec54e2-5797-4143-abbd-2f34d952bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "716ef2e8-fb82-47e7-9583-89e2c1cd85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattened for fully connected\n",
    "train_set_flattened = TensorDataset(x_train_flattened.to(dtype=torch.float32), y_train)\n",
    "train_loader_flattened = DataLoader(train_set_flattened, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set_flattened = TensorDataset(x_test_flattened.to(dtype=torch.float32), y_test)\n",
    "test_loader_flattened = DataLoader(test_set_flattened, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# channeled for convolution\n",
    "train_set_channeled = TensorDataset(x_train_channeled.to(dtype=torch.float32), y_train)\n",
    "train_loader_channeled = DataLoader(train_set_channeled, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set_channeled = TensorDataset(x_test_channeled.to(dtype=torch.float32), y_test)\n",
    "test_loader_channeled = DataLoader(test_set_channeled, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c17bf8-aa2a-4242-bd05-9e8caa2a208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_flattened = {'train': train_loader_flattened, 'test': test_loader_flattened}\n",
    "dataset_channeled = {'train': train_loader_channeled, 'test': test_loader_channeled}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd564596-965f-4afc-bacd-94254e986b47",
   "metadata": {},
   "source": [
    "### Code for classical MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "759b8ae1-4e75-4392-b4ca-a85d5738ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    '''\n",
    "    width is the dimension of each layer, like [784, 20, 20, 10]\n",
    "    '''\n",
    "    def __init__(self, width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        stack = []\n",
    "        l = len(width)\n",
    "        for i in range(l-2):\n",
    "            stack.append(nn.Linear(width[i], width[i+1]))\n",
    "            stack.append(nn.ReLU())\n",
    "        stack.append(nn.Linear(width[l-2], width[l-1]))\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(*stack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc38fb-1f39-4a03-9bca-38810ba322f9",
   "metadata": {},
   "source": [
    "### Code for ConvolutionKAN\n",
    "copied from: https://github.com/AntonioTepsich/Convolutional-KANs/tree/master/architectures_28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc651b5-57c9-4620-963e-1b70e38e7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvKAN_2conv(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(625, 64)\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c530bf6-ee8a-4d4f-9d87-bf1f9889beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvKAN_1conv(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(845, 64)\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d297c27-9173-4576-af6f-e06509c6484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KKAN_Convolutional_Network(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            625,\n",
    "            10,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0,1],\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.kan1(x) \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ac46581-3a8e-4d97-8b3a-df18e3e6dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "convkan_types_map = {0: ConvKAN_1conv, 1: ConvKAN_2conv, 2: KKAN_Convolutional_Network}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff23c7",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc24218-af0c-4f6b-b24c-4d88bc7949e9",
   "metadata": {},
   "source": [
    "##### utility funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2666675",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# see total number of params\n",
    "def get_num_params(model):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    pytorch_total_params_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    return pytorch_total_params, pytorch_total_params_trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d0906-8543-4b2f-a86d-cdc12c679d00",
   "metadata": {},
   "source": [
    "##### New util codes\n",
    "copied from: https://github.com/AntonioTepsich/Convolutional-KANs/blob/master/experiment_28x28.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e59fd1b-c13c-4215-9a10-746f893fb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_loader(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: the optimizer to use (e.g. SGD)\n",
    "        epoch: the current epoch\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: the average loss over the training set\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        # Get the loss\n",
    "        loss = criterion(output, target)\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    # print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "def test_batch_loader(model, device, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        test_loss: the average loss over the test set\n",
    "        accuracy: the accuracy of the model on the test set\n",
    "        precision: the precision of the model on the test set\n",
    "        recall: the recall of the model on the test set\n",
    "        f1: the f1 score of the model on the test set\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (target == predicted).sum().item()\n",
    "\n",
    "            # Collect all targets and predictions for metric calculations\n",
    "            all_targets.extend(target.view_as(predicted).cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Normalize test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Precision: {:.2f}, Recall: {:.2f}, F1 Score: {:.2f}\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset), accuracy, precision, recall, f1))\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f5c3f5d-99b7-4c43-87d7-c77a8dd16ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(model, num_epochs, loss_fn, train_loader, test_loader, optimizer, scheduler=None):\n",
    "    res = {'train_loss': [], 'test_loss': [], 'test_acc': []}\n",
    "    for n in tqdm(range(num_epochs)):\n",
    "        train_loss = train_batch_loader(model, 'cuda', train_loader, optimizer, n, loss_fn)\n",
    "        # test_loss, test_acc, precision, recall, f1 = test_batch_loader(model, 'cuda', test_loader, loss_fn)\n",
    "        test_loss, test_acc = test_batch_loader(model, 'cuda', test_loader, loss_fn)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        res['train_loss'].append(train_loss)\n",
    "        res['test_loss'].append(test_loss)\n",
    "        res['test_acc'].append(test_acc)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce08650-5506-4aa4-bd63-c5c1e8f250b3",
   "metadata": {},
   "source": [
    "##### Create different types of models and train them\n",
    "We want to use the same optimization method, batch size, etc. to compare the different architectures fairly \\\n",
    "This might cause slower training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0685fc62-a62d-4549-a698-0dc3785dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create, train, then discard a model\n",
    "our objective is to figure out the efficacy of different shaped models\n",
    "'''\n",
    "def create_and_train(model_type, width, epochs, lr, batch_size=-1):\n",
    "    dset = dataset_flattened\n",
    "    \n",
    "    # create model\n",
    "    if model_type == 'mlp':\n",
    "        model = NeuralNetwork(width).to(device='cuda')\n",
    "    elif model_type == 'kan':\n",
    "        model = KAN(width, grid_size=3, spline_order=3).to(device='cuda')\n",
    "    elif model_type == 'convkan':\n",
    "        # TODO: change to use width\n",
    "        model = convkan_types_map[width]().to(device='cuda')\n",
    "        dset = dataset_channeled\n",
    "\n",
    "    # record num of params\n",
    "    num_params = get_num_params(model)\n",
    "    \n",
    "    # use categorical cross entropy loss\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    # learning rate and adam optimizer\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "    \n",
    "    # train as any vanilla pytorch model\n",
    "    start = time.time()\n",
    "    # results = train(model, epochs, loss_fn, dset, optimizer, batch_size=batch_size)\n",
    "    results = train_process(model, epochs, loss_fn, dset['train'], dset['test'], optimizer, scheduler=scheduler)\n",
    "    end = time.time()\n",
    "\n",
    "    # free the memory\n",
    "    model.cpu()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return {'model_type': model_type, 'width': width, 'num_params': num_params, 'train_result': results, 'train_time': (end - start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58594fae-d5eb-489b-821c-d861fb808836",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_shapes = [\n",
    "    [784, 10],\n",
    "    [784, 16, 10],\n",
    "    [784, 32, 10],\n",
    "    [784, 64, 10],\n",
    "    [784, 128, 10],\n",
    "    [784, 32, 32, 10],\n",
    "    [784, 64, 64, 10],\n",
    "]\n",
    "\n",
    "mlp_shapes = [\n",
    "    [784, 10],\n",
    "    [784, 16, 10],\n",
    "    [784, 32, 10],\n",
    "    [784, 64, 10],\n",
    "    [784, 128, 10],\n",
    "    [784, 256, 10],\n",
    "    [784, 32, 32, 10],\n",
    "    [784, 64, 64, 10],\n",
    "    [784, 128, 128, 10],\n",
    "    [784, 256, 256, 10],\n",
    "    [784, 512, 512, 10],\n",
    "]\n",
    "\n",
    "convkan_types = convkan_types_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "197de4ce-917d-4412-9921-7c70862572bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1c8134c-b0d4-4397-a4ab-f43d7ce236f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_ct = 40\n",
    "# epoch_ct = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ee5be8f-7a97-480a-883e-23d92f65ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KAN shape: [784, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:57<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 57.71826672554016\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 16, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:10<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 70.62232851982117\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:10<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 70.56811594963074\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:07<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 67.23344850540161\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:05<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 65.37789392471313\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 32, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:23<00:00,  2.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 83.26506209373474\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 64, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:21<00:00,  2.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 81.20583653450012\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [10:02<00:00, 15.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 602.0037631988525\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [33:31<00:00, 50.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2011.3804113864899\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [34:16<00:00, 51.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2056.061446905136\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:39<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 39.70387029647827\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 16, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:42<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 42.671016216278076\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.271278858184814\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.53585982322693\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.94669270515442\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 256, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:45<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 45.42043113708496\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 32, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:45<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 45.24801063537598\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 64, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:46<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 46.59905123710632\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 128, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.21124076843262\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 256, 256, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:48<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 48.14005398750305\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 512, 512, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.39455962181091\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for shape in kan_shapes:\n",
    "    print('Training KAN shape:', shape)\n",
    "    res = create_and_train('kan', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)\n",
    "\n",
    "for shape in convkan_types:\n",
    "    print('Training ConvKAN type:', shape)\n",
    "    res = create_and_train('convkan', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)\n",
    "\n",
    "for shape in mlp_shapes:\n",
    "    print('Training MLP shape:', shape)\n",
    "    res = create_and_train('mlp', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbcd1cc8-4d9b-441d-bc29-047761851f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'kan',\n",
       "  'width': [784, 10],\n",
       "  'num_params': (62720, 62720),\n",
       "  'train_result': {'train_loss': [0.838990182318586,\n",
       "    0.5200798833623845,\n",
       "    0.4686173620376181,\n",
       "    0.44641085064157526,\n",
       "    0.4327016163379588,\n",
       "    0.4240541048506473,\n",
       "    0.4172017543873888,\n",
       "    0.4124736603270186,\n",
       "    0.4092126345380824,\n",
       "    0.40685463344797174,\n",
       "    0.405140664983303,\n",
       "    0.40294047911116415,\n",
       "    0.4017946201436063,\n",
       "    0.4010421858188954,\n",
       "    0.40010680537274546,\n",
       "    0.39969822688305634,\n",
       "    0.39878858936593886,\n",
       "    0.3986085350209094,\n",
       "    0.3982203347885862,\n",
       "    0.3979123854256691,\n",
       "    0.397643252002432,\n",
       "    0.39770095766858854,\n",
       "    0.3975338933315683,\n",
       "    0.3971603459500252,\n",
       "    0.39782198287071063,\n",
       "    0.3971752736162632,\n",
       "    0.39730572605386694,\n",
       "    0.39709142839654965,\n",
       "    0.39735567569732666,\n",
       "    0.397542302532399,\n",
       "    0.39716964059687676,\n",
       "    0.39690654594847496,\n",
       "    0.397364282861669,\n",
       "    0.3967489796750089,\n",
       "    0.3973621606826782,\n",
       "    0.39680553268879015,\n",
       "    0.39705689638218983,\n",
       "    0.39697475940623184,\n",
       "    0.3967218689461972,\n",
       "    0.39685847454882683],\n",
       "   'test_loss': [0.0023206034243106843,\n",
       "    0.0020238363474607466,\n",
       "    0.00190898075401783,\n",
       "    0.001862968671321869,\n",
       "    0.0018193288922309875,\n",
       "    0.0017991377890110016,\n",
       "    0.0017802656143903733,\n",
       "    0.001766429877281189,\n",
       "    0.0017603026300668716,\n",
       "    0.0017499294251203537,\n",
       "    0.0017443415850400925,\n",
       "    0.0017394162833690642,\n",
       "    0.0017380844473838806,\n",
       "    0.0017342101633548736,\n",
       "    0.0017327907651662827,\n",
       "    0.0017316541343927383,\n",
       "    0.001729640531539917,\n",
       "    0.0017290571182966231,\n",
       "    0.001728000396490097,\n",
       "    0.0017273048549890518,\n",
       "    0.0017267870724201203,\n",
       "    0.0017264389514923095,\n",
       "    0.001726158806681633,\n",
       "    0.001725853431224823,\n",
       "    0.001725733858346939,\n",
       "    0.0017255476802587508,\n",
       "    0.00172542445063591,\n",
       "    0.0017252996444702148,\n",
       "    0.0017252333998680114,\n",
       "    0.0017251626074314117,\n",
       "    0.001725115677714348,\n",
       "    0.0017250768303871155,\n",
       "    0.0017250394999980927,\n",
       "    0.001725014665722847,\n",
       "    0.0017249909669160843,\n",
       "    0.001724972864985466,\n",
       "    0.0017249602049589157,\n",
       "    0.001724948999285698,\n",
       "    0.0017249389737844468,\n",
       "    0.0017249332785606384],\n",
       "   'test_acc': [0.7972,\n",
       "    0.8219,\n",
       "    0.8307,\n",
       "    0.8368,\n",
       "    0.8383,\n",
       "    0.8383,\n",
       "    0.8398,\n",
       "    0.8409,\n",
       "    0.8402,\n",
       "    0.8431,\n",
       "    0.8416,\n",
       "    0.8421,\n",
       "    0.8421,\n",
       "    0.8421,\n",
       "    0.8437,\n",
       "    0.8429,\n",
       "    0.8441,\n",
       "    0.8432,\n",
       "    0.8439,\n",
       "    0.8439,\n",
       "    0.8432,\n",
       "    0.8433,\n",
       "    0.8435,\n",
       "    0.8435,\n",
       "    0.8434,\n",
       "    0.8437,\n",
       "    0.8436,\n",
       "    0.8436,\n",
       "    0.8436,\n",
       "    0.8436,\n",
       "    0.8437,\n",
       "    0.8437,\n",
       "    0.8438,\n",
       "    0.8437,\n",
       "    0.8437,\n",
       "    0.8438,\n",
       "    0.8437,\n",
       "    0.8437,\n",
       "    0.8438,\n",
       "    0.8438]},\n",
       "  'train_time': 57.71826672554016},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 16, 10],\n",
       "  'num_params': (101632, 101632),\n",
       "  'train_result': {'train_loss': [0.8942279682514516,\n",
       "    0.5123397678770918,\n",
       "    0.46331153905138056,\n",
       "    0.43875799255168185,\n",
       "    0.4241788952908617,\n",
       "    0.4122324819260455,\n",
       "    0.40474949174738944,\n",
       "    0.3989982262570807,\n",
       "    0.39486247922511813,\n",
       "    0.3917900762659438,\n",
       "    0.38902613875713754,\n",
       "    0.3867378166381349,\n",
       "    0.3850293156314403,\n",
       "    0.38384676613706226,\n",
       "    0.3827445286385556,\n",
       "    0.38198388878335343,\n",
       "    0.38136005794748346,\n",
       "    0.38100828946904935,\n",
       "    0.3807273538188731,\n",
       "    0.3797844775179599,\n",
       "    0.37928045956378287,\n",
       "    0.3794160622231504,\n",
       "    0.37956437506574264,\n",
       "    0.37909311798024686,\n",
       "    0.3787347807529125,\n",
       "    0.3792283616167434,\n",
       "    0.3785736838553814,\n",
       "    0.3790861949007562,\n",
       "    0.37887310664704504,\n",
       "    0.3788766544550023,\n",
       "    0.37850456491429757,\n",
       "    0.3786773114762408,\n",
       "    0.37859200201136,\n",
       "    0.37831807637468295,\n",
       "    0.37850869069708154,\n",
       "    0.37857743565072405,\n",
       "    0.3787038560877455,\n",
       "    0.37850374211656285,\n",
       "    0.3783708346650956,\n",
       "    0.37887478889303006],\n",
       "   'test_loss': [0.0022750471323728563,\n",
       "    0.002000239512324333,\n",
       "    0.001903210139274597,\n",
       "    0.001827922147512436,\n",
       "    0.0017963032305240631,\n",
       "    0.001765527081489563,\n",
       "    0.0017400146067142487,\n",
       "    0.0017277604281902314,\n",
       "    0.0017107412785291672,\n",
       "    0.0017046854436397552,\n",
       "    0.0017003048717975616,\n",
       "    0.0016923357367515564,\n",
       "    0.0016874335289001465,\n",
       "    0.0016828591763973237,\n",
       "    0.0016795344680547715,\n",
       "    0.0016783558130264282,\n",
       "    0.001676656809449196,\n",
       "    0.0016749358743429184,\n",
       "    0.001673947212100029,\n",
       "    0.0016729049742221832,\n",
       "    0.0016729535311460495,\n",
       "    0.001671694216132164,\n",
       "    0.0016715310335159302,\n",
       "    0.0016710505336523056,\n",
       "    0.0016708451688289643,\n",
       "    0.0016707329869270326,\n",
       "    0.0016705341279506683,\n",
       "    0.0016703865438699723,\n",
       "    0.0016702421814203262,\n",
       "    0.0016701588153839111,\n",
       "    0.0016700790703296662,\n",
       "    0.0016700492709875107,\n",
       "    0.0016700219303369523,\n",
       "    0.0016699828147888184,\n",
       "    0.0016699650317430496,\n",
       "    0.0016699376940727234,\n",
       "    0.0016699227392673493,\n",
       "    0.0016699104696512221,\n",
       "    0.001669899010658264,\n",
       "    0.001669890969991684],\n",
       "   'test_acc': [0.802,\n",
       "    0.8235,\n",
       "    0.8283,\n",
       "    0.836,\n",
       "    0.8379,\n",
       "    0.8411,\n",
       "    0.8444,\n",
       "    0.847,\n",
       "    0.8465,\n",
       "    0.8468,\n",
       "    0.8476,\n",
       "    0.8477,\n",
       "    0.8473,\n",
       "    0.8478,\n",
       "    0.8487,\n",
       "    0.8477,\n",
       "    0.8492,\n",
       "    0.8483,\n",
       "    0.8482,\n",
       "    0.8481,\n",
       "    0.8476,\n",
       "    0.8486,\n",
       "    0.8483,\n",
       "    0.8492,\n",
       "    0.8485,\n",
       "    0.8487,\n",
       "    0.8489,\n",
       "    0.8486,\n",
       "    0.8486,\n",
       "    0.8486,\n",
       "    0.8486,\n",
       "    0.8487,\n",
       "    0.8485,\n",
       "    0.8486,\n",
       "    0.8485,\n",
       "    0.8485,\n",
       "    0.8486,\n",
       "    0.8486,\n",
       "    0.8486,\n",
       "    0.8485]},\n",
       "  'train_time': 70.62232851982117},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 32, 10],\n",
       "  'num_params': (203264, 203264),\n",
       "  'train_result': {'train_loss': [0.7950195110858755,\n",
       "    0.47451822580175196,\n",
       "    0.42991534750512306,\n",
       "    0.4056038680228781,\n",
       "    0.3896776802996372,\n",
       "    0.378621814098764,\n",
       "    0.37004125321165043,\n",
       "    0.36283890167449384,\n",
       "    0.35782271230474433,\n",
       "    0.3538319596584807,\n",
       "    0.350833282952613,\n",
       "    0.3486548671062957,\n",
       "    0.3462454596098433,\n",
       "    0.3451818972191912,\n",
       "    0.34371469984663294,\n",
       "    0.3424753518814736,\n",
       "    0.3418414959248076,\n",
       "    0.34144253420068865,\n",
       "    0.34068354932551687,\n",
       "    0.3402563861075868,\n",
       "    0.3401060232456694,\n",
       "    0.33966492794929665,\n",
       "    0.3394714537453144,\n",
       "    0.33923255243199935,\n",
       "    0.33927058393650866,\n",
       "    0.33889198525154846,\n",
       "    0.3391749120773153,\n",
       "    0.3391966751281251,\n",
       "    0.3390194070466021,\n",
       "    0.33902324025935315,\n",
       "    0.33868295043072805,\n",
       "    0.33858900216031584,\n",
       "    0.3385676014296552,\n",
       "    0.33908259868621826,\n",
       "    0.33853782986072783,\n",
       "    0.33867158642474643,\n",
       "    0.3391700326762301,\n",
       "    0.338777501215326,\n",
       "    0.3385911098186006,\n",
       "    0.3385838270187378],\n",
       "   'test_loss': [0.0021299617737531662,\n",
       "    0.0018770494043827057,\n",
       "    0.0017664956927299499,\n",
       "    0.00170502832531929,\n",
       "    0.0016779318779706954,\n",
       "    0.0016432524025440215,\n",
       "    0.001613846480846405,\n",
       "    0.0016041735917329788,\n",
       "    0.0015830385625362395,\n",
       "    0.001583762091398239,\n",
       "    0.0015737605273723602,\n",
       "    0.0015597679033875465,\n",
       "    0.0015541478350758553,\n",
       "    0.0015496756717562675,\n",
       "    0.001546773062646389,\n",
       "    0.001545760963857174,\n",
       "    0.00154417062997818,\n",
       "    0.0015410242348909379,\n",
       "    0.0015401749417185784,\n",
       "    0.001539833900332451,\n",
       "    0.0015385782927274704,\n",
       "    0.0015378368243575097,\n",
       "    0.0015371807858347894,\n",
       "    0.0015368470147252083,\n",
       "    0.0015366981729865075,\n",
       "    0.0015362955749034881,\n",
       "    0.001536135971546173,\n",
       "    0.0015362065806984902,\n",
       "    0.001535981960594654,\n",
       "    0.0015358571901917457,\n",
       "    0.0015357933863997459,\n",
       "    0.0015357425779104232,\n",
       "    0.0015356744229793548,\n",
       "    0.0015356413036584854,\n",
       "    0.0015355978712439538,\n",
       "    0.001535572338104248,\n",
       "    0.0015355598822236062,\n",
       "    0.0015355423837900162,\n",
       "    0.0015355231821537019,\n",
       "    0.0015355136692523955],\n",
       "   'test_acc': [0.8081,\n",
       "    0.833,\n",
       "    0.8418,\n",
       "    0.8478,\n",
       "    0.8495,\n",
       "    0.8512,\n",
       "    0.855,\n",
       "    0.8575,\n",
       "    0.8594,\n",
       "    0.8579,\n",
       "    0.8575,\n",
       "    0.8601,\n",
       "    0.8607,\n",
       "    0.8617,\n",
       "    0.8616,\n",
       "    0.8625,\n",
       "    0.8622,\n",
       "    0.8622,\n",
       "    0.8623,\n",
       "    0.8629,\n",
       "    0.8622,\n",
       "    0.862,\n",
       "    0.8626,\n",
       "    0.8629,\n",
       "    0.8625,\n",
       "    0.8625,\n",
       "    0.8624,\n",
       "    0.8624,\n",
       "    0.8625,\n",
       "    0.8628,\n",
       "    0.8628,\n",
       "    0.8627,\n",
       "    0.8627,\n",
       "    0.8628,\n",
       "    0.8627,\n",
       "    0.8627,\n",
       "    0.8627,\n",
       "    0.8627,\n",
       "    0.8627,\n",
       "    0.8627]},\n",
       "  'train_time': 70.56811594963074},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 64, 10],\n",
       "  'num_params': (406528, 406528),\n",
       "  'train_result': {'train_loss': [0.7228194007214079,\n",
       "    0.45736427345174424,\n",
       "    0.4179276683229081,\n",
       "    0.3927201564007617,\n",
       "    0.37635298320587646,\n",
       "    0.36354438548392437,\n",
       "    0.3541531548221061,\n",
       "    0.346066847253353,\n",
       "    0.3414272884739206,\n",
       "    0.33680860127540346,\n",
       "    0.3332734298198781,\n",
       "    0.3307828614052306,\n",
       "    0.3278263160522948,\n",
       "    0.326137664850722,\n",
       "    0.32475614909161915,\n",
       "    0.32346857335973295,\n",
       "    0.32296582016539066,\n",
       "    0.32172937843393773,\n",
       "    0.32118460612094146,\n",
       "    0.3207434545806114,\n",
       "    0.32049344613197,\n",
       "    0.320123464566596,\n",
       "    0.32016992029991553,\n",
       "    0.3195877712457738,\n",
       "    0.3194492813754589,\n",
       "    0.3194876803362623,\n",
       "    0.3193362892942226,\n",
       "    0.31944460361561877,\n",
       "    0.3193455058843532,\n",
       "    0.3191320468770697,\n",
       "    0.31892791428464523,\n",
       "    0.318997973520705,\n",
       "    0.3189646265608199,\n",
       "    0.3188533841929537,\n",
       "    0.31918694972991946,\n",
       "    0.31904864786787235,\n",
       "    0.3192559393162423,\n",
       "    0.3188936317854739,\n",
       "    0.31894042447526405,\n",
       "    0.31923034894973673],\n",
       "   'test_loss': [0.002022271701693535,\n",
       "    0.0018640360891819,\n",
       "    0.001748456996679306,\n",
       "    0.0016607482016086578,\n",
       "    0.0016317390874028205,\n",
       "    0.0016021769598126411,\n",
       "    0.0015657131031155587,\n",
       "    0.0015482631370425225,\n",
       "    0.0015392455235123635,\n",
       "    0.0015248094260692598,\n",
       "    0.0015157693952322006,\n",
       "    0.0015039323210716247,\n",
       "    0.001505177791416645,\n",
       "    0.00149468332529068,\n",
       "    0.0014923639178276063,\n",
       "    0.0014899490609765053,\n",
       "    0.0014874344006180764,\n",
       "    0.0014859695747494698,\n",
       "    0.0014855325937271119,\n",
       "    0.0014836222440004349,\n",
       "    0.0014824981436133385,\n",
       "    0.0014827201873064042,\n",
       "    0.0014817557767033576,\n",
       "    0.00148088291734457,\n",
       "    0.00148067417293787,\n",
       "    0.001480333250761032,\n",
       "    0.0014801553398370742,\n",
       "    0.0014801290422677995,\n",
       "    0.0014798246636986733,\n",
       "    0.00147971101552248,\n",
       "    0.001479646910727024,\n",
       "    0.0014795823186635971,\n",
       "    0.001479544833302498,\n",
       "    0.0014795138016343117,\n",
       "    0.0014794798970222474,\n",
       "    0.0014794543012976646,\n",
       "    0.0014794177249073982,\n",
       "    0.001479414440691471,\n",
       "    0.0014794010907411576,\n",
       "    0.00147939041107893],\n",
       "   'test_acc': [0.8194,\n",
       "    0.8292,\n",
       "    0.8432,\n",
       "    0.8494,\n",
       "    0.8543,\n",
       "    0.8543,\n",
       "    0.8601,\n",
       "    0.8613,\n",
       "    0.8609,\n",
       "    0.8636,\n",
       "    0.8634,\n",
       "    0.8642,\n",
       "    0.8641,\n",
       "    0.8659,\n",
       "    0.8658,\n",
       "    0.8669,\n",
       "    0.8656,\n",
       "    0.8666,\n",
       "    0.8663,\n",
       "    0.8675,\n",
       "    0.867,\n",
       "    0.8654,\n",
       "    0.8669,\n",
       "    0.8671,\n",
       "    0.8673,\n",
       "    0.8676,\n",
       "    0.8673,\n",
       "    0.8672,\n",
       "    0.8673,\n",
       "    0.8672,\n",
       "    0.8672,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675,\n",
       "    0.8675]},\n",
       "  'train_time': 67.23344850540161},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 128, 10],\n",
       "  'num_params': (813056, 813056),\n",
       "  'train_result': {'train_loss': [0.6675438790879351,\n",
       "    0.44253634100264694,\n",
       "    0.39987122391132596,\n",
       "    0.37626387927126376,\n",
       "    0.3597527834963291,\n",
       "    0.34347947772513043,\n",
       "    0.3338434453340287,\n",
       "    0.325579464308759,\n",
       "    0.3196106118090609,\n",
       "    0.31407373186121595,\n",
       "    0.3092374878994962,\n",
       "    0.3067238412638928,\n",
       "    0.3040912534962309,\n",
       "    0.30203201948328223,\n",
       "    0.3003495031214775,\n",
       "    0.2987781954572556,\n",
       "    0.29775381107279597,\n",
       "    0.2968927898305528,\n",
       "    0.29598438644662817,\n",
       "    0.29599380645346135,\n",
       "    0.2950377287382775,\n",
       "    0.2945295089736898,\n",
       "    0.2945433629320023,\n",
       "    0.2943960816302198,\n",
       "    0.29418202346943795,\n",
       "    0.29404433889591947,\n",
       "    0.2937903916582148,\n",
       "    0.2938282180973824,\n",
       "    0.29369890043076047,\n",
       "    0.2934415467876069,\n",
       "    0.29333869700736187,\n",
       "    0.29340435507449697,\n",
       "    0.2934088602345041,\n",
       "    0.29393992145010767,\n",
       "    0.29350597795019756,\n",
       "    0.29349425035588284,\n",
       "    0.29370652779619744,\n",
       "    0.2935842378976497,\n",
       "    0.29322254784563756,\n",
       "    0.2933125620826762],\n",
       "   'test_loss': [0.0020631087869405745,\n",
       "    0.0017955889940261842,\n",
       "    0.001698513036966324,\n",
       "    0.0015944561272859573,\n",
       "    0.0015729211896657943,\n",
       "    0.0015314579665660858,\n",
       "    0.0014973815128207207,\n",
       "    0.0014747659415006637,\n",
       "    0.0014579701527953149,\n",
       "    0.0014479292988777161,\n",
       "    0.0014435911133885383,\n",
       "    0.0014425172120332717,\n",
       "    0.001422615347802639,\n",
       "    0.0014206990092992782,\n",
       "    0.0014152889370918273,\n",
       "    0.0014121173590421676,\n",
       "    0.0014112643897533418,\n",
       "    0.001408391483128071,\n",
       "    0.0014060355380177498,\n",
       "    0.0014050397083163262,\n",
       "    0.0014043311536312104,\n",
       "    0.0014032910853624344,\n",
       "    0.0014026349395513534,\n",
       "    0.0014027954906225203,\n",
       "    0.0014023254036903382,\n",
       "    0.0014023631602525712,\n",
       "    0.0014018054351210595,\n",
       "    0.0014014268696308136,\n",
       "    0.0014015482798218728,\n",
       "    0.0014013800397515298,\n",
       "    0.0014011937230825424,\n",
       "    0.001401129986345768,\n",
       "    0.001401094964146614,\n",
       "    0.0014010242059826852,\n",
       "    0.001400990104675293,\n",
       "    0.0014009477198123931,\n",
       "    0.0014009188383817673,\n",
       "    0.0014009027600288392,\n",
       "    0.0014008863151073457,\n",
       "    0.0014008742943406106],\n",
       "   'test_acc': [0.8216,\n",
       "    0.8411,\n",
       "    0.8469,\n",
       "    0.8565,\n",
       "    0.858,\n",
       "    0.8616,\n",
       "    0.8643,\n",
       "    0.8682,\n",
       "    0.8691,\n",
       "    0.8696,\n",
       "    0.8699,\n",
       "    0.8684,\n",
       "    0.8709,\n",
       "    0.8701,\n",
       "    0.872,\n",
       "    0.8725,\n",
       "    0.871,\n",
       "    0.871,\n",
       "    0.873,\n",
       "    0.8725,\n",
       "    0.8724,\n",
       "    0.8726,\n",
       "    0.8723,\n",
       "    0.8727,\n",
       "    0.8727,\n",
       "    0.8725,\n",
       "    0.8733,\n",
       "    0.8731,\n",
       "    0.8729,\n",
       "    0.8732,\n",
       "    0.8733,\n",
       "    0.8731,\n",
       "    0.8731,\n",
       "    0.8732,\n",
       "    0.8732,\n",
       "    0.8732,\n",
       "    0.873,\n",
       "    0.8731,\n",
       "    0.8731,\n",
       "    0.8731]},\n",
       "  'train_time': 65.37789392471313},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 32, 32, 10],\n",
       "  'num_params': (211456, 211456),\n",
       "  'train_result': {'train_loss': [0.8404583782591718,\n",
       "    0.47580464723262383,\n",
       "    0.4263102087568729,\n",
       "    0.40107324009246015,\n",
       "    0.38495770198233586,\n",
       "    0.3720916726487748,\n",
       "    0.3644171171999992,\n",
       "    0.35695974636585154,\n",
       "    0.35157419075357155,\n",
       "    0.34748781393183037,\n",
       "    0.34396242765670126,\n",
       "    0.3414160526179253,\n",
       "    0.33986643698621305,\n",
       "    0.33788308209561285,\n",
       "    0.3367811782562986,\n",
       "    0.3355663602656506,\n",
       "    0.3346545438183115,\n",
       "    0.33407136189176684,\n",
       "    0.3337919256788619,\n",
       "    0.33343046783132757,\n",
       "    0.33284099216156815,\n",
       "    0.33261509360151087,\n",
       "    0.3322910620177046,\n",
       "    0.33245884516137714,\n",
       "    0.33207412324053176,\n",
       "    0.33177224124999755,\n",
       "    0.33172019003553593,\n",
       "    0.3323638673792494,\n",
       "    0.3319986896946075,\n",
       "    0.3313847038974153,\n",
       "    0.33163800328335863,\n",
       "    0.331464724337801,\n",
       "    0.33138114518307626,\n",
       "    0.33152887529515207,\n",
       "    0.3311061021495373,\n",
       "    0.33148682142825836,\n",
       "    0.3316075039670823,\n",
       "    0.3313906882037508,\n",
       "    0.3313719327779526,\n",
       "    0.3315492434704557],\n",
       "   'test_loss': [0.002126893216371536,\n",
       "    0.0018651416182518005,\n",
       "    0.0017632890671491622,\n",
       "    0.0017221739202737808,\n",
       "    0.0016545465409755708,\n",
       "    0.0016169663161039352,\n",
       "    0.0016075147926807403,\n",
       "    0.0015781591206789018,\n",
       "    0.0015676024079322815,\n",
       "    0.0015598848849534988,\n",
       "    0.0015481014788150788,\n",
       "    0.0015406812518835068,\n",
       "    0.0015350574672222137,\n",
       "    0.0015331046283245087,\n",
       "    0.0015309994280338288,\n",
       "    0.00152739597260952,\n",
       "    0.0015243793666362762,\n",
       "    0.0015228610932826996,\n",
       "    0.0015236319690942765,\n",
       "    0.0015210646867752076,\n",
       "    0.0015202964872121812,\n",
       "    0.0015192178040742874,\n",
       "    0.0015192882299423218,\n",
       "    0.001518423855304718,\n",
       "    0.0015183807134628296,\n",
       "    0.0015180153846740723,\n",
       "    0.0015178797632455826,\n",
       "    0.0015177853763103486,\n",
       "    0.001517580869793892,\n",
       "    0.0015175283014774322,\n",
       "    0.0015174250930547713,\n",
       "    0.0015173873275518418,\n",
       "    0.0015173128038644791,\n",
       "    0.001517276692390442,\n",
       "    0.0015172372043132782,\n",
       "    0.0015172268956899642,\n",
       "    0.0015172160178422928,\n",
       "    0.0015171906381845474,\n",
       "    0.0015171803385019302,\n",
       "    0.001517167866230011],\n",
       "   'test_acc': [0.8056,\n",
       "    0.8313,\n",
       "    0.8393,\n",
       "    0.8468,\n",
       "    0.8507,\n",
       "    0.8525,\n",
       "    0.8545,\n",
       "    0.8563,\n",
       "    0.859,\n",
       "    0.859,\n",
       "    0.8602,\n",
       "    0.8624,\n",
       "    0.862,\n",
       "    0.8622,\n",
       "    0.8625,\n",
       "    0.8633,\n",
       "    0.8634,\n",
       "    0.8639,\n",
       "    0.863,\n",
       "    0.8636,\n",
       "    0.8633,\n",
       "    0.8639,\n",
       "    0.8637,\n",
       "    0.864,\n",
       "    0.8639,\n",
       "    0.8645,\n",
       "    0.8644,\n",
       "    0.8642,\n",
       "    0.8642,\n",
       "    0.8643,\n",
       "    0.8642,\n",
       "    0.8642,\n",
       "    0.8645,\n",
       "    0.8643,\n",
       "    0.8644,\n",
       "    0.8643,\n",
       "    0.8644,\n",
       "    0.8644,\n",
       "    0.8644,\n",
       "    0.8645]},\n",
       "  'train_time': 83.26506209373474},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 64, 64, 10],\n",
       "  'num_params': (439296, 439296),\n",
       "  'train_result': {'train_loss': [0.7378133168879976,\n",
       "    0.4308387273169578,\n",
       "    0.38579333094840357,\n",
       "    0.3596011539723011,\n",
       "    0.3435759350974509,\n",
       "    0.32854013214720057,\n",
       "    0.31901183610266826,\n",
       "    0.31127459914126293,\n",
       "    0.30480039233857015,\n",
       "    0.29967202062302445,\n",
       "    0.2958059497336124,\n",
       "    0.2929586190492549,\n",
       "    0.2909314792206947,\n",
       "    0.2888083231575946,\n",
       "    0.28705660491547685,\n",
       "    0.28592312012581117,\n",
       "    0.28473919655414337,\n",
       "    0.28402674889310875,\n",
       "    0.283290563238428,\n",
       "    0.2826975086267958,\n",
       "    0.28225663716488697,\n",
       "    0.2820920043803276,\n",
       "    0.2813797335675422,\n",
       "    0.2815787130213798,\n",
       "    0.28118353860175355,\n",
       "    0.28117733718232907,\n",
       "    0.2808454601688588,\n",
       "    0.2807535669270982,\n",
       "    0.28080469636206934,\n",
       "    0.2806451253434445,\n",
       "    0.28053717619561136,\n",
       "    0.28069046444081247,\n",
       "    0.2805108471119657,\n",
       "    0.2804544786823557,\n",
       "    0.28030821655658966,\n",
       "    0.28057281368590414,\n",
       "    0.28031621004672763,\n",
       "    0.2805446158698265,\n",
       "    0.28044322056973237,\n",
       "    0.28055160159760334],\n",
       "   'test_loss': [0.0019640578120946883,\n",
       "    0.001698355197906494,\n",
       "    0.0016264896720647813,\n",
       "    0.0015356167718768119,\n",
       "    0.0015065556421875953,\n",
       "    0.0014696637481451036,\n",
       "    0.0014627801567316055,\n",
       "    0.0014162231132388114,\n",
       "    0.0014143225729465485,\n",
       "    0.0013940806210041047,\n",
       "    0.001395776577293873,\n",
       "    0.001385453774034977,\n",
       "    0.0013871794059872628,\n",
       "    0.0013737359583377838,\n",
       "    0.0013722244083881378,\n",
       "    0.0013701083168387413,\n",
       "    0.0013657012179493905,\n",
       "    0.0013654531583189963,\n",
       "    0.0013635441169142723,\n",
       "    0.0013630847692489624,\n",
       "    0.0013638036623597144,\n",
       "    0.0013608993038535118,\n",
       "    0.0013607217594981194,\n",
       "    0.0013603545978665352,\n",
       "    0.0013602671146392823,\n",
       "    0.0013602686688303947,\n",
       "    0.0013598642602562904,\n",
       "    0.0013597392618656158,\n",
       "    0.0013596070006489753,\n",
       "    0.001359503448009491,\n",
       "    0.0013594892472028732,\n",
       "    0.00135950248837471,\n",
       "    0.0013594432026147842,\n",
       "    0.001359377157688141,\n",
       "    0.0013593247249722481,\n",
       "    0.001359330327808857,\n",
       "    0.0013592940673232078,\n",
       "    0.0013592770636081696,\n",
       "    0.0013592695757746697,\n",
       "    0.0013592549845576286],\n",
       "   'test_acc': [0.82,\n",
       "    0.8468,\n",
       "    0.852,\n",
       "    0.8615,\n",
       "    0.8659,\n",
       "    0.8685,\n",
       "    0.8692,\n",
       "    0.8738,\n",
       "    0.8728,\n",
       "    0.8754,\n",
       "    0.8756,\n",
       "    0.8766,\n",
       "    0.8751,\n",
       "    0.8768,\n",
       "    0.8765,\n",
       "    0.8764,\n",
       "    0.8758,\n",
       "    0.8775,\n",
       "    0.878,\n",
       "    0.8774,\n",
       "    0.8752,\n",
       "    0.8772,\n",
       "    0.8769,\n",
       "    0.8774,\n",
       "    0.8776,\n",
       "    0.8772,\n",
       "    0.877,\n",
       "    0.877,\n",
       "    0.877,\n",
       "    0.8774,\n",
       "    0.8769,\n",
       "    0.8768,\n",
       "    0.8769,\n",
       "    0.8771,\n",
       "    0.8771,\n",
       "    0.8771,\n",
       "    0.8773,\n",
       "    0.8772,\n",
       "    0.8771,\n",
       "    0.8771]},\n",
       "  'train_time': 81.20583653450012},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 0,\n",
       "  'num_params': (55244, 55244),\n",
       "  'train_result': {'train_loss': [0.7129807071482882,\n",
       "    0.44731754102605453,\n",
       "    0.40887845374168236,\n",
       "    0.3862087499588094,\n",
       "    0.3725392219868112,\n",
       "    0.3623921499607411,\n",
       "    0.3550905715911946,\n",
       "    0.34948047215634204,\n",
       "    0.3453462490376006,\n",
       "    0.341380224012314,\n",
       "    0.339678460232755,\n",
       "    0.33711934609616057,\n",
       "    0.3362428013948684,\n",
       "    0.33411775783021397,\n",
       "    0.33350004547453943,\n",
       "    0.33223853212721804,\n",
       "    0.3319010258355039,\n",
       "    0.3311823492354535,\n",
       "    0.33113345662330057,\n",
       "    0.3306357350755245,\n",
       "    0.3305479839761206,\n",
       "    0.3303787128722414,\n",
       "    0.3297442926371351,\n",
       "    0.32980256974697114,\n",
       "    0.32955739942002804,\n",
       "    0.3294056428873793,\n",
       "    0.3294046041813303,\n",
       "    0.32907421113328733,\n",
       "    0.32931234880964805,\n",
       "    0.32912963349768454,\n",
       "    0.32953840278564617,\n",
       "    0.3291841297073567,\n",
       "    0.3292886752397456,\n",
       "    0.3289799111320617,\n",
       "    0.32923675731141516,\n",
       "    0.3290360207253314,\n",
       "    0.32928631755899873,\n",
       "    0.32877354697978245,\n",
       "    0.32886229683744145,\n",
       "    0.32945737515358214],\n",
       "   'test_loss': [0.0019980394929647446,\n",
       "    0.001744228881597519,\n",
       "    0.0016850912302732468,\n",
       "    0.0016285414054989815,\n",
       "    0.0015590372502803803,\n",
       "    0.0015167168632149695,\n",
       "    0.0014951463103294372,\n",
       "    0.0014688471615314483,\n",
       "    0.0014590469658374787,\n",
       "    0.0014636227786540986,\n",
       "    0.001461150474846363,\n",
       "    0.001437236176431179,\n",
       "    0.001439114148914814,\n",
       "    0.001429105657339096,\n",
       "    0.0014283156424760818,\n",
       "    0.0014252672359347344,\n",
       "    0.0014236355647444725,\n",
       "    0.0014227958604693413,\n",
       "    0.0014203007251024247,\n",
       "    0.001419259637594223,\n",
       "    0.001419292563199997,\n",
       "    0.0014181269332766532,\n",
       "    0.0014178854048252105,\n",
       "    0.0014182665273547172,\n",
       "    0.0014177625805139541,\n",
       "    0.0014170562699437142,\n",
       "    0.0014169557988643645,\n",
       "    0.0014167341336607934,\n",
       "    0.0014169196128845216,\n",
       "    0.00141674425303936,\n",
       "    0.0014165453121066094,\n",
       "    0.0014165362671017647,\n",
       "    0.001416522081196308,\n",
       "    0.001416469207406044,\n",
       "    0.0014164493575692177,\n",
       "    0.0014164077028632164,\n",
       "    0.0014164014354348183,\n",
       "    0.0014163807362318039,\n",
       "    0.0014163555905222893,\n",
       "    0.0014163575425744056],\n",
       "   'test_acc': [0.8185,\n",
       "    0.8426,\n",
       "    0.8502,\n",
       "    0.853,\n",
       "    0.8581,\n",
       "    0.8632,\n",
       "    0.8663,\n",
       "    0.8674,\n",
       "    0.8687,\n",
       "    0.8679,\n",
       "    0.867,\n",
       "    0.8703,\n",
       "    0.8708,\n",
       "    0.8724,\n",
       "    0.8709,\n",
       "    0.8717,\n",
       "    0.8704,\n",
       "    0.8717,\n",
       "    0.8731,\n",
       "    0.8727,\n",
       "    0.872,\n",
       "    0.8729,\n",
       "    0.8732,\n",
       "    0.8725,\n",
       "    0.8722,\n",
       "    0.8727,\n",
       "    0.8728,\n",
       "    0.8727,\n",
       "    0.873,\n",
       "    0.8728,\n",
       "    0.8729,\n",
       "    0.8727,\n",
       "    0.8727,\n",
       "    0.8728,\n",
       "    0.873,\n",
       "    0.8729,\n",
       "    0.8729,\n",
       "    0.873,\n",
       "    0.873,\n",
       "    0.873]},\n",
       "  'train_time': 602.0037631988525},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 1,\n",
       "  'num_params': (41614, 41614),\n",
       "  'train_result': {'train_loss': [0.8424539237580401,\n",
       "    0.4976853218484432,\n",
       "    0.4502199873011163,\n",
       "    0.42820187350536915,\n",
       "    0.41171813011169434,\n",
       "    0.40042417493272336,\n",
       "    0.3917159194641925,\n",
       "    0.3861875615221389,\n",
       "    0.38150538694351277,\n",
       "    0.3768464210819691,\n",
       "    0.3742738146731194,\n",
       "    0.3719356848204389,\n",
       "    0.3695502722516973,\n",
       "    0.3679934187772426,\n",
       "    0.36731365652794534,\n",
       "    0.36599957581530224,\n",
       "    0.36532024113421746,\n",
       "    0.3647904512730051,\n",
       "    0.3642496739930295,\n",
       "    0.36379259748661774,\n",
       "    0.36290516885037116,\n",
       "    0.36317926651619853,\n",
       "    0.3626373176244979,\n",
       "    0.3627083538694585,\n",
       "    0.36243438809476003,\n",
       "    0.362473640796986,\n",
       "    0.362450288331255,\n",
       "    0.3625800156212868,\n",
       "    0.36241142749786376,\n",
       "    0.362240066553684,\n",
       "    0.3618413671534112,\n",
       "    0.3618170029305397,\n",
       "    0.36178199262061017,\n",
       "    0.3618988811969757,\n",
       "    0.36247995825524026,\n",
       "    0.36270826401862694,\n",
       "    0.36189466917768437,\n",
       "    0.3620627258052217,\n",
       "    0.36197711546370326,\n",
       "    0.36181240474924126],\n",
       "   'test_loss': [0.002193940478563309,\n",
       "    0.001896684731543064,\n",
       "    0.0017934409067034722,\n",
       "    0.00171077651232481,\n",
       "    0.0016789287641644478,\n",
       "    0.0016389429196715355,\n",
       "    0.0016414038881659508,\n",
       "    0.0016144370526075364,\n",
       "    0.0016037376165390015,\n",
       "    0.0015754983097314836,\n",
       "    0.001581898982822895,\n",
       "    0.0015601018220186232,\n",
       "    0.0015613230615854263,\n",
       "    0.0015700551480054856,\n",
       "    0.001550211736559868,\n",
       "    0.0015455587550997733,\n",
       "    0.0015461159959435462,\n",
       "    0.0015440924108028411,\n",
       "    0.0015419638991355897,\n",
       "    0.0015409388542175293,\n",
       "    0.0015418855503201484,\n",
       "    0.0015407407820224762,\n",
       "    0.0015394089430570603,\n",
       "    0.001538944585621357,\n",
       "    0.0015385914757847785,\n",
       "    0.001538911947607994,\n",
       "    0.001537563180923462,\n",
       "    0.0015375995248556138,\n",
       "    0.0015376194074749946,\n",
       "    0.0015374464690685271,\n",
       "    0.0015372996479272843,\n",
       "    0.0015372779101133346,\n",
       "    0.0015372588098049164,\n",
       "    0.001537218289077282,\n",
       "    0.0015372039124369621,\n",
       "    0.001537201528251171,\n",
       "    0.0015371787011623382,\n",
       "    0.0015371564507484436,\n",
       "    0.0015371433466672896,\n",
       "    0.001537139144539833],\n",
       "   'test_acc': [0.7906,\n",
       "    0.8211,\n",
       "    0.8349,\n",
       "    0.8423,\n",
       "    0.8477,\n",
       "    0.8519,\n",
       "    0.8489,\n",
       "    0.8525,\n",
       "    0.8542,\n",
       "    0.8579,\n",
       "    0.8563,\n",
       "    0.8613,\n",
       "    0.8598,\n",
       "    0.8595,\n",
       "    0.8605,\n",
       "    0.8613,\n",
       "    0.8621,\n",
       "    0.8614,\n",
       "    0.8618,\n",
       "    0.8608,\n",
       "    0.8617,\n",
       "    0.8615,\n",
       "    0.8612,\n",
       "    0.8613,\n",
       "    0.8611,\n",
       "    0.8611,\n",
       "    0.8614,\n",
       "    0.8616,\n",
       "    0.8612,\n",
       "    0.8615,\n",
       "    0.8612,\n",
       "    0.861,\n",
       "    0.8611,\n",
       "    0.8614,\n",
       "    0.8613,\n",
       "    0.8614,\n",
       "    0.8614,\n",
       "    0.8611,\n",
       "    0.8612,\n",
       "    0.8613]},\n",
       "  'train_time': 2011.3804113864899},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 2,\n",
       "  'num_params': (94650, 94650),\n",
       "  'train_result': {'train_loss': [0.9637355647188552,\n",
       "    0.4382653902185724,\n",
       "    0.37658720745685254,\n",
       "    0.3489212471119901,\n",
       "    0.3306910068430799,\n",
       "    0.3187578487903514,\n",
       "    0.3108279247233208,\n",
       "    0.3041319546547342,\n",
       "    0.29981425563071634,\n",
       "    0.2960632669798871,\n",
       "    0.293353947933684,\n",
       "    0.2911879576901172,\n",
       "    0.2891512322299024,\n",
       "    0.2879890598515247,\n",
       "    0.2867724896111387,\n",
       "    0.2861003911241572,\n",
       "    0.28550036378363347,\n",
       "    0.2851115136704546,\n",
       "    0.28402898210160277,\n",
       "    0.28407503803993794,\n",
       "    0.28368763035916267,\n",
       "    0.283379076960239,\n",
       "    0.2834674904321102,\n",
       "    0.2833154484312585,\n",
       "    0.2833378309899188,\n",
       "    0.283293547084991,\n",
       "    0.28285567773149367,\n",
       "    0.28282929868140116,\n",
       "    0.28311829788887755,\n",
       "    0.2829060642643178,\n",
       "    0.2827436124390744,\n",
       "    0.2825706656942976,\n",
       "    0.28261309545090857,\n",
       "    0.28310865246235056,\n",
       "    0.28252626397508257,\n",
       "    0.2827815816757527,\n",
       "    0.2829310927619325,\n",
       "    0.2825411509326164,\n",
       "    0.28313572850633173,\n",
       "    0.2827427550833276],\n",
       "   'test_loss': [0.0020737308084964753,\n",
       "    0.0016791779726743699,\n",
       "    0.0015636368215084075,\n",
       "    0.0014727376729249955,\n",
       "    0.0014244525536894798,\n",
       "    0.0013921365559101105,\n",
       "    0.0013652566403150558,\n",
       "    0.0013527571946382524,\n",
       "    0.0013380086496472359,\n",
       "    0.00132972454726696,\n",
       "    0.0013231331661343573,\n",
       "    0.0013190267235040664,\n",
       "    0.0013132677167654037,\n",
       "    0.0013107466846704484,\n",
       "    0.001309030820429325,\n",
       "    0.0013054827749729157,\n",
       "    0.0013046886771917344,\n",
       "    0.001303248444199562,\n",
       "    0.00130247732847929,\n",
       "    0.0013017422109842301,\n",
       "    0.0013009004175662995,\n",
       "    0.0013001346781849861,\n",
       "    0.0012997188970446587,\n",
       "    0.0012994279459118843,\n",
       "    0.001299252162873745,\n",
       "    0.0012991324841976166,\n",
       "    0.0012988678321242332,\n",
       "    0.0012987154141068458,\n",
       "    0.0012986254245042801,\n",
       "    0.0012985310286283494,\n",
       "    0.0012984719410538673,\n",
       "    0.0012984325006604196,\n",
       "    0.0012983852460980415,\n",
       "    0.0012983581617474556,\n",
       "    0.0012983261227607727,\n",
       "    0.0012983122006058692,\n",
       "    0.001298291827738285,\n",
       "    0.001298279371857643,\n",
       "    0.0012982696250081061,\n",
       "    0.0012982593923807145],\n",
       "   'test_acc': [0.8082,\n",
       "    0.8506,\n",
       "    0.8577,\n",
       "    0.8688,\n",
       "    0.8733,\n",
       "    0.8752,\n",
       "    0.8779,\n",
       "    0.8793,\n",
       "    0.8795,\n",
       "    0.8813,\n",
       "    0.8817,\n",
       "    0.8817,\n",
       "    0.8821,\n",
       "    0.8829,\n",
       "    0.8827,\n",
       "    0.8824,\n",
       "    0.8834,\n",
       "    0.8833,\n",
       "    0.8843,\n",
       "    0.8839,\n",
       "    0.8836,\n",
       "    0.8837,\n",
       "    0.8834,\n",
       "    0.8834,\n",
       "    0.8836,\n",
       "    0.8837,\n",
       "    0.8838,\n",
       "    0.8836,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838,\n",
       "    0.8838]},\n",
       "  'train_time': 2056.061446905136},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 10],\n",
       "  'num_params': (7850, 7850),\n",
       "  'train_result': {'train_loss': [0.8434166887973217,\n",
       "    0.5674711319994419,\n",
       "    0.5196124700789756,\n",
       "    0.4957909378599613,\n",
       "    0.48161747671188193,\n",
       "    0.47193148148820757,\n",
       "    0.4656018206413756,\n",
       "    0.46048743851641394,\n",
       "    0.45676489599207615,\n",
       "    0.45359659651492507,\n",
       "    0.4513568932705737,\n",
       "    0.4499063035275074,\n",
       "    0.4487111639469228,\n",
       "    0.44787907930130655,\n",
       "    0.44676311383856104,\n",
       "    0.44562168197428925,\n",
       "    0.4449562599050238,\n",
       "    0.4450798691587245,\n",
       "    0.4443032017413606,\n",
       "    0.44425149496565475,\n",
       "    0.44391569254246166,\n",
       "    0.4436749132389718,\n",
       "    0.44381667185336987,\n",
       "    0.4433322692171056,\n",
       "    0.4435976997334906,\n",
       "    0.4433428709811353,\n",
       "    0.44332095080233636,\n",
       "    0.4434941460477545,\n",
       "    0.44326795238129635,\n",
       "    0.4431139087423365,\n",
       "    0.44317630770358635,\n",
       "    0.44299015377430206,\n",
       "    0.4432503185373671,\n",
       "    0.44262879719125464,\n",
       "    0.4431976431227745,\n",
       "    0.4429953136342637,\n",
       "    0.44317123572877115,\n",
       "    0.44290284108608324,\n",
       "    0.44289232796811046,\n",
       "    0.4430242141510578],\n",
       "   'test_loss': [0.002486234727501869,\n",
       "    0.00221692051589489,\n",
       "    0.0021091410636901856,\n",
       "    0.002047645750641823,\n",
       "    0.0020122750550508497,\n",
       "    0.001975638073682785,\n",
       "    0.001959404644370079,\n",
       "    0.0019447933971881866,\n",
       "    0.0019363548070192337,\n",
       "    0.0019286046773195266,\n",
       "    0.001921512019634247,\n",
       "    0.001915576308965683,\n",
       "    0.0019103778421878815,\n",
       "    0.001908090490102768,\n",
       "    0.0019055859357118606,\n",
       "    0.0019033015012741088,\n",
       "    0.0019022534877061845,\n",
       "    0.001901225969195366,\n",
       "    0.001900687149167061,\n",
       "    0.0018990878045558929,\n",
       "    0.001898631364107132,\n",
       "    0.0018982285559177399,\n",
       "    0.0018978151321411133,\n",
       "    0.0018975358217954636,\n",
       "    0.0018972386986017228,\n",
       "    0.0018970417708158492,\n",
       "    0.001896838355064392,\n",
       "    0.0018967534750699998,\n",
       "    0.001896635702252388,\n",
       "    0.0018965582877397537,\n",
       "    0.0018964991569519042,\n",
       "    0.0018964351177215577,\n",
       "    0.001896401470899582,\n",
       "    0.0018963606238365173,\n",
       "    0.0018963406026363374,\n",
       "    0.0018963194251060485,\n",
       "    0.0018963020443916322,\n",
       "    0.0018962893307209014,\n",
       "    0.001896278065443039,\n",
       "    0.001896269702911377],\n",
       "   'test_acc': [0.7913,\n",
       "    0.8139,\n",
       "    0.8206,\n",
       "    0.8227,\n",
       "    0.8265,\n",
       "    0.8294,\n",
       "    0.8307,\n",
       "    0.8323,\n",
       "    0.8321,\n",
       "    0.8327,\n",
       "    0.8325,\n",
       "    0.8336,\n",
       "    0.8344,\n",
       "    0.8336,\n",
       "    0.8342,\n",
       "    0.8337,\n",
       "    0.8346,\n",
       "    0.8346,\n",
       "    0.8345,\n",
       "    0.8348,\n",
       "    0.835,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8353,\n",
       "    0.8352,\n",
       "    0.8352,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8352,\n",
       "    0.835,\n",
       "    0.8352,\n",
       "    0.8352,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8351,\n",
       "    0.8351]},\n",
       "  'train_time': 39.70387029647827},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 16, 10],\n",
       "  'num_params': (12730, 12730),\n",
       "  'train_result': {'train_loss': [0.9643630395544336,\n",
       "    0.5481892651699959,\n",
       "    0.4901119115504813,\n",
       "    0.46351753067463003,\n",
       "    0.4487633949898659,\n",
       "    0.43865833586834846,\n",
       "    0.4317768043026011,\n",
       "    0.4272040918786475,\n",
       "    0.4241619829167711,\n",
       "    0.42050659047796374,\n",
       "    0.41861471850821314,\n",
       "    0.41708016978933454,\n",
       "    0.4155658369368695,\n",
       "    0.41437505344127085,\n",
       "    0.41384893592367783,\n",
       "    0.4131345984783578,\n",
       "    0.41247908764697133,\n",
       "    0.41212217452678274,\n",
       "    0.41168308854103086,\n",
       "    0.41131697373187287,\n",
       "    0.4112891459718664,\n",
       "    0.41080119926878744,\n",
       "    0.41067142258299155,\n",
       "    0.4104475016289569,\n",
       "    0.4106231066774815,\n",
       "    0.41071326960908605,\n",
       "    0.41066407929075527,\n",
       "    0.4103912206406289,\n",
       "    0.41078926464344595,\n",
       "    0.4103486597537994,\n",
       "    0.41037798460493696,\n",
       "    0.4104693464776303,\n",
       "    0.4104722633006725,\n",
       "    0.41069075439838654,\n",
       "    0.4102641927435043,\n",
       "    0.41046601305616665,\n",
       "    0.41037278682627576,\n",
       "    0.41012859065481955,\n",
       "    0.4100145211879243,\n",
       "    0.41052379291108315],\n",
       "   'test_loss': [0.0025165964275598524,\n",
       "    0.0021290647566318513,\n",
       "    0.0019965127408504485,\n",
       "    0.0019159505516290665,\n",
       "    0.0018888434708118438,\n",
       "    0.0018548962593078614,\n",
       "    0.001835448130965233,\n",
       "    0.0018156213581562042,\n",
       "    0.001806148287653923,\n",
       "    0.0018008857697248458,\n",
       "    0.001792873987555504,\n",
       "    0.0017903103560209274,\n",
       "    0.0017859064251184464,\n",
       "    0.0017819258034229278,\n",
       "    0.0017791773796081542,\n",
       "    0.0017770137667655944,\n",
       "    0.0017752257883548736,\n",
       "    0.00177421852350235,\n",
       "    0.0017747409015893935,\n",
       "    0.0017727704226970674,\n",
       "    0.001772391065955162,\n",
       "    0.0017719693005084991,\n",
       "    0.0017715325891971589,\n",
       "    0.001771284320950508,\n",
       "    0.0017709898918867111,\n",
       "    0.0017708414673805236,\n",
       "    0.0017707354694604875,\n",
       "    0.0017706042379140854,\n",
       "    0.001770508337020874,\n",
       "    0.0017704372137784957,\n",
       "    0.0017703821837902068,\n",
       "    0.001770336964726448,\n",
       "    0.0017703035056591033,\n",
       "    0.0017702643007040024,\n",
       "    0.0017702412486076354,\n",
       "    0.0017702264845371246,\n",
       "    0.0017702096164226532,\n",
       "    0.0017701978594064712,\n",
       "    0.001770190539956093,\n",
       "    0.001770182853937149],\n",
       "   'test_acc': [0.7842,\n",
       "    0.8132,\n",
       "    0.8274,\n",
       "    0.8312,\n",
       "    0.8307,\n",
       "    0.837,\n",
       "    0.8358,\n",
       "    0.8403,\n",
       "    0.8396,\n",
       "    0.8408,\n",
       "    0.8409,\n",
       "    0.843,\n",
       "    0.8413,\n",
       "    0.8412,\n",
       "    0.8429,\n",
       "    0.8422,\n",
       "    0.8434,\n",
       "    0.8428,\n",
       "    0.8439,\n",
       "    0.8429,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.8432,\n",
       "    0.8433,\n",
       "    0.8432,\n",
       "    0.8431,\n",
       "    0.8433,\n",
       "    0.8432,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.8431,\n",
       "    0.8431,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843]},\n",
       "  'train_time': 42.671016216278076},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 32, 10],\n",
       "  'num_params': (25450, 25450),\n",
       "  'train_result': {'train_loss': [0.8279056273876353,\n",
       "    0.5101912038123354,\n",
       "    0.4679204411963199,\n",
       "    0.4479603392012576,\n",
       "    0.43595633988684795,\n",
       "    0.4268714875616926,\n",
       "    0.4220910130029029,\n",
       "    0.4179743464956892,\n",
       "    0.4143425136170489,\n",
       "    0.41218319497209915,\n",
       "    0.41029374700911503,\n",
       "    0.40869660517002676,\n",
       "    0.407036603511648,\n",
       "    0.40595657736697094,\n",
       "    0.4055311639258202,\n",
       "    0.40473924177758236,\n",
       "    0.4046157089953727,\n",
       "    0.4042060082263135,\n",
       "    0.403716264252967,\n",
       "    0.40306234410468567,\n",
       "    0.4031316801588586,\n",
       "    0.40338576474088306,\n",
       "    0.4029478520789045,\n",
       "    0.4031159261439709,\n",
       "    0.4028766503993501,\n",
       "    0.4030513791961873,\n",
       "    0.40248347203782264,\n",
       "    0.40285640549152457,\n",
       "    0.40275574592833824,\n",
       "    0.40259560460739946,\n",
       "    0.4026109813375676,\n",
       "    0.40266110808291333,\n",
       "    0.40262418934639466,\n",
       "    0.4026551242838515,\n",
       "    0.4023445265090212,\n",
       "    0.4026156053898182,\n",
       "    0.402572518460294,\n",
       "    0.40223254929197594,\n",
       "    0.4024521244333146,\n",
       "    0.40239789359113004],\n",
       "   'test_loss': [0.0022688707321882246,\n",
       "    0.001996867650747299,\n",
       "    0.0019277665585279466,\n",
       "    0.0018814010024070739,\n",
       "    0.0018431677907705306,\n",
       "    0.0018260760843753815,\n",
       "    0.0018062104016542434,\n",
       "    0.001796216517686844,\n",
       "    0.0017831607818603516,\n",
       "    0.0017827482134103775,\n",
       "    0.0017728267461061477,\n",
       "    0.0017692331701517105,\n",
       "    0.001769371047616005,\n",
       "    0.0017677921742200852,\n",
       "    0.001763035413622856,\n",
       "    0.0017641336917877198,\n",
       "    0.0017623163789510727,\n",
       "    0.0017600505888462066,\n",
       "    0.001759756815433502,\n",
       "    0.0017589645981788634,\n",
       "    0.0017585777789354325,\n",
       "    0.0017579940736293792,\n",
       "    0.0017579609036445618,\n",
       "    0.0017578496485948563,\n",
       "    0.001757476055622101,\n",
       "    0.001757320088148117,\n",
       "    0.0017571479618549346,\n",
       "    0.0017570424169301986,\n",
       "    0.0017569724559783936,\n",
       "    0.0017569003641605377,\n",
       "    0.0017568758606910705,\n",
       "    0.0017568542450666427,\n",
       "    0.0017568131595849992,\n",
       "    0.0017567879617214203,\n",
       "    0.0017567790061235428,\n",
       "    0.0017567644089460373,\n",
       "    0.0017567504703998565,\n",
       "    0.0017567425012588501,\n",
       "    0.0017567349702119828,\n",
       "    0.0017567281633615495],\n",
       "   'test_acc': [0.8021,\n",
       "    0.8265,\n",
       "    0.8303,\n",
       "    0.8323,\n",
       "    0.8358,\n",
       "    0.8354,\n",
       "    0.8373,\n",
       "    0.8381,\n",
       "    0.8393,\n",
       "    0.8414,\n",
       "    0.8406,\n",
       "    0.8412,\n",
       "    0.8406,\n",
       "    0.8417,\n",
       "    0.8426,\n",
       "    0.842,\n",
       "    0.8416,\n",
       "    0.8426,\n",
       "    0.843,\n",
       "    0.8426,\n",
       "    0.843,\n",
       "    0.8434,\n",
       "    0.843,\n",
       "    0.8429,\n",
       "    0.8432,\n",
       "    0.8431,\n",
       "    0.8429,\n",
       "    0.843,\n",
       "    0.8428,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843,\n",
       "    0.843]},\n",
       "  'train_time': 43.271278858184814},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 64, 10],\n",
       "  'num_params': (50890, 50890),\n",
       "  'train_result': {'train_loss': [0.7383614153303999,\n",
       "    0.4773859089993416,\n",
       "    0.4361341268458265,\n",
       "    0.41562905666675976,\n",
       "    0.4008261118797546,\n",
       "    0.39188941514238396,\n",
       "    0.38368260270737586,\n",
       "    0.37857619511320234,\n",
       "    0.3745771701665635,\n",
       "    0.37061660055150375,\n",
       "    0.36777422034994084,\n",
       "    0.3661033277815961,\n",
       "    0.36436609207315646,\n",
       "    0.36301013072754473,\n",
       "    0.3622650365880195,\n",
       "    0.36128709963027467,\n",
       "    0.36038993679462594,\n",
       "    0.35971617121645744,\n",
       "    0.35979088620936617,\n",
       "    0.35934176305507093,\n",
       "    0.35890060701268783,\n",
       "    0.3587954507229176,\n",
       "    0.35835600095860504,\n",
       "    0.3585252637558795,\n",
       "    0.35847008012710735,\n",
       "    0.3580840583811415,\n",
       "    0.35802212801385436,\n",
       "    0.3581766798141155,\n",
       "    0.35823265263374815,\n",
       "    0.3579058567260174,\n",
       "    0.35813960325210653,\n",
       "    0.3581971602871063,\n",
       "    0.3576535825399642,\n",
       "    0.35761669436667826,\n",
       "    0.3577220410742658,\n",
       "    0.35759691291667045,\n",
       "    0.3575500648706517,\n",
       "    0.3578944837793391,\n",
       "    0.35791725389500884,\n",
       "    0.35792812806494695],\n",
       "   'test_loss': [0.002123192062973976,\n",
       "    0.0019221156239509582,\n",
       "    0.0018193437784910203,\n",
       "    0.001756036177277565,\n",
       "    0.0017083090901374818,\n",
       "    0.0016938080817461014,\n",
       "    0.0016619824290275574,\n",
       "    0.0016536847442388534,\n",
       "    0.0016488156020641328,\n",
       "    0.0016331460237503051,\n",
       "    0.0016254968583583832,\n",
       "    0.0016221971541643143,\n",
       "    0.0016191751807928085,\n",
       "    0.0016191019356250763,\n",
       "    0.0016123698949813844,\n",
       "    0.0016118865072727202,\n",
       "    0.0016099247485399247,\n",
       "    0.0016094886004924774,\n",
       "    0.0016079185277223587,\n",
       "    0.0016075879901647568,\n",
       "    0.0016071985095739364,\n",
       "    0.0016064590692520142,\n",
       "    0.0016067832708358764,\n",
       "    0.0016059247851371765,\n",
       "    0.0016055028229951859,\n",
       "    0.0016053916662931442,\n",
       "    0.0016053022265434265,\n",
       "    0.0016051439493894577,\n",
       "    0.0016050149202346802,\n",
       "    0.0016049484550952912,\n",
       "    0.001604882237315178,\n",
       "    0.0016048620104789735,\n",
       "    0.0016047924131155015,\n",
       "    0.0016047661900520324,\n",
       "    0.001604745239019394,\n",
       "    0.0016047280848026275,\n",
       "    0.0016047062307596206,\n",
       "    0.0016046982020139695,\n",
       "    0.001604685005545616,\n",
       "    0.0016046802937984465],\n",
       "   'test_acc': [0.8133,\n",
       "    0.8302,\n",
       "    0.8383,\n",
       "    0.8439,\n",
       "    0.848,\n",
       "    0.8477,\n",
       "    0.8508,\n",
       "    0.8521,\n",
       "    0.8535,\n",
       "    0.8548,\n",
       "    0.8548,\n",
       "    0.8549,\n",
       "    0.8551,\n",
       "    0.8555,\n",
       "    0.856,\n",
       "    0.8554,\n",
       "    0.8552,\n",
       "    0.8552,\n",
       "    0.8561,\n",
       "    0.8565,\n",
       "    0.8562,\n",
       "    0.8556,\n",
       "    0.8559,\n",
       "    0.8553,\n",
       "    0.8561,\n",
       "    0.8557,\n",
       "    0.856,\n",
       "    0.856,\n",
       "    0.8564,\n",
       "    0.8563,\n",
       "    0.8563,\n",
       "    0.8564,\n",
       "    0.8562,\n",
       "    0.8564,\n",
       "    0.8563,\n",
       "    0.8564,\n",
       "    0.8564,\n",
       "    0.8564,\n",
       "    0.8564,\n",
       "    0.8564]},\n",
       "  'train_time': 44.53585982322693},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 128, 10],\n",
       "  'num_params': (101770, 101770),\n",
       "  'train_result': {'train_loss': [0.6716052902505752,\n",
       "    0.45216234897045376,\n",
       "    0.4110862147300801,\n",
       "    0.39040218743872135,\n",
       "    0.37612715249365947,\n",
       "    0.36449146587797937,\n",
       "    0.3568258788991482,\n",
       "    0.35033717504207124,\n",
       "    0.34480018622063574,\n",
       "    0.34200184827155256,\n",
       "    0.33923828880837625,\n",
       "    0.3363542084998273,\n",
       "    0.3343262768806295,\n",
       "    0.33249873138488606,\n",
       "    0.33122453562756804,\n",
       "    0.3301044963775797,\n",
       "    0.3299389164498512,\n",
       "    0.32874210483216226,\n",
       "    0.3286394629072636,\n",
       "    0.32820064520582237,\n",
       "    0.3274450423869681,\n",
       "    0.3270582989809361,\n",
       "    0.3270640469611959,\n",
       "    0.32679927184226665,\n",
       "    0.3265963312793285,\n",
       "    0.32673777861798065,\n",
       "    0.3267043300131534,\n",
       "    0.3266010119559917,\n",
       "    0.32626654302820246,\n",
       "    0.3262297876971833,\n",
       "    0.3263363696793292,\n",
       "    0.32657268199514833,\n",
       "    0.32622248815729266,\n",
       "    0.32616874271250784,\n",
       "    0.32668016090037977,\n",
       "    0.3262404552165498,\n",
       "    0.32599261022628623,\n",
       "    0.3262442615438015,\n",
       "    0.326336356680444,\n",
       "    0.3263866593863102],\n",
       "   'test_loss': [0.002050568935275078,\n",
       "    0.0017999114632606507,\n",
       "    0.0017420017898082732,\n",
       "    0.0016730514049530028,\n",
       "    0.0016218097925186157,\n",
       "    0.001606815841794014,\n",
       "    0.0015788825511932373,\n",
       "    0.0015700336694717408,\n",
       "    0.0015545918077230453,\n",
       "    0.0015333204746246338,\n",
       "    0.0015282802432775497,\n",
       "    0.0015225881040096282,\n",
       "    0.0015173660784959793,\n",
       "    0.0015119476318359376,\n",
       "    0.001507710137963295,\n",
       "    0.0015074949353933334,\n",
       "    0.0015038135617971421,\n",
       "    0.0015044096678495408,\n",
       "    0.0015020673111081123,\n",
       "    0.0015008742451667785,\n",
       "    0.0014998768657445908,\n",
       "    0.0014993739396333694,\n",
       "    0.0014991247341036797,\n",
       "    0.0014988864302635193,\n",
       "    0.0014990904659032821,\n",
       "    0.0014984608352184296,\n",
       "    0.0014983205109834672,\n",
       "    0.001498093608021736,\n",
       "    0.0014979509264230729,\n",
       "    0.001497940018773079,\n",
       "    0.0014978273034095765,\n",
       "    0.0014977234929800035,\n",
       "    0.0014976890593767166,\n",
       "    0.0014976346164941787,\n",
       "    0.0014976042300462722,\n",
       "    0.0014975663691759108,\n",
       "    0.0014975557208061218,\n",
       "    0.001497536751627922,\n",
       "    0.0014975309580564499,\n",
       "    0.0014975147783756256],\n",
       "   'test_acc': [0.8176,\n",
       "    0.8388,\n",
       "    0.848,\n",
       "    0.8525,\n",
       "    0.8572,\n",
       "    0.8567,\n",
       "    0.8593,\n",
       "    0.8598,\n",
       "    0.8619,\n",
       "    0.8644,\n",
       "    0.8638,\n",
       "    0.865,\n",
       "    0.8656,\n",
       "    0.8656,\n",
       "    0.8654,\n",
       "    0.8657,\n",
       "    0.866,\n",
       "    0.8669,\n",
       "    0.8659,\n",
       "    0.8661,\n",
       "    0.866,\n",
       "    0.8665,\n",
       "    0.8663,\n",
       "    0.867,\n",
       "    0.8661,\n",
       "    0.8665,\n",
       "    0.8668,\n",
       "    0.8664,\n",
       "    0.8667,\n",
       "    0.8668,\n",
       "    0.8669,\n",
       "    0.867,\n",
       "    0.8669,\n",
       "    0.8668,\n",
       "    0.8668,\n",
       "    0.8668,\n",
       "    0.8667,\n",
       "    0.8668,\n",
       "    0.8668,\n",
       "    0.8667]},\n",
       "  'train_time': 44.94669270515442},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 256, 10],\n",
       "  'num_params': (203530, 203530),\n",
       "  'train_result': {'train_loss': [0.621733552724757,\n",
       "    0.42844625445122414,\n",
       "    0.3912907023379143,\n",
       "    0.36846056504452485,\n",
       "    0.3522044983315975,\n",
       "    0.3412405511166187,\n",
       "    0.3313885762970498,\n",
       "    0.32397755327376915,\n",
       "    0.31801280296863393,\n",
       "    0.313897428614028,\n",
       "    0.3108352075231836,\n",
       "    0.3078146500156281,\n",
       "    0.3054763991782006,\n",
       "    0.303447982795695,\n",
       "    0.30168264343383466,\n",
       "    0.3008368411596785,\n",
       "    0.2996056016455305,\n",
       "    0.29913042371577403,\n",
       "    0.2979802465185206,\n",
       "    0.29803392164250636,\n",
       "    0.2974688503970491,\n",
       "    0.2971981744816963,\n",
       "    0.29702190642661236,\n",
       "    0.2965597930106711,\n",
       "    0.2966164152038858,\n",
       "    0.2960968223023922,\n",
       "    0.29643369919442114,\n",
       "    0.2958867471268837,\n",
       "    0.2957622524905712,\n",
       "    0.29604045748710633,\n",
       "    0.29608029830963056,\n",
       "    0.29587995777738857,\n",
       "    0.29579784515056207,\n",
       "    0.295682278338899,\n",
       "    0.29594099705523635,\n",
       "    0.29572795261728,\n",
       "    0.2958510623333302,\n",
       "    0.2957081766838723,\n",
       "    0.29561770824675865,\n",
       "    0.29575472645303036],\n",
       "   'test_loss': [0.001952132350206375,\n",
       "    0.0018200347781181336,\n",
       "    0.0016782465696334838,\n",
       "    0.001577870598435402,\n",
       "    0.0015271763145923614,\n",
       "    0.0015598469376564025,\n",
       "    0.0014978402525186538,\n",
       "    0.0014872023776173592,\n",
       "    0.001472698187828064,\n",
       "    0.0014597991973161698,\n",
       "    0.0014542259246110916,\n",
       "    0.00144232889264822,\n",
       "    0.0014323687747120858,\n",
       "    0.0014306345492601394,\n",
       "    0.0014281150966882707,\n",
       "    0.0014267705485224724,\n",
       "    0.0014229991480708122,\n",
       "    0.0014240886196494103,\n",
       "    0.0014204927623271942,\n",
       "    0.0014193005427718163,\n",
       "    0.0014178487583994866,\n",
       "    0.0014174436628818512,\n",
       "    0.0014175350606441498,\n",
       "    0.0014163350865244865,\n",
       "    0.0014162738218903542,\n",
       "    0.0014161331236362457,\n",
       "    0.0014157074227929116,\n",
       "    0.0014156901732087135,\n",
       "    0.001415339708328247,\n",
       "    0.001415377040207386,\n",
       "    0.001415313221514225,\n",
       "    0.0014152001738548278,\n",
       "    0.0014151175141334533,\n",
       "    0.0014150848716497422,\n",
       "    0.001415015883743763,\n",
       "    0.0014150227934122085,\n",
       "    0.0014150044813752173,\n",
       "    0.0014149799332022668,\n",
       "    0.001414979898929596,\n",
       "    0.0014149780631065368],\n",
       "   'test_acc': [0.827,\n",
       "    0.8317,\n",
       "    0.851,\n",
       "    0.8599,\n",
       "    0.8639,\n",
       "    0.8593,\n",
       "    0.8682,\n",
       "    0.8687,\n",
       "    0.8706,\n",
       "    0.8709,\n",
       "    0.8718,\n",
       "    0.8727,\n",
       "    0.8719,\n",
       "    0.8724,\n",
       "    0.8727,\n",
       "    0.8714,\n",
       "    0.8731,\n",
       "    0.873,\n",
       "    0.8729,\n",
       "    0.8737,\n",
       "    0.8735,\n",
       "    0.8729,\n",
       "    0.8731,\n",
       "    0.8733,\n",
       "    0.8728,\n",
       "    0.8726,\n",
       "    0.8726,\n",
       "    0.8731,\n",
       "    0.873,\n",
       "    0.873,\n",
       "    0.8732,\n",
       "    0.8729,\n",
       "    0.8731,\n",
       "    0.873,\n",
       "    0.8731,\n",
       "    0.873,\n",
       "    0.873,\n",
       "    0.873,\n",
       "    0.873,\n",
       "    0.873]},\n",
       "  'train_time': 45.42043113708496},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 32, 32, 10],\n",
       "  'num_params': (26506, 26506),\n",
       "  'train_result': {'train_loss': [0.8884680985136235,\n",
       "    0.4992819423371173,\n",
       "    0.4522806461821211,\n",
       "    0.42859134357026285,\n",
       "    0.4160127816048074,\n",
       "    0.4061572953741601,\n",
       "    0.40008109744558945,\n",
       "    0.39532021778695126,\n",
       "    0.3915017197740839,\n",
       "    0.3878824477500104,\n",
       "    0.3858782598946957,\n",
       "    0.38424808725397636,\n",
       "    0.38270687575035905,\n",
       "    0.3817322254180908,\n",
       "    0.38078057727915177,\n",
       "    0.3799181733993774,\n",
       "    0.3792616901245523,\n",
       "    0.3784479855222905,\n",
       "    0.37864035786466393,\n",
       "    0.3781003273547964,\n",
       "    0.3778335544023108,\n",
       "    0.37831191192282004,\n",
       "    0.3773552637150947,\n",
       "    0.37737829761302216,\n",
       "    0.37733046260285885,\n",
       "    0.37719968608085147,\n",
       "    0.37706046243931385,\n",
       "    0.3770609953302018,\n",
       "    0.377187181153196,\n",
       "    0.3769781124718646,\n",
       "    0.3767551839351654,\n",
       "    0.37702962312292543,\n",
       "    0.37679184523034603,\n",
       "    0.37710995623405946,\n",
       "    0.37676160075563064,\n",
       "    0.3772387924346518,\n",
       "    0.37681883548168427,\n",
       "    0.37660150223589955,\n",
       "    0.37690158980958005,\n",
       "    0.37677734703459637],\n",
       "   'test_loss': [0.0022431371867656707,\n",
       "    0.001963003608584404,\n",
       "    0.0018766902059316635,\n",
       "    0.0018152518391609193,\n",
       "    0.0017791442036628722,\n",
       "    0.0017615014791488649,\n",
       "    0.0017267845302820206,\n",
       "    0.0017414587199687957,\n",
       "    0.0017077294766902923,\n",
       "    0.0016956294506788254,\n",
       "    0.001701663911342621,\n",
       "    0.0016875329375267028,\n",
       "    0.0016846677929162979,\n",
       "    0.0016841858237981796,\n",
       "    0.0016801939368247987,\n",
       "    0.0016781711846590042,\n",
       "    0.0016763935774564743,\n",
       "    0.001675514230132103,\n",
       "    0.0016749092161655425,\n",
       "    0.0016754829645156861,\n",
       "    0.0016733993500471114,\n",
       "    0.001673501056432724,\n",
       "    0.0016727812111377717,\n",
       "    0.0016724202662706375,\n",
       "    0.0016724548131227493,\n",
       "    0.0016720290362834931,\n",
       "    0.0016718580156564712,\n",
       "    0.0016718295991420746,\n",
       "    0.00167168428003788,\n",
       "    0.001671592527627945,\n",
       "    0.001671597820520401,\n",
       "    0.0016715213507413865,\n",
       "    0.0016714695453643798,\n",
       "    0.0016714152842760086,\n",
       "    0.0016714034020900727,\n",
       "    0.0016714090138673782,\n",
       "    0.0016713883280754089,\n",
       "    0.0016713878244161606,\n",
       "    0.0016713762372732163,\n",
       "    0.0016713616520166398],\n",
       "   'test_acc': [0.8004,\n",
       "    0.8239,\n",
       "    0.8329,\n",
       "    0.8389,\n",
       "    0.8412,\n",
       "    0.8417,\n",
       "    0.8467,\n",
       "    0.8455,\n",
       "    0.848,\n",
       "    0.8507,\n",
       "    0.8489,\n",
       "    0.8514,\n",
       "    0.8507,\n",
       "    0.8514,\n",
       "    0.8515,\n",
       "    0.8513,\n",
       "    0.8523,\n",
       "    0.8516,\n",
       "    0.8526,\n",
       "    0.8525,\n",
       "    0.852,\n",
       "    0.8516,\n",
       "    0.8523,\n",
       "    0.8524,\n",
       "    0.8529,\n",
       "    0.8523,\n",
       "    0.8518,\n",
       "    0.8517,\n",
       "    0.8518,\n",
       "    0.852,\n",
       "    0.8518,\n",
       "    0.8519,\n",
       "    0.8519,\n",
       "    0.8518,\n",
       "    0.8518,\n",
       "    0.8518,\n",
       "    0.8518,\n",
       "    0.8518,\n",
       "    0.8519,\n",
       "    0.8519]},\n",
       "  'train_time': 45.24801063537598},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 64, 64, 10],\n",
       "  'num_params': (55050, 55050),\n",
       "  'train_result': {'train_loss': [0.7612302789028654,\n",
       "    0.46534360165291644,\n",
       "    0.424513367769566,\n",
       "    0.39964272608148294,\n",
       "    0.38581589320872695,\n",
       "    0.37454773441274114,\n",
       "    0.36609413585764294,\n",
       "    0.3597335123001261,\n",
       "    0.35423076362051864,\n",
       "    0.35083206600331246,\n",
       "    0.3475748469854923,\n",
       "    0.3445128247458884,\n",
       "    0.34311140889817093,\n",
       "    0.341497023054894,\n",
       "    0.3398404582383785,\n",
       "    0.33892867451018477,\n",
       "    0.33800203045631977,\n",
       "    0.33797757232442815,\n",
       "    0.3368623067089852,\n",
       "    0.33647024764659555,\n",
       "    0.33604448050894636,\n",
       "    0.33638969469577706,\n",
       "    0.33563795324335705,\n",
       "    0.33558363527693646,\n",
       "    0.3356353071775842,\n",
       "    0.3354407543197591,\n",
       "    0.3357250709482964,\n",
       "    0.33496468149601144,\n",
       "    0.3349565384235788,\n",
       "    0.3349634495187313,\n",
       "    0.3349899723174724,\n",
       "    0.3346484497506568,\n",
       "    0.3355507938151664,\n",
       "    0.3346406709006492,\n",
       "    0.3349168170639809,\n",
       "    0.33492959268549655,\n",
       "    0.33499039119862495,\n",
       "    0.33523640429719964,\n",
       "    0.3349784956333485,\n",
       "    0.3350013607994039],\n",
       "   'test_loss': [0.0021186572045087814,\n",
       "    0.0018931682080030442,\n",
       "    0.0017566089898347855,\n",
       "    0.0017093194663524627,\n",
       "    0.0016432436972856521,\n",
       "    0.0016407349169254304,\n",
       "    0.0016043083012104034,\n",
       "    0.0015896280884742737,\n",
       "    0.0015718062192201614,\n",
       "    0.0015704197078943252,\n",
       "    0.0015547798603773118,\n",
       "    0.00155042677372694,\n",
       "    0.001543797129392624,\n",
       "    0.00154318488240242,\n",
       "    0.0015476230323314666,\n",
       "    0.0015387116000056267,\n",
       "    0.0015346953392028808,\n",
       "    0.0015332717031240463,\n",
       "    0.0015328027307987212,\n",
       "    0.0015300099477171898,\n",
       "    0.001530193117260933,\n",
       "    0.0015295330330729485,\n",
       "    0.0015285289078950882,\n",
       "    0.0015284889161586762,\n",
       "    0.0015283105790615081,\n",
       "    0.0015279074519872666,\n",
       "    0.0015277666002511978,\n",
       "    0.0015274665072560311,\n",
       "    0.0015275525599718093,\n",
       "    0.0015275152161717414,\n",
       "    0.0015274058371782303,\n",
       "    0.0015273712798953057,\n",
       "    0.0015273204654455185,\n",
       "    0.0015272842586040497,\n",
       "    0.0015272931024432183,\n",
       "    0.0015272822484374046,\n",
       "    0.0015272632926702499,\n",
       "    0.0015272550299763679,\n",
       "    0.001527234211564064,\n",
       "    0.001527226634323597],\n",
       "   'test_acc': [0.8101,\n",
       "    0.8321,\n",
       "    0.844,\n",
       "    0.8493,\n",
       "    0.856,\n",
       "    0.8538,\n",
       "    0.8601,\n",
       "    0.8596,\n",
       "    0.8609,\n",
       "    0.8618,\n",
       "    0.8622,\n",
       "    0.8619,\n",
       "    0.8636,\n",
       "    0.8629,\n",
       "    0.8632,\n",
       "    0.8629,\n",
       "    0.8657,\n",
       "    0.8651,\n",
       "    0.8651,\n",
       "    0.8657,\n",
       "    0.8651,\n",
       "    0.8649,\n",
       "    0.8652,\n",
       "    0.8651,\n",
       "    0.8649,\n",
       "    0.8654,\n",
       "    0.8653,\n",
       "    0.8654,\n",
       "    0.8655,\n",
       "    0.8652,\n",
       "    0.8654,\n",
       "    0.8655,\n",
       "    0.8653,\n",
       "    0.8654,\n",
       "    0.8655,\n",
       "    0.8655,\n",
       "    0.8654,\n",
       "    0.8655,\n",
       "    0.8653,\n",
       "    0.8653]},\n",
       "  'train_time': 46.59905123710632},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 128, 128, 10],\n",
       "  'num_params': (118282, 118282),\n",
       "  'train_result': {'train_loss': [0.675513213999728,\n",
       "    0.43222388117871385,\n",
       "    0.39389598496416783,\n",
       "    0.3728710200558317,\n",
       "    0.35741128185962107,\n",
       "    0.34531677866235694,\n",
       "    0.3354564475886365,\n",
       "    0.32974883368674746,\n",
       "    0.322259720525843,\n",
       "    0.318661734652012,\n",
       "    0.31448251478215483,\n",
       "    0.3119450092949766,\n",
       "    0.3092481278358622,\n",
       "    0.3072023424696415,\n",
       "    0.3053146293822755,\n",
       "    0.30443572363954907,\n",
       "    0.303531088790995,\n",
       "    0.3028839281264772,\n",
       "    0.3016761016972522,\n",
       "    0.3011921425449087,\n",
       "    0.3008421056448145,\n",
       "    0.30023002472329646,\n",
       "    0.30023051436911236,\n",
       "    0.300128337360443,\n",
       "    0.30012277770549695,\n",
       "    0.2997272735580485,\n",
       "    0.2995406646043696,\n",
       "    0.2992806317324334,\n",
       "    0.2989217904653955,\n",
       "    0.29922488211317266,\n",
       "    0.2991909090508806,\n",
       "    0.2989099874141368,\n",
       "    0.2989232321368887,\n",
       "    0.29887758778764845,\n",
       "    0.2988112647482689,\n",
       "    0.29881114649011736,\n",
       "    0.29895397697357423,\n",
       "    0.2989563569109491,\n",
       "    0.2986656946070651,\n",
       "    0.29905788511671916],\n",
       "   'test_loss': [0.0019520343422889709,\n",
       "    0.0018001283913850784,\n",
       "    0.0017080321907997132,\n",
       "    0.0015823626130819321,\n",
       "    0.0015643402725458145,\n",
       "    0.0015218304753303528,\n",
       "    0.0015182131722569466,\n",
       "    0.0014789485812187195,\n",
       "    0.0014717669740319252,\n",
       "    0.0014627825751900674,\n",
       "    0.0014502913862466812,\n",
       "    0.0014466503888368606,\n",
       "    0.0014462616622447967,\n",
       "    0.0014423177018761636,\n",
       "    0.0014368290573358537,\n",
       "    0.0014308269560337067,\n",
       "    0.0014304591104388237,\n",
       "    0.0014296484872698785,\n",
       "    0.0014265014350414275,\n",
       "    0.001425190880894661,\n",
       "    0.0014262302339076995,\n",
       "    0.0014249805375933647,\n",
       "    0.001424833744764328,\n",
       "    0.0014236598402261734,\n",
       "    0.001423767890036106,\n",
       "    0.0014228577584028245,\n",
       "    0.0014228471741080284,\n",
       "    0.001423207539319992,\n",
       "    0.001422573982179165,\n",
       "    0.0014226228013634681,\n",
       "    0.0014223659917712212,\n",
       "    0.0014224054917693137,\n",
       "    0.0014223295763134956,\n",
       "    0.001422353793680668,\n",
       "    0.0014222917139530182,\n",
       "    0.0014223121970891952,\n",
       "    0.0014222764164209367,\n",
       "    0.0014222378805279733,\n",
       "    0.0014222281143069268,\n",
       "    0.0014222260653972627],\n",
       "   'test_acc': [0.8275,\n",
       "    0.8379,\n",
       "    0.8475,\n",
       "    0.8592,\n",
       "    0.8626,\n",
       "    0.8645,\n",
       "    0.8632,\n",
       "    0.867,\n",
       "    0.869,\n",
       "    0.8684,\n",
       "    0.8694,\n",
       "    0.8699,\n",
       "    0.869,\n",
       "    0.8696,\n",
       "    0.8718,\n",
       "    0.8718,\n",
       "    0.8711,\n",
       "    0.8706,\n",
       "    0.8722,\n",
       "    0.8719,\n",
       "    0.8713,\n",
       "    0.871,\n",
       "    0.8708,\n",
       "    0.8717,\n",
       "    0.872,\n",
       "    0.8723,\n",
       "    0.872,\n",
       "    0.8714,\n",
       "    0.8717,\n",
       "    0.8719,\n",
       "    0.8717,\n",
       "    0.8718,\n",
       "    0.8717,\n",
       "    0.872,\n",
       "    0.872,\n",
       "    0.8722,\n",
       "    0.8721,\n",
       "    0.872,\n",
       "    0.8721,\n",
       "    0.8721]},\n",
       "  'train_time': 44.21124076843262},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 256, 256, 10],\n",
       "  'num_params': (269322, 269322),\n",
       "  'train_result': {'train_loss': [0.6147275724309555,\n",
       "    0.40036224481907295,\n",
       "    0.35699334493342866,\n",
       "    0.3345783348413224,\n",
       "    0.31354907313559915,\n",
       "    0.30156485552483414,\n",
       "    0.2900069459955743,\n",
       "    0.2819823350044007,\n",
       "    0.2737185296226055,\n",
       "    0.2670802545674304,\n",
       "    0.26345241342453246,\n",
       "    0.2589029590500162,\n",
       "    0.2562054579562329,\n",
       "    0.253554940921195,\n",
       "    0.2512221980285137,\n",
       "    0.250049286193036,\n",
       "    0.2481624447284861,\n",
       "    0.2472660078013197,\n",
       "    0.24658818206888564,\n",
       "    0.24607269846378488,\n",
       "    0.2452946368050068,\n",
       "    0.24498398874668365,\n",
       "    0.2443918529343098,\n",
       "    0.2438580923892082,\n",
       "    0.2435229926667315,\n",
       "    0.2437186990646606,\n",
       "    0.24332508983764242,\n",
       "    0.24337218980839911,\n",
       "    0.24316464047482672,\n",
       "    0.24293243720176372,\n",
       "    0.24327849986705374,\n",
       "    0.24282632514517358,\n",
       "    0.24288555282227536,\n",
       "    0.24310346531107072,\n",
       "    0.2427913694305623,\n",
       "    0.24276339278576223,\n",
       "    0.24312925554336384,\n",
       "    0.24292806539129705,\n",
       "    0.24265824949487727,\n",
       "    0.24252474314354835],\n",
       "   'test_loss': [0.0019169396817684174,\n",
       "    0.0016548942983150483,\n",
       "    0.001529505878686905,\n",
       "    0.001491386266052723,\n",
       "    0.0014385170117020606,\n",
       "    0.0014046581447124482,\n",
       "    0.001381494726240635,\n",
       "    0.0013508848577737807,\n",
       "    0.0013550289124250412,\n",
       "    0.0013370546892285348,\n",
       "    0.0013232527703046799,\n",
       "    0.0013210659310221673,\n",
       "    0.001313697651028633,\n",
       "    0.0013312230184674262,\n",
       "    0.0013157250419259072,\n",
       "    0.0013083731338381767,\n",
       "    0.001306873506307602,\n",
       "    0.0013087504670023919,\n",
       "    0.0013065643101930619,\n",
       "    0.0013031885787844657,\n",
       "    0.0013032675668597222,\n",
       "    0.001304111947119236,\n",
       "    0.0013018103793263436,\n",
       "    0.0013017818674445152,\n",
       "    0.0013023240745067596,\n",
       "    0.0013011202752590178,\n",
       "    0.0013013931900262832,\n",
       "    0.0013009867295622826,\n",
       "    0.0013011262074112892,\n",
       "    0.0013009623512625695,\n",
       "    0.0013012696772813797,\n",
       "    0.0013009248331189156,\n",
       "    0.001300919519364834,\n",
       "    0.0013008863180875778,\n",
       "    0.0013008854687213897,\n",
       "    0.0013008650198578834,\n",
       "    0.0013009213984012604,\n",
       "    0.0013008830398321151,\n",
       "    0.001300872614979744,\n",
       "    0.0013008631482720374],\n",
       "   'test_acc': [0.8338,\n",
       "    0.8518,\n",
       "    0.8635,\n",
       "    0.8649,\n",
       "    0.8692,\n",
       "    0.8737,\n",
       "    0.8772,\n",
       "    0.879,\n",
       "    0.8807,\n",
       "    0.8811,\n",
       "    0.883,\n",
       "    0.8819,\n",
       "    0.8845,\n",
       "    0.8823,\n",
       "    0.8838,\n",
       "    0.8851,\n",
       "    0.8853,\n",
       "    0.8854,\n",
       "    0.8861,\n",
       "    0.8851,\n",
       "    0.8861,\n",
       "    0.8855,\n",
       "    0.8855,\n",
       "    0.8855,\n",
       "    0.8867,\n",
       "    0.8854,\n",
       "    0.8865,\n",
       "    0.8863,\n",
       "    0.8861,\n",
       "    0.8864,\n",
       "    0.8861,\n",
       "    0.8866,\n",
       "    0.8864,\n",
       "    0.8867,\n",
       "    0.8866,\n",
       "    0.8865,\n",
       "    0.8865,\n",
       "    0.8865,\n",
       "    0.8865,\n",
       "    0.8865]},\n",
       "  'train_time': 48.14005398750305},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 512, 512, 10],\n",
       "  'num_params': (669706, 669706),\n",
       "  'train_result': {'train_loss': [0.5683653743977243,\n",
       "    0.376444536447525,\n",
       "    0.33157120765523707,\n",
       "    0.3047454551179358,\n",
       "    0.28256439173475223,\n",
       "    0.2651828954828546,\n",
       "    0.2544280232267177,\n",
       "    0.24327305384138798,\n",
       "    0.23280870578390486,\n",
       "    0.22669207390318524,\n",
       "    0.21887330802831245,\n",
       "    0.2136105570387333,\n",
       "    0.20880596048020303,\n",
       "    0.20516815876707117,\n",
       "    0.20191781666684658,\n",
       "    0.19918571726438847,\n",
       "    0.1975457618211178,\n",
       "    0.19568081770805604,\n",
       "    0.1942658634261882,\n",
       "    0.19299797865938634,\n",
       "    0.19222419198523177,\n",
       "    0.19161920335064542,\n",
       "    0.19068774733137578,\n",
       "    0.19059659965494846,\n",
       "    0.19018588205601306,\n",
       "    0.18960300338395097,\n",
       "    0.18921851404803863,\n",
       "    0.18916003288740807,\n",
       "    0.1890211282258338,\n",
       "    0.18901830724579222,\n",
       "    0.18893730485058846,\n",
       "    0.18863196842213895,\n",
       "    0.18857637421881898,\n",
       "    0.18863804264271514,\n",
       "    0.18843534271767798,\n",
       "    0.18841298298632844,\n",
       "    0.18840123440356965,\n",
       "    0.18852931717608837,\n",
       "    0.18848705367839083,\n",
       "    0.18835914788093971],\n",
       "   'test_loss': [0.0017329962313175201,\n",
       "    0.0015166069626808166,\n",
       "    0.001486901046335697,\n",
       "    0.0013516756042838097,\n",
       "    0.0013163646474480628,\n",
       "    0.001283924461901188,\n",
       "    0.0012755557909607887,\n",
       "    0.0012565647378563881,\n",
       "    0.0012295397520065308,\n",
       "    0.001234209457039833,\n",
       "    0.0012194706469774246,\n",
       "    0.001239043989777565,\n",
       "    0.0012049977973103523,\n",
       "    0.0012160689458251,\n",
       "    0.0012027357399463654,\n",
       "    0.0012051349923014642,\n",
       "    0.0011999357029795646,\n",
       "    0.001198609283566475,\n",
       "    0.0011930822119116783,\n",
       "    0.0011942051500082017,\n",
       "    0.0011963683679699897,\n",
       "    0.0011943185552954674,\n",
       "    0.0011933154121041298,\n",
       "    0.0011954527273774147,\n",
       "    0.0011937376976013183,\n",
       "    0.0011933807775378227,\n",
       "    0.0011934397608041763,\n",
       "    0.00119372016787529,\n",
       "    0.001194129541516304,\n",
       "    0.001193718248605728,\n",
       "    0.0011936430260539054,\n",
       "    0.0011934576362371445,\n",
       "    0.0011934903621673583,\n",
       "    0.0011936014384031296,\n",
       "    0.001193537899851799,\n",
       "    0.0011934536665678024,\n",
       "    0.001193489384651184,\n",
       "    0.001193479086458683,\n",
       "    0.0011934704720973968,\n",
       "    0.0011934559777379036],\n",
       "   'test_acc': [0.844,\n",
       "    0.8612,\n",
       "    0.8624,\n",
       "    0.8774,\n",
       "    0.8817,\n",
       "    0.8839,\n",
       "    0.8833,\n",
       "    0.8868,\n",
       "    0.8896,\n",
       "    0.8901,\n",
       "    0.8929,\n",
       "    0.8907,\n",
       "    0.8919,\n",
       "    0.8932,\n",
       "    0.8941,\n",
       "    0.8944,\n",
       "    0.8935,\n",
       "    0.8943,\n",
       "    0.8947,\n",
       "    0.8949,\n",
       "    0.8952,\n",
       "    0.8943,\n",
       "    0.8947,\n",
       "    0.8961,\n",
       "    0.8938,\n",
       "    0.8945,\n",
       "    0.8945,\n",
       "    0.8946,\n",
       "    0.8949,\n",
       "    0.8957,\n",
       "    0.8951,\n",
       "    0.8947,\n",
       "    0.8951,\n",
       "    0.8953,\n",
       "    0.8951,\n",
       "    0.8952,\n",
       "    0.895,\n",
       "    0.895,\n",
       "    0.8951,\n",
       "    0.8952]},\n",
       "  'train_time': 44.39455962181091}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f7b08de-fbc2-442a-a948-620cd2023cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save results to file\n",
    "f = open('test_results_fashionMNIST_2.pickle', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bf36a-3f62-43b8-958f-0a4d8aede913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a17310-d554-4137-8dbf-063cc0a4eced",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6c1f9-a5d6-4b83-b79b-5b2d11a5901a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan_venv_2",
   "language": "python",
   "name": "pykan_venv_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
