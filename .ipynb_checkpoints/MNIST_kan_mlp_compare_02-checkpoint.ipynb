{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66d4d150-96b6-4a63-8bc9-9b20b62ab163",
   "metadata": {},
   "source": [
    "# Comparing MLP vs. KAN on Classification problem with a bit more input dimensions (MNIST)\n",
    "\n",
    "Original KAN example: https://github.com/KindXiaoming/pykan/blob/master/tutorials/Example_3_classfication.ipynb \\\n",
    "EfficientKAN by Blealtan: https://github.com/Blealtan/efficient-kan \\\n",
    "MLP in pytorch Referenced from: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html \\\n",
    "ConvolutionalKAN by AntonioTepsich: https://github.com/AntonioTepsich/Convolutional-KANs\n",
    "\n",
    "Test with MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b0f2c9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import struct\n",
    "from array import array\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import gc\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ac3b61-ace6-422d-9457-05e00b3d55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'efficient-kan-master', 'src')))\n",
    "\n",
    "from efficient_kan import KAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bd87f3-a8ec-48a9-9360-79d1a6100659",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'Convolutional-KANs-master')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..', 'Convolutional-KANs-master', 'kan_convolutional')))\n",
    "\n",
    "from kan_convolutional.KANConv import KAN_Convolutional_Layer\n",
    "from kan_convolutional.KANLinear import KANLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c591dd6",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has CUDA: True\n",
      "device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "print('Has CUDA:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('device name:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d67376",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10e022d-b2df-4188-8788-dd3d86aca214",
   "metadata": {},
   "source": [
    "##### Read from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999e35ca-fa49-4913-a381-769fa92a82e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Data Loader Class\n",
    "# https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c775ef69-5284-4819-b75e-7ca6fb230c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths based on added MNIST Datasets\n",
    "input_path = 'MNIST_dataset'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb77dfc0-3aa6-4813-ba08-27a820852a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MINST dataset\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_tr, y_tr), (x_te, y_te) = mnist_dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e57795-5f95-42f6-9c55-05354a932b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = np.array(x_tr)\n",
    "y_tr = np.array(y_tr)\n",
    "x_te = np.array(x_te)\n",
    "y_te = np.array(y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873af6e1-6c1e-4e9f-b0d9-c3ffcc9c713b",
   "metadata": {},
   "source": [
    "##### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32e1d798-d19d-491d-ab66-1623bcfd7353",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# normalie the dataset values to [0.0, 1.0]\n",
    "vmax = np.amax(x_tr)\n",
    "x_tr = x_tr / vmax\n",
    "x_te = x_te / vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1709bf4-602a-4b6d-bf82-c862b1d4e84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "x_tr_flattened = x_tr.reshape((x_tr.shape[0], x_tr.shape[1] * x_tr.shape[2]))\n",
    "x_te_flattened = x_te.reshape((x_te.shape[0], x_te.shape[1] * x_te.shape[2]))\n",
    "\n",
    "# conv color channel\n",
    "x_tr_channeled = x_tr.reshape((x_tr.shape[0], 1, x_tr.shape[1], x_tr.shape[2]))\n",
    "x_te_channeled = x_te.reshape((x_te.shape[0], 1, x_te.shape[1], x_te.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fab300",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x_train_flattened = torch.tensor(np.array(x_tr_flattened))\n",
    "x_train_channeled = torch.tensor(np.array(x_tr_channeled))\n",
    "y_train = torch.tensor(np.array(y_tr))\n",
    "\n",
    "x_test_flattened  = torch.tensor(np.array(x_te_flattened))\n",
    "x_test_channeled  = torch.tensor(np.array(x_te_channeled))\n",
    "y_test  = torch.tensor(np.array(y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2187dba",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ba19f4-a864-42bf-8ede-fa7411670255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_channeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3bb877b",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# chop off a ratio of the train sets\n",
    "ratio_keep = 1.0\n",
    "\n",
    "num_train = x_tr.shape[0]\n",
    "num_test = x_te.shape[0]\n",
    "\n",
    "num_train_1 = int(num_train * ratio_keep)\n",
    "num_test_1  = int(num_test * ratio_keep)\n",
    "\n",
    "x_train_flattened = x_train_flattened[:num_train_1, :]\n",
    "x_train_channeled = x_train_channeled[:num_train_1, :]\n",
    "y_train = y_train[:num_train_1]\n",
    "\n",
    "x_test_flattened = x_test_flattened[:num_test_1, :]\n",
    "x_test_channeled = x_test_channeled[:num_test_1, :]\n",
    "y_test = y_test[:num_test_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4c83e-02d4-4ca2-bbe2-568336431765",
   "metadata": {},
   "source": [
    "##### Create a troch dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a08d7590",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11ec54e2-5797-4143-abbd-2f34d952bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "716ef2e8-fb82-47e7-9583-89e2c1cd85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattened for fully connected\n",
    "train_set_flattened = TensorDataset(x_train_flattened.to(dtype=torch.float32), y_train)\n",
    "train_loader_flattened = DataLoader(train_set_flattened, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set_flattened = TensorDataset(x_test_flattened.to(dtype=torch.float32), y_test)\n",
    "test_loader_flattened = DataLoader(test_set_flattened, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# channeled for convolution\n",
    "train_set_channeled = TensorDataset(x_train_channeled.to(dtype=torch.float32), y_train)\n",
    "train_loader_channeled = DataLoader(train_set_channeled, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_set_channeled = TensorDataset(x_test_channeled.to(dtype=torch.float32), y_test)\n",
    "test_loader_channeled = DataLoader(test_set_channeled, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c17bf8-aa2a-4242-bd05-9e8caa2a208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_flattened = {'train': train_loader_flattened, 'test': test_loader_flattened}\n",
    "dataset_channeled = {'train': train_loader_channeled, 'test': test_loader_channeled}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd564596-965f-4afc-bacd-94254e986b47",
   "metadata": {},
   "source": [
    "### Code for classical MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "759b8ae1-4e75-4392-b4ca-a85d5738ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    '''\n",
    "    width is the dimension of each layer, like [784, 20, 20, 10]\n",
    "    '''\n",
    "    def __init__(self, width):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        stack = []\n",
    "        l = len(width)\n",
    "        for i in range(l-2):\n",
    "            stack.append(nn.Linear(width[i], width[i+1]))\n",
    "            stack.append(nn.ReLU())\n",
    "        stack.append(nn.Linear(width[l-2], width[l-1]))\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(*stack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc38fb-1f39-4a03-9bca-38810ba322f9",
   "metadata": {},
   "source": [
    "### Code for ConvolutionKAN\n",
    "copied from: https://github.com/AntonioTepsich/Convolutional-KANs/tree/master/architectures_28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc651b5-57c9-4620-963e-1b70e38e7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvKAN_2conv(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(625, 64)\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c530bf6-ee8a-4d4f-9d87-bf1f9889beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvKAN_1conv(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "        \n",
    "        self.linear1 = nn.Linear(845, 64)\n",
    "        self.linear2 = nn.Linear(64, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d297c27-9173-4576-af6f-e06509c6484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KKAN_Convolutional_Network(nn.Module):\n",
    "    def __init__(self,device: str = 'cuda'):\n",
    "        super().__init__()\n",
    "        self.conv1 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size= (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.conv2 = KAN_Convolutional_Layer(\n",
    "            n_convs = 5,\n",
    "            kernel_size = (3,3),\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(\n",
    "            kernel_size=(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.flat = nn.Flatten() \n",
    "\n",
    "        self.kan1 = KANLinear(\n",
    "            625,\n",
    "            10,\n",
    "            grid_size=10,\n",
    "            spline_order=3,\n",
    "            scale_noise=0.01,\n",
    "            scale_base=1,\n",
    "            scale_spline=1,\n",
    "            base_activation=nn.SiLU,\n",
    "            grid_eps=0.02,\n",
    "            grid_range=[0,1],\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flat(x)\n",
    "\n",
    "        x = self.kan1(x) \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac46581-3a8e-4d97-8b3a-df18e3e6dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "convkan_types_map = {0: ConvKAN_1conv, 1: ConvKAN_2conv, 2: KKAN_Convolutional_Network}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff23c7",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc24218-af0c-4f6b-b24c-4d88bc7949e9",
   "metadata": {},
   "source": [
    "##### utility funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2666675",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# see total number of params\n",
    "def get_num_params(model):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    pytorch_total_params_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    return pytorch_total_params, pytorch_total_params_trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d0906-8543-4b2f-a86d-cdc12c679d00",
   "metadata": {},
   "source": [
    "##### New util codes\n",
    "copied from: https://github.com/AntonioTepsich/Convolutional-KANs/blob/master/experiment_28x28.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e59fd1b-c13c-4215-9a10-746f893fb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_loader(model, device, train_loader, optimizer, epoch, criterion):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        train_loader: DataLoader for training data\n",
    "        optimizer: the optimizer to use (e.g. SGD)\n",
    "        epoch: the current epoch\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        avg_loss: the average loss over the training set\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        # Get the loss\n",
    "        loss = criterion(output, target)\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    # print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "\n",
    "def test_batch_loader(model, device, test_loader, criterion):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "\n",
    "    Args:\n",
    "        model: the neural network model\n",
    "        device: cuda or cpu\n",
    "        test_loader: DataLoader for test data\n",
    "        criterion: the loss function (e.g. CrossEntropy)\n",
    "\n",
    "    Returns:\n",
    "        test_loss: the average loss over the test set\n",
    "        accuracy: the accuracy of the model on the test set\n",
    "        precision: the precision of the model on the test set\n",
    "        recall: the recall of the model on the test set\n",
    "        f1: the f1 score of the model on the test set\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += criterion(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (target == predicted).sum().item()\n",
    "\n",
    "            # Collect all targets and predictions for metric calculations\n",
    "            all_targets.extend(target.view_as(predicted).cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Normalize test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Precision: {:.2f}, Recall: {:.2f}, F1 Score: {:.2f}\\n'.format(\n",
    "    #     test_loss, correct, len(test_loader.dataset), accuracy, precision, recall, f1))\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f5c3f5d-99b7-4c43-87d7-c77a8dd16ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(model, num_epochs, loss_fn, train_loader, test_loader, optimizer, scheduler=None):\n",
    "    res = {'train_loss': [], 'test_loss': [], 'test_acc': []}\n",
    "    for n in tqdm(range(num_epochs)):\n",
    "        train_loss = train_batch_loader(model, 'cuda', train_loader, optimizer, n, loss_fn)\n",
    "        # test_loss, test_acc, precision, recall, f1 = test_batch_loader(model, 'cuda', test_loader, loss_fn)\n",
    "        test_loss, test_acc = test_batch_loader(model, 'cuda', test_loader, loss_fn)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        res['train_loss'].append(train_loss)\n",
    "        res['test_loss'].append(test_loss)\n",
    "        res['test_acc'].append(test_acc)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce08650-5506-4aa4-bd63-c5c1e8f250b3",
   "metadata": {},
   "source": [
    "##### Create different types of models and train them\n",
    "We want to use the same optimization method, batch size, etc. to compare the different architectures fairly \\\n",
    "This might cause slower training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0685fc62-a62d-4549-a698-0dc3785dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create, train, then discard a model\n",
    "our objective is to figure out the efficacy of different shaped models\n",
    "'''\n",
    "def create_and_train(model_type, width, epochs, lr, batch_size=-1):\n",
    "    dset = dataset_flattened\n",
    "    \n",
    "    # create model\n",
    "    if model_type == 'mlp':\n",
    "        model = NeuralNetwork(width).to(device='cuda')\n",
    "    elif model_type == 'kan':\n",
    "        model = KAN(width, grid_size=3, spline_order=3).to(device='cuda')\n",
    "    elif model_type == 'convkan':\n",
    "        # TODO: change to use width\n",
    "        model = convkan_types_map[width]().to(device='cuda')\n",
    "        dset = dataset_channeled\n",
    "\n",
    "    # record num of params\n",
    "    num_params = get_num_params(model)\n",
    "    \n",
    "    # use categorical cross entropy loss\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    # learning rate and adam optimizer\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "    \n",
    "    # train as any vanilla pytorch model\n",
    "    start = time.time()\n",
    "    # results = train(model, epochs, loss_fn, dset, optimizer, batch_size=batch_size)\n",
    "    results = train_process(model, epochs, loss_fn, dset['train'], dset['test'], optimizer, scheduler=scheduler)\n",
    "    end = time.time()\n",
    "\n",
    "    # free the memory\n",
    "    model.cpu()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return {'model_type': model_type, 'width': width, 'num_params': num_params, 'train_result': results, 'train_time': (end - start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58594fae-d5eb-489b-821c-d861fb808836",
   "metadata": {},
   "outputs": [],
   "source": [
    "kan_shapes = [\n",
    "    [784, 10],\n",
    "    [784, 16, 10],\n",
    "    [784, 32, 10],\n",
    "    [784, 64, 10],\n",
    "    [784, 128, 10],\n",
    "    [784, 32, 32, 10],\n",
    "    [784, 64, 64, 10],\n",
    "]\n",
    "\n",
    "mlp_shapes = [\n",
    "    [784, 10],\n",
    "    [784, 16, 10],\n",
    "    [784, 32, 10],\n",
    "    [784, 64, 10],\n",
    "    [784, 128, 10],\n",
    "    [784, 256, 10],\n",
    "    [784, 32, 32, 10],\n",
    "    [784, 64, 64, 10],\n",
    "    [784, 128, 128, 10],\n",
    "    [784, 256, 256, 10],\n",
    "    [784, 512, 512, 10],\n",
    "]\n",
    "\n",
    "convkan_types = convkan_types_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "197de4ce-917d-4412-9921-7c70862572bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c8134c-b0d4-4397-a4ab-f43d7ce236f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_ct = 40\n",
    "# epoch_ct = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ee5be8f-7a97-480a-883e-23d92f65ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KAN shape: [784, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:57<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 57.024134397506714\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 16, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:09<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 69.70530200004578\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:09<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 69.58233690261841\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:05<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 65.91526436805725\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:06<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 66.72944474220276\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 32, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:23<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 83.45880961418152\n",
      "------------------------------------------------------------\n",
      "Training KAN shape: [784, 64, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [01:20<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 80.53492832183838\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [09:58<00:00, 14.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 598.6782262325287\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [33:28<00:00, 50.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2008.5516653060913\n",
      "------------------------------------------------------------\n",
      "Training ConvKAN type: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [34:13<00:00, 51.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2053.6402065753937\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:39<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 39.381596326828\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 16, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.26330351829529\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.281919717788696\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.23043966293335\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.35863900184631\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 256, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.43997931480408\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 32, 32, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:44<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 44.26502466201782\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 64, 64, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:46<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 46.36068105697632\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 128, 128, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.14708209037781\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 256, 256, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:46<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 46.928699254989624\n",
      "------------------------------------------------------------\n",
      "Training MLP shape: [784, 512, 512, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 40/40 [00:43<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.43510174751282\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for shape in kan_shapes:\n",
    "    print('Training KAN shape:', shape)\n",
    "    res = create_and_train('kan', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)\n",
    "\n",
    "for shape in convkan_types:\n",
    "    print('Training ConvKAN type:', shape)\n",
    "    res = create_and_train('convkan', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)\n",
    "\n",
    "for shape in mlp_shapes:\n",
    "    print('Training MLP shape:', shape)\n",
    "    res = create_and_train('mlp', shape, epoch_ct, lr=1e-3)\n",
    "    print('train time:', res['train_time'])\n",
    "    print('------------------------------------------------------------')\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbcd1cc8-4d9b-441d-bc29-047761851f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_type': 'kan',\n",
       "  'width': [784, 10],\n",
       "  'num_params': (62720, 62720),\n",
       "  'train_result': {'train_loss': [0.8547003550732389,\n",
       "    0.385613499803746,\n",
       "    0.33371262036739513,\n",
       "    0.31314211119996743,\n",
       "    0.3015814148999275,\n",
       "    0.2943480814390994,\n",
       "    0.2889997953430135,\n",
       "    0.2853761023029368,\n",
       "    0.28301142365374465,\n",
       "    0.28106454820074933,\n",
       "    0.2790402493578322,\n",
       "    0.2779865837477623,\n",
       "    0.2771090750364547,\n",
       "    0.27592858621414673,\n",
       "    0.27546686308181034,\n",
       "    0.2746155270870696,\n",
       "    0.2748618239417989,\n",
       "    0.27429414829041093,\n",
       "    0.27417522408860795,\n",
       "    0.27410230826824267,\n",
       "    0.27352276691730987,\n",
       "    0.27331564305944644,\n",
       "    0.2734539895615679,\n",
       "    0.2732338231294713,\n",
       "    0.27364757859960515,\n",
       "    0.273379614188316,\n",
       "    0.273683895773076,\n",
       "    0.2732433831438105,\n",
       "    0.27292971446159037,\n",
       "    0.2734361114020043,\n",
       "    0.272896498061241,\n",
       "    0.27337897071178924,\n",
       "    0.2733150319850191,\n",
       "    0.27300069655509707,\n",
       "    0.27303145591248856,\n",
       "    0.2733002274594408,\n",
       "    0.27326074001636913,\n",
       "    0.27324040456021087,\n",
       "    0.272803026627987,\n",
       "    0.273079909986638],\n",
       "   'test_loss': [0.0016579361520707608,\n",
       "    0.0013333566695451736,\n",
       "    0.0012174376383423805,\n",
       "    0.0011711086004972458,\n",
       "    0.0011412098044529557,\n",
       "    0.0011255681905895472,\n",
       "    0.0011146645424887538,\n",
       "    0.0011022905515506863,\n",
       "    0.0010963713513687252,\n",
       "    0.0010903265992179513,\n",
       "    0.0010885055404156446,\n",
       "    0.0010856182657182217,\n",
       "    0.0010831571528688074,\n",
       "    0.0010807550434023142,\n",
       "    0.0010791293937712908,\n",
       "    0.0010783321481198072,\n",
       "    0.0010774343775585293,\n",
       "    0.0010767366662621498,\n",
       "    0.0010762432578951121,\n",
       "    0.001075719067826867,\n",
       "    0.0010753649700433016,\n",
       "    0.0010750597339123488,\n",
       "    0.0010749107083305716,\n",
       "    0.001074711399525404,\n",
       "    0.0010746355792507528,\n",
       "    0.0010744877563789487,\n",
       "    0.0010743660930544138,\n",
       "    0.0010743409590795636,\n",
       "    0.0010742771554738283,\n",
       "    0.0010742387361824513,\n",
       "    0.0010742037499323488,\n",
       "    0.0010741745114326478,\n",
       "    0.0010741634441539644,\n",
       "    0.0010741414731368422,\n",
       "    0.0010741232531145215,\n",
       "    0.0010741144716739654,\n",
       "    0.001074102609232068,\n",
       "    0.0010740960193797945,\n",
       "    0.0010740904783830046,\n",
       "    0.0010740861278027297],\n",
       "   'test_acc': [0.8908,\n",
       "    0.91,\n",
       "    0.9148,\n",
       "    0.9177,\n",
       "    0.9173,\n",
       "    0.9197,\n",
       "    0.9207,\n",
       "    0.9208,\n",
       "    0.9219,\n",
       "    0.9224,\n",
       "    0.922,\n",
       "    0.9223,\n",
       "    0.9227,\n",
       "    0.9228,\n",
       "    0.9232,\n",
       "    0.9233,\n",
       "    0.9233,\n",
       "    0.9237,\n",
       "    0.9229,\n",
       "    0.9231,\n",
       "    0.9231,\n",
       "    0.9234,\n",
       "    0.9236,\n",
       "    0.9235,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9238,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9238,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237,\n",
       "    0.9237]},\n",
       "  'train_time': 57.024134397506714},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 16, 10],\n",
       "  'num_params': (101632, 101632),\n",
       "  'train_result': {'train_loss': [0.879574785460817,\n",
       "    0.3509314185127299,\n",
       "    0.3001890071529023,\n",
       "    0.2777007416841832,\n",
       "    0.2637123056548707,\n",
       "    0.2541625752093944,\n",
       "    0.2466633605196121,\n",
       "    0.241625196248927,\n",
       "    0.2371981586864654,\n",
       "    0.23415770562405283,\n",
       "    0.23235682756342788,\n",
       "    0.2300859012502305,\n",
       "    0.22844587703968616,\n",
       "    0.22708678270908111,\n",
       "    0.22619316495479422,\n",
       "    0.22543508822613575,\n",
       "    0.22484518923658006,\n",
       "    0.22442787080369098,\n",
       "    0.22434572951590762,\n",
       "    0.22464681087022131,\n",
       "    0.22387955797479508,\n",
       "    0.22311083414453142,\n",
       "    0.2232755865505401,\n",
       "    0.22285395670444408,\n",
       "    0.22311805562770112,\n",
       "    0.22268699949726145,\n",
       "    0.22267012665880487,\n",
       "    0.22251916733827998,\n",
       "    0.22269760271970263,\n",
       "    0.22281353790709313,\n",
       "    0.22240091270588813,\n",
       "    0.2226652075952672,\n",
       "    0.22275926191756065,\n",
       "    0.22235792970403712,\n",
       "    0.22283768210005253,\n",
       "    0.22244531207896293,\n",
       "    0.22245658870707166,\n",
       "    0.22270727468297838,\n",
       "    0.22255597333324717,\n",
       "    0.22256350723352838],\n",
       "   'test_loss': [0.0015605289474129678,\n",
       "    0.0012184366468340159,\n",
       "    0.0011121807802468538,\n",
       "    0.001057043758034706,\n",
       "    0.001016595816425979,\n",
       "    0.000987713067419827,\n",
       "    0.0009751185255125165,\n",
       "    0.0009527289493009448,\n",
       "    0.0009455906350165606,\n",
       "    0.0009378909030929208,\n",
       "    0.0009284519582986832,\n",
       "    0.0009238699017092586,\n",
       "    0.0009199002970010042,\n",
       "    0.0009173267344012857,\n",
       "    0.0009144144870340824,\n",
       "    0.0009126123275607825,\n",
       "    0.0009106568548828363,\n",
       "    0.0009098248563706875,\n",
       "    0.0009085505038499833,\n",
       "    0.0009077836077660322,\n",
       "    0.0009070453939959407,\n",
       "    0.0009066452778875828,\n",
       "    0.0009063174687325954,\n",
       "    0.000905984541773796,\n",
       "    0.0009057629875838756,\n",
       "    0.0009056002005934715,\n",
       "    0.0009054262844845652,\n",
       "    0.0009053083620965481,\n",
       "    0.0009052014958113432,\n",
       "    0.0009051365150138735,\n",
       "    0.000905080246925354,\n",
       "    0.0009050252847373486,\n",
       "    0.0009049722272902727,\n",
       "    0.0009049492482095957,\n",
       "    0.0009049133855849505,\n",
       "    0.0009048905912786722,\n",
       "    0.0009048762187361717,\n",
       "    0.0009048656156286597,\n",
       "    0.0009048562023788691,\n",
       "    0.0009048458894714713],\n",
       "   'test_acc': [0.8947,\n",
       "    0.9115,\n",
       "    0.9165,\n",
       "    0.9219,\n",
       "    0.9244,\n",
       "    0.9269,\n",
       "    0.9283,\n",
       "    0.9292,\n",
       "    0.9309,\n",
       "    0.9316,\n",
       "    0.9317,\n",
       "    0.9325,\n",
       "    0.9326,\n",
       "    0.9333,\n",
       "    0.9332,\n",
       "    0.9332,\n",
       "    0.9331,\n",
       "    0.9335,\n",
       "    0.9334,\n",
       "    0.9332,\n",
       "    0.9332,\n",
       "    0.9333,\n",
       "    0.9333,\n",
       "    0.9334,\n",
       "    0.9336,\n",
       "    0.9337,\n",
       "    0.9336,\n",
       "    0.9337,\n",
       "    0.9336,\n",
       "    0.9336,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338,\n",
       "    0.9338]},\n",
       "  'train_time': 69.70530200004578},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 32, 10],\n",
       "  'num_params': (203264, 203264),\n",
       "  'train_result': {'train_loss': [0.7262959120121408,\n",
       "    0.3113436539122399,\n",
       "    0.2718445617467799,\n",
       "    0.2487638900888727,\n",
       "    0.2320335379306306,\n",
       "    0.2199045886067634,\n",
       "    0.2100805736602621,\n",
       "    0.2027309886635618,\n",
       "    0.19693541866033634,\n",
       "    0.1921936850598518,\n",
       "    0.18872303737604873,\n",
       "    0.18635569278230057,\n",
       "    0.18362852943704483,\n",
       "    0.18188056482913648,\n",
       "    0.18075734643225974,\n",
       "    0.17927596771970708,\n",
       "    0.17832640799436164,\n",
       "    0.17758397117574165,\n",
       "    0.1770250918066248,\n",
       "    0.17665143992672575,\n",
       "    0.17636684889489032,\n",
       "    0.17607091316517362,\n",
       "    0.17565560787916185,\n",
       "    0.17556099340002587,\n",
       "    0.17540882588066953,\n",
       "    0.17533900297068536,\n",
       "    0.17531035647113272,\n",
       "    0.17566129546216194,\n",
       "    0.17488254077256993,\n",
       "    0.17496645380841924,\n",
       "    0.1751986395488394,\n",
       "    0.17514175287586578,\n",
       "    0.17501199172532306,\n",
       "    0.17514022033899387,\n",
       "    0.1751840389155327,\n",
       "    0.17480015012812108,\n",
       "    0.174850299034981,\n",
       "    0.17529858781936322,\n",
       "    0.17480982199628303,\n",
       "    0.1748697388996469],\n",
       "   'test_loss': [0.0012932279881089925,\n",
       "    0.001084187949821353,\n",
       "    0.0009976315289735795,\n",
       "    0.0009421915706247092,\n",
       "    0.0008960008908063174,\n",
       "    0.0008589817494153977,\n",
       "    0.0008385520888492465,\n",
       "    0.000808588757738471,\n",
       "    0.0007958009550347924,\n",
       "    0.0007807143265381455,\n",
       "    0.000772755085118115,\n",
       "    0.0007656597795896232,\n",
       "    0.000759591013006866,\n",
       "    0.0007552728531882167,\n",
       "    0.0007497886501252651,\n",
       "    0.0007476739441975951,\n",
       "    0.0007443930972367525,\n",
       "    0.0007424874641001225,\n",
       "    0.000740777294896543,\n",
       "    0.0007396837553009391,\n",
       "    0.0007390419973991811,\n",
       "    0.0007377627810463309,\n",
       "    0.0007370804958045482,\n",
       "    0.000736810846440494,\n",
       "    0.0007362920587882399,\n",
       "    0.000735995022021234,\n",
       "    0.000735811760649085,\n",
       "    0.0007355899287387729,\n",
       "    0.0007354470612481236,\n",
       "    0.0007353175573050976,\n",
       "    0.0007352284854277968,\n",
       "    0.0007351622287184,\n",
       "    0.0007350886958651245,\n",
       "    0.0007350405752658844,\n",
       "    0.0007349883926101029,\n",
       "    0.0007349675783887505,\n",
       "    0.0007349380817264318,\n",
       "    0.0007349155146628619,\n",
       "    0.000734900520555675,\n",
       "    0.0007348901105113327],\n",
       "   'test_acc': [0.9077,\n",
       "    0.9229,\n",
       "    0.929,\n",
       "    0.9316,\n",
       "    0.9351,\n",
       "    0.938,\n",
       "    0.9403,\n",
       "    0.9414,\n",
       "    0.9426,\n",
       "    0.9436,\n",
       "    0.944,\n",
       "    0.9446,\n",
       "    0.9452,\n",
       "    0.9453,\n",
       "    0.9461,\n",
       "    0.9456,\n",
       "    0.9462,\n",
       "    0.9463,\n",
       "    0.9463,\n",
       "    0.9465,\n",
       "    0.9464,\n",
       "    0.9464,\n",
       "    0.9465,\n",
       "    0.9465,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466,\n",
       "    0.9466]},\n",
       "  'train_time': 69.58233690261841},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 64, 10],\n",
       "  'num_params': (406528, 406528),\n",
       "  'train_result': {'train_loss': [0.6257635688528101,\n",
       "    0.29229858264010006,\n",
       "    0.25364827050807626,\n",
       "    0.224289892518774,\n",
       "    0.20190113139279345,\n",
       "    0.18509025110843333,\n",
       "    0.1726258083226833,\n",
       "    0.16296225485015423,\n",
       "    0.1559548427766942,\n",
       "    0.15026048222120772,\n",
       "    0.14646222293376923,\n",
       "    0.14290985617231816,\n",
       "    0.14035405744897558,\n",
       "    0.138586385294478,\n",
       "    0.13662736658403213,\n",
       "    0.13531072643843103,\n",
       "    0.1342744308424757,\n",
       "    0.1335692084533103,\n",
       "    0.13276576369683793,\n",
       "    0.13248203333387984,\n",
       "    0.1320288970749429,\n",
       "    0.13143140933615097,\n",
       "    0.13129271734902198,\n",
       "    0.13105306257592872,\n",
       "    0.13082961551052458,\n",
       "    0.13065528187980044,\n",
       "    0.13058965846579126,\n",
       "    0.13060909482709904,\n",
       "    0.13045957342107245,\n",
       "    0.13021632440863773,\n",
       "    0.13052192471445875,\n",
       "    0.13042856943100056,\n",
       "    0.13015640481038296,\n",
       "    0.13031545443103668,\n",
       "    0.13010319935831618,\n",
       "    0.13014857705603255,\n",
       "    0.13009260081230326,\n",
       "    0.1301025889021285,\n",
       "    0.1301644153417425,\n",
       "    0.1302889125144228],\n",
       "   'test_loss': [0.0012211644701659679,\n",
       "    0.0010543227335438133,\n",
       "    0.0009360608268529177,\n",
       "    0.0008341616662219166,\n",
       "    0.0007766936299391091,\n",
       "    0.0007289876434020699,\n",
       "    0.0006973587622866034,\n",
       "    0.0006696733862161636,\n",
       "    0.000646957729384303,\n",
       "    0.0006316880776546896,\n",
       "    0.0006215275065973401,\n",
       "    0.0006158453099429608,\n",
       "    0.0006044721356593072,\n",
       "    0.0006009411397390067,\n",
       "    0.0005961494237184525,\n",
       "    0.0005931430250406266,\n",
       "    0.0005892530981451273,\n",
       "    0.0005876977766864002,\n",
       "    0.0005858282132074237,\n",
       "    0.0005847868140786886,\n",
       "    0.0005835026424378157,\n",
       "    0.000582408791128546,\n",
       "    0.000582205765414983,\n",
       "    0.0005814813886769116,\n",
       "    0.0005810634670779109,\n",
       "    0.0005807697737589478,\n",
       "    0.0005804791279137134,\n",
       "    0.0005802669414319098,\n",
       "    0.0005800966996699572,\n",
       "    0.0005799721967428923,\n",
       "    0.0005798436149023473,\n",
       "    0.0005797726813703775,\n",
       "    0.0005797195336781442,\n",
       "    0.0005796531684696674,\n",
       "    0.0005796043113805353,\n",
       "    0.000579566450137645,\n",
       "    0.0005795391740277409,\n",
       "    0.0005795230469666421,\n",
       "    0.0005795054929330945,\n",
       "    0.0005794900584034622],\n",
       "   'test_acc': [0.9116,\n",
       "    0.9257,\n",
       "    0.9324,\n",
       "    0.9384,\n",
       "    0.9428,\n",
       "    0.945,\n",
       "    0.948,\n",
       "    0.9498,\n",
       "    0.952,\n",
       "    0.953,\n",
       "    0.9534,\n",
       "    0.9537,\n",
       "    0.9548,\n",
       "    0.9544,\n",
       "    0.9554,\n",
       "    0.9559,\n",
       "    0.9561,\n",
       "    0.9562,\n",
       "    0.9565,\n",
       "    0.9568,\n",
       "    0.9566,\n",
       "    0.9567,\n",
       "    0.9567,\n",
       "    0.957,\n",
       "    0.9569,\n",
       "    0.9568,\n",
       "    0.957,\n",
       "    0.9569,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.957,\n",
       "    0.9571,\n",
       "    0.9571,\n",
       "    0.9571]},\n",
       "  'train_time': 65.91526436805725},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 128, 10],\n",
       "  'num_params': (813056, 813056),\n",
       "  'train_result': {'train_loss': [0.5458262967936536,\n",
       "    0.2667551738784668,\n",
       "    0.21745612627648292,\n",
       "    0.181236073945431,\n",
       "    0.15571724664657674,\n",
       "    0.13857284752612417,\n",
       "    0.12578792977840342,\n",
       "    0.11626382726938167,\n",
       "    0.10971338254340152,\n",
       "    0.10407709599809443,\n",
       "    0.10007341350329683,\n",
       "    0.09683393181321469,\n",
       "    0.09464678128666067,\n",
       "    0.09235856396720764,\n",
       "    0.09096882893367017,\n",
       "    0.08956042859465518,\n",
       "    0.08854291187797456,\n",
       "    0.08791448078415495,\n",
       "    0.08723228754515344,\n",
       "    0.08664530033760882,\n",
       "    0.08632038999745187,\n",
       "    0.08588049660654778,\n",
       "    0.08587735661483825,\n",
       "    0.08543284229458646,\n",
       "    0.08531946132474758,\n",
       "    0.08509473063527269,\n",
       "    0.08495749265272566,\n",
       "    0.08506181255934087,\n",
       "    0.08487570607598792,\n",
       "    0.08507611047714314,\n",
       "    0.08493188369147321,\n",
       "    0.08468589213617304,\n",
       "    0.08466355948055045,\n",
       "    0.08509442982204417,\n",
       "    0.08466015259953255,\n",
       "    0.08471623386474365,\n",
       "    0.08458219130147011,\n",
       "    0.08483714963051867,\n",
       "    0.08472703084983724,\n",
       "    0.08468555170804896],\n",
       "   'test_loss': [0.0011410074053332209,\n",
       "    0.0009318927019834519,\n",
       "    0.0007897546626627445,\n",
       "    0.0006864875334315002,\n",
       "    0.0006107631545513868,\n",
       "    0.0005557418564334512,\n",
       "    0.0005234041783958673,\n",
       "    0.0005018554676324129,\n",
       "    0.0004838641447480768,\n",
       "    0.0004696676548104733,\n",
       "    0.0004600882772356272,\n",
       "    0.0004517785446718335,\n",
       "    0.0004447057600133121,\n",
       "    0.00044052760531194506,\n",
       "    0.0004384375527966768,\n",
       "    0.0004339491837192327,\n",
       "    0.0004323727910872549,\n",
       "    0.0004298753866460174,\n",
       "    0.00042842190880328416,\n",
       "    0.00042760031633079054,\n",
       "    0.00042653760612010956,\n",
       "    0.0004262187878601253,\n",
       "    0.0004253182499203831,\n",
       "    0.00042502834568731486,\n",
       "    0.00042461093212477864,\n",
       "    0.000424224813003093,\n",
       "    0.0004240102728363126,\n",
       "    0.00042380359321832656,\n",
       "    0.0004236779384315014,\n",
       "    0.00042357025500386954,\n",
       "    0.0004234688857104629,\n",
       "    0.00042339939074590804,\n",
       "    0.0004233289372175932,\n",
       "    0.0004232755096629262,\n",
       "    0.0004232418548781425,\n",
       "    0.0004232101937290281,\n",
       "    0.0004231886716093868,\n",
       "    0.0004231668916065246,\n",
       "    0.00042315592649392784,\n",
       "    0.0004231388356070966],\n",
       "   'test_acc': [0.919,\n",
       "    0.934,\n",
       "    0.9419,\n",
       "    0.9482,\n",
       "    0.9548,\n",
       "    0.9594,\n",
       "    0.9612,\n",
       "    0.9635,\n",
       "    0.9662,\n",
       "    0.9663,\n",
       "    0.9672,\n",
       "    0.9671,\n",
       "    0.9677,\n",
       "    0.968,\n",
       "    0.968,\n",
       "    0.9685,\n",
       "    0.969,\n",
       "    0.9687,\n",
       "    0.9687,\n",
       "    0.9692,\n",
       "    0.9692,\n",
       "    0.9691,\n",
       "    0.9691,\n",
       "    0.9694,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9694,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695,\n",
       "    0.9695]},\n",
       "  'train_time': 66.72944474220276},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 32, 32, 10],\n",
       "  'num_params': (211456, 211456),\n",
       "  'train_result': {'train_loss': [0.7556824034198801,\n",
       "    0.2965848240446537,\n",
       "    0.2535310653295923,\n",
       "    0.22779489562232444,\n",
       "    0.20788935058294458,\n",
       "    0.19402323622018733,\n",
       "    0.18334009495187312,\n",
       "    0.17452953847798897,\n",
       "    0.16788280568224317,\n",
       "    0.16336316022467107,\n",
       "    0.15925829898803792,\n",
       "    0.15603823912270526,\n",
       "    0.15365859954915148,\n",
       "    0.15190948888342432,\n",
       "    0.15049377213767234,\n",
       "    0.1490755074835838,\n",
       "    0.1481813056037781,\n",
       "    0.14795321628768393,\n",
       "    0.14698105885627422,\n",
       "    0.1462986951495739,\n",
       "    0.1459570384406029,\n",
       "    0.14567546968130354,\n",
       "    0.1455340014493212,\n",
       "    0.14504551126601847,\n",
       "    0.14489047145272824,\n",
       "    0.14503465180701397,\n",
       "    0.1447573704288361,\n",
       "    0.1447692221466531,\n",
       "    0.14490537364432152,\n",
       "    0.1446213944478238,\n",
       "    0.14451924004453293,\n",
       "    0.1446194683617734,\n",
       "    0.1445624517316514,\n",
       "    0.14455686972496357,\n",
       "    0.14435527476858587,\n",
       "    0.1442589223701903,\n",
       "    0.14451435436593726,\n",
       "    0.14461046932859623,\n",
       "    0.144395406940516,\n",
       "    0.1444029006869235],\n",
       "   'test_loss': [0.0013165421225130559,\n",
       "    0.0010396493384614586,\n",
       "    0.0009290078749880195,\n",
       "    0.0008894332356750965,\n",
       "    0.0008208436977118254,\n",
       "    0.0007736368618905544,\n",
       "    0.0007428348830901087,\n",
       "    0.0007208660453557968,\n",
       "    0.0007052782818675041,\n",
       "    0.0006893850245513022,\n",
       "    0.0006770397549495101,\n",
       "    0.0006692492244765163,\n",
       "    0.0006674131805077195,\n",
       "    0.0006605597794055939,\n",
       "    0.0006573874088004231,\n",
       "    0.0006543226009234786,\n",
       "    0.0006504135627299547,\n",
       "    0.000650047324411571,\n",
       "    0.0006473554039373994,\n",
       "    0.0006464213560335338,\n",
       "    0.0006457673018798232,\n",
       "    0.0006452585956081748,\n",
       "    0.0006446058860048652,\n",
       "    0.000644135903660208,\n",
       "    0.0006438436230644584,\n",
       "    0.0006434379572048784,\n",
       "    0.0006432511430233717,\n",
       "    0.0006430728903971612,\n",
       "    0.0006428971732035279,\n",
       "    0.0006428039643913508,\n",
       "    0.0006427128313109279,\n",
       "    0.0006426209343597293,\n",
       "    0.0006425747964531183,\n",
       "    0.0006424948591738939,\n",
       "    0.0006424758929759264,\n",
       "    0.0006424341917969286,\n",
       "    0.0006424135589972139,\n",
       "    0.0006423877071589231,\n",
       "    0.0006423745942302048,\n",
       "    0.0006423578310757876],\n",
       "   'test_acc': [0.9032,\n",
       "    0.9234,\n",
       "    0.9302,\n",
       "    0.9353,\n",
       "    0.9392,\n",
       "    0.9417,\n",
       "    0.9453,\n",
       "    0.9473,\n",
       "    0.9462,\n",
       "    0.9494,\n",
       "    0.9502,\n",
       "    0.9509,\n",
       "    0.9506,\n",
       "    0.9516,\n",
       "    0.9517,\n",
       "    0.9523,\n",
       "    0.9519,\n",
       "    0.9524,\n",
       "    0.9521,\n",
       "    0.9521,\n",
       "    0.9521,\n",
       "    0.9525,\n",
       "    0.9519,\n",
       "    0.9522,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.9518,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952,\n",
       "    0.952]},\n",
       "  'train_time': 83.45880961418152},\n",
       " {'model_type': 'kan',\n",
       "  'width': [784, 64, 64, 10],\n",
       "  'num_params': (439296, 439296),\n",
       "  'train_result': {'train_loss': [0.6158656756294535,\n",
       "    0.2527236602407821,\n",
       "    0.20100212680532578,\n",
       "    0.16870417331761503,\n",
       "    0.14710499327233498,\n",
       "    0.1308635430133089,\n",
       "    0.11986743162604088,\n",
       "    0.11199581207747156,\n",
       "    0.10536923465576578,\n",
       "    0.10072917197930052,\n",
       "    0.0971746768089051,\n",
       "    0.0941681278037264,\n",
       "    0.0918333722872937,\n",
       "    0.08978233529215163,\n",
       "    0.08863604715529909,\n",
       "    0.08741605118551153,\n",
       "    0.08658387026888259,\n",
       "    0.08571481130858685,\n",
       "    0.08519727828654837,\n",
       "    0.08462203170390839,\n",
       "    0.08431500274133175,\n",
       "    0.08377590785793801,\n",
       "    0.0838556651739364,\n",
       "    0.0834071629462724,\n",
       "    0.08323890191126378,\n",
       "    0.08311768553834012,\n",
       "    0.08337820628856091,\n",
       "    0.08334643631539446,\n",
       "    0.08293448092138514,\n",
       "    0.08278455628042525,\n",
       "    0.08275023792335327,\n",
       "    0.08291706970714509,\n",
       "    0.08275220511441535,\n",
       "    0.08274722337088686,\n",
       "    0.08262548514027544,\n",
       "    0.08270800486207008,\n",
       "    0.08271404447707724,\n",
       "    0.08268415458658908,\n",
       "    0.08261301720396001,\n",
       "    0.08271167075380366],\n",
       "   'test_loss': [0.0011008431224152446,\n",
       "    0.0008812286823987961,\n",
       "    0.0007530434422194957,\n",
       "    0.000672101261653006,\n",
       "    0.0005763312069699168,\n",
       "    0.0005463342621922493,\n",
       "    0.0005216342497617007,\n",
       "    0.0004972391004674137,\n",
       "    0.0004885459820739925,\n",
       "    0.00046709206448867916,\n",
       "    0.0004626264754682779,\n",
       "    0.00045627505024895074,\n",
       "    0.00044876282289624215,\n",
       "    0.0004496176777407527,\n",
       "    0.0004422866961918771,\n",
       "    0.00044001685809344054,\n",
       "    0.0004399499203078449,\n",
       "    0.000438625209685415,\n",
       "    0.0004360236038453877,\n",
       "    0.0004370309947989881,\n",
       "    0.0004351736611686647,\n",
       "    0.00043451679199934005,\n",
       "    0.0004341835896484554,\n",
       "    0.0004341188018210232,\n",
       "    0.0004337292187847197,\n",
       "    0.0004334227935411036,\n",
       "    0.0004332767034880817,\n",
       "    0.0004331540188752115,\n",
       "    0.00043311833441257475,\n",
       "    0.00043296219622716305,\n",
       "    0.00043293835408985613,\n",
       "    0.0004328314774669707,\n",
       "    0.00043280483242124317,\n",
       "    0.0004327611283399165,\n",
       "    0.00043274865532293914,\n",
       "    0.0004327110799960792,\n",
       "    0.00043271627062931657,\n",
       "    0.00043269271515309813,\n",
       "    0.00043268222818151116,\n",
       "    0.0004326699383556843],\n",
       "   'test_acc': [0.9168,\n",
       "    0.9353,\n",
       "    0.9411,\n",
       "    0.9496,\n",
       "    0.9561,\n",
       "    0.9579,\n",
       "    0.9596,\n",
       "    0.9617,\n",
       "    0.963,\n",
       "    0.9629,\n",
       "    0.9641,\n",
       "    0.9647,\n",
       "    0.9653,\n",
       "    0.964,\n",
       "    0.9661,\n",
       "    0.966,\n",
       "    0.9657,\n",
       "    0.9662,\n",
       "    0.9655,\n",
       "    0.9662,\n",
       "    0.9655,\n",
       "    0.9662,\n",
       "    0.9663,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9663,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9661,\n",
       "    0.9661,\n",
       "    0.9661,\n",
       "    0.9662,\n",
       "    0.9661,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9662,\n",
       "    0.9662]},\n",
       "  'train_time': 80.53492832183838},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 0,\n",
       "  'num_params': (55244, 55244),\n",
       "  'train_result': {'train_loss': [0.5599605475968503,\n",
       "    0.25719756350872364,\n",
       "    0.22033859009438372,\n",
       "    0.19962446429628006,\n",
       "    0.18445332662222233,\n",
       "    0.17405961996063274,\n",
       "    0.1658968616356241,\n",
       "    0.1597226432663329,\n",
       "    0.1548427477161935,\n",
       "    0.15080507727379494,\n",
       "    0.1477562999313182,\n",
       "    0.1456983299648508,\n",
       "    0.14386405507300762,\n",
       "    0.14232883320209827,\n",
       "    0.1410304953760289,\n",
       "    0.14015177537469153,\n",
       "    0.13925807539452897,\n",
       "    0.13902251787008124,\n",
       "    0.13833351864459667,\n",
       "    0.13793781047805825,\n",
       "    0.13740497000039892,\n",
       "    0.1370938127186704,\n",
       "    0.13716685889249153,\n",
       "    0.1370111698482899,\n",
       "    0.13720901526035145,\n",
       "    0.13661329242143225,\n",
       "    0.1367431845119659,\n",
       "    0.13638841658830642,\n",
       "    0.13662904328171244,\n",
       "    0.13669939637184142,\n",
       "    0.13711128555079724,\n",
       "    0.13635898167465596,\n",
       "    0.13678906360205184,\n",
       "    0.13636700853388362,\n",
       "    0.13637561634817022,\n",
       "    0.13636079681046465,\n",
       "    0.13642427464748952,\n",
       "    0.13638500270057233,\n",
       "    0.1365204335844263,\n",
       "    0.13620640656098407],\n",
       "   'test_loss': [0.0011307331372052431,\n",
       "    0.0008934666423127055,\n",
       "    0.000807668192870915,\n",
       "    0.000752306149713695,\n",
       "    0.000732016865722835,\n",
       "    0.0006786838550120592,\n",
       "    0.0006670244307257235,\n",
       "    0.0006483908104710281,\n",
       "    0.0006279686415567995,\n",
       "    0.000624063771776855,\n",
       "    0.0006130603284575045,\n",
       "    0.0006061889314092696,\n",
       "    0.00060147315999493,\n",
       "    0.0005973444699309766,\n",
       "    0.0005953133910894394,\n",
       "    0.0005925881147384644,\n",
       "    0.0005898681525141001,\n",
       "    0.0005903378793969751,\n",
       "    0.0005882036816328764,\n",
       "    0.0005865375459194183,\n",
       "    0.0005860645739361644,\n",
       "    0.0005852589627727866,\n",
       "    0.0005849385391920805,\n",
       "    0.0005848206466995179,\n",
       "    0.0005844649083912373,\n",
       "    0.0005840601078234613,\n",
       "    0.0005838375775143504,\n",
       "    0.000583711343165487,\n",
       "    0.0005834917409345508,\n",
       "    0.0005833611340261995,\n",
       "    0.000583285737875849,\n",
       "    0.0005832895208150149,\n",
       "    0.000583243463281542,\n",
       "    0.0005832219021394848,\n",
       "    0.0005831790808588267,\n",
       "    0.0005831759566441179,\n",
       "    0.0005831437135115266,\n",
       "    0.0005831214166246354,\n",
       "    0.0005831128029152751,\n",
       "    0.0005831013392657041],\n",
       "   'test_acc': [0.9169,\n",
       "    0.934,\n",
       "    0.9399,\n",
       "    0.9439,\n",
       "    0.9457,\n",
       "    0.9488,\n",
       "    0.9507,\n",
       "    0.9521,\n",
       "    0.9535,\n",
       "    0.9536,\n",
       "    0.9541,\n",
       "    0.956,\n",
       "    0.9564,\n",
       "    0.9563,\n",
       "    0.9565,\n",
       "    0.9562,\n",
       "    0.9572,\n",
       "    0.957,\n",
       "    0.9571,\n",
       "    0.9572,\n",
       "    0.9573,\n",
       "    0.9575,\n",
       "    0.9572,\n",
       "    0.9572,\n",
       "    0.9573,\n",
       "    0.9574,\n",
       "    0.9575,\n",
       "    0.9573,\n",
       "    0.9575,\n",
       "    0.9576,\n",
       "    0.9575,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574,\n",
       "    0.9574]},\n",
       "  'train_time': 598.6782262325287},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 1,\n",
       "  'num_params': (41614, 41614),\n",
       "  'train_result': {'train_loss': [0.5943440715049175,\n",
       "    0.11590255259516391,\n",
       "    0.08863026888129559,\n",
       "    0.07708694556767637,\n",
       "    0.07067967197520936,\n",
       "    0.0665752064436674,\n",
       "    0.06314968609825727,\n",
       "    0.06044085445476973,\n",
       "    0.058983062564375556,\n",
       "    0.057418770683889696,\n",
       "    0.05650593605922892,\n",
       "    0.05561068633848682,\n",
       "    0.05495182075240511,\n",
       "    0.05423688100690537,\n",
       "    0.05382374665759345,\n",
       "    0.05339231108057689,\n",
       "    0.05311776879540783,\n",
       "    0.052922375397162234,\n",
       "    0.05296173086588053,\n",
       "    0.052589067662174395,\n",
       "    0.05267059825994867,\n",
       "    0.05239072849855144,\n",
       "    0.052280501248513134,\n",
       "    0.05227488165206098,\n",
       "    0.05238615848678858,\n",
       "    0.052314216877393266,\n",
       "    0.05226451028138399,\n",
       "    0.0520803898691814,\n",
       "    0.05209125182492302,\n",
       "    0.05204671402560904,\n",
       "    0.05213110821440499,\n",
       "    0.05208234579322186,\n",
       "    0.052056081319584495,\n",
       "    0.051998083348921004,\n",
       "    0.05209159981063072,\n",
       "    0.05227905353729395,\n",
       "    0.051995617008589685,\n",
       "    0.05200503884240034,\n",
       "    0.052025226788951995,\n",
       "    0.05196959616101168],\n",
       "   'test_loss': [0.0005277296701446175,\n",
       "    0.000353643698617816,\n",
       "    0.0003106449025683105,\n",
       "    0.0002893035253509879,\n",
       "    0.00027323653085622936,\n",
       "    0.00025772583150537686,\n",
       "    0.00025360475324559957,\n",
       "    0.00025128421388799326,\n",
       "    0.00024135128642665223,\n",
       "    0.00024025050448253752,\n",
       "    0.00023944677729159593,\n",
       "    0.00023563436807598918,\n",
       "    0.00023769350971560924,\n",
       "    0.0002356975232134573,\n",
       "    0.000237716962385457,\n",
       "    0.00023446869482286276,\n",
       "    0.00023680727941682563,\n",
       "    0.00023439186199102551,\n",
       "    0.00023481414085254072,\n",
       "    0.00023411959708901124,\n",
       "    0.00023439077178481966,\n",
       "    0.00023408060832880439,\n",
       "    0.00023377762336749584,\n",
       "    0.0002338236794108525,\n",
       "    0.00023372223528567702,\n",
       "    0.00023353105906862766,\n",
       "    0.00023343038890743628,\n",
       "    0.00023335651956731454,\n",
       "    0.00023331345533952118,\n",
       "    0.00023329059870447964,\n",
       "    0.0002332802234799601,\n",
       "    0.00023325625073630362,\n",
       "    0.00023326379962963984,\n",
       "    0.00023324052367825062,\n",
       "    0.0002332536696223542,\n",
       "    0.000233245983091183,\n",
       "    0.00023324804597068578,\n",
       "    0.0002332446302520111,\n",
       "    0.0002332384779350832,\n",
       "    0.0002332351818215102],\n",
       "   'test_acc': [0.9601,\n",
       "    0.9722,\n",
       "    0.975,\n",
       "    0.9768,\n",
       "    0.9783,\n",
       "    0.9796,\n",
       "    0.9798,\n",
       "    0.9798,\n",
       "    0.981,\n",
       "    0.981,\n",
       "    0.981,\n",
       "    0.9816,\n",
       "    0.9806,\n",
       "    0.9805,\n",
       "    0.9809,\n",
       "    0.9809,\n",
       "    0.9814,\n",
       "    0.9806,\n",
       "    0.9809,\n",
       "    0.9808,\n",
       "    0.9808,\n",
       "    0.9806,\n",
       "    0.9805,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9805,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806,\n",
       "    0.9806]},\n",
       "  'train_time': 2008.5516653060913},\n",
       " {'model_type': 'convkan',\n",
       "  'width': 2,\n",
       "  'num_params': (94650, 94650),\n",
       "  'train_result': {'train_loss': [0.7403000272968983,\n",
       "    0.14796801832445125,\n",
       "    0.10267445124844288,\n",
       "    0.0834165216205602,\n",
       "    0.07251822718597473,\n",
       "    0.06504649248846034,\n",
       "    0.06016537648566226,\n",
       "    0.05663607620653954,\n",
       "    0.05387857504030492,\n",
       "    0.05182926486781303,\n",
       "    0.05013842998032874,\n",
       "    0.048937596745313484,\n",
       "    0.04800363140220338,\n",
       "    0.047224548122191685,\n",
       "    0.04675342848405559,\n",
       "    0.046386538148718945,\n",
       "    0.04579702283632248,\n",
       "    0.04547330951912606,\n",
       "    0.04514472966498517,\n",
       "    0.044990580663719075,\n",
       "    0.04493298035194265,\n",
       "    0.0448203906733939,\n",
       "    0.044753013305524565,\n",
       "    0.04450601447135844,\n",
       "    0.044578994818507356,\n",
       "    0.04450042088456611,\n",
       "    0.04435155329076534,\n",
       "    0.04435454454827816,\n",
       "    0.04433629733530131,\n",
       "    0.04422666694017801,\n",
       "    0.04425113122672477,\n",
       "    0.04429787775461978,\n",
       "    0.0442422082845835,\n",
       "    0.0442639143463779,\n",
       "    0.04433950792126199,\n",
       "    0.044195369258522986,\n",
       "    0.044159793231557026,\n",
       "    0.04415975305390485,\n",
       "    0.04432749519164258,\n",
       "    0.0442397922515235],\n",
       "   'test_loss': [0.0007097016947343946,\n",
       "    0.0004294530462473631,\n",
       "    0.00034047109950333836,\n",
       "    0.0002919833909720182,\n",
       "    0.0002673472494352609,\n",
       "    0.0002529488577274606,\n",
       "    0.00024314233295153826,\n",
       "    0.0002334796884097159,\n",
       "    0.0002262318659340963,\n",
       "    0.0002212390712928027,\n",
       "    0.00021942797717638314,\n",
       "    0.00021599171473644674,\n",
       "    0.0002141065699979663,\n",
       "    0.00021323042488656939,\n",
       "    0.00021127870965283364,\n",
       "    0.0002102581858402118,\n",
       "    0.00021018293041270226,\n",
       "    0.0002096247738460079,\n",
       "    0.00020897721794899552,\n",
       "    0.00020864223106764257,\n",
       "    0.00020829424292314797,\n",
       "    0.00020809679729864001,\n",
       "    0.00020781894116662442,\n",
       "    0.00020771694851573556,\n",
       "    0.00020751689278986304,\n",
       "    0.00020740789300762117,\n",
       "    0.00020737365246750413,\n",
       "    0.00020732263452373446,\n",
       "    0.00020725967448670418,\n",
       "    0.0002072275529615581,\n",
       "    0.00020720388651825487,\n",
       "    0.0002071732756216079,\n",
       "    0.00020714947218075395,\n",
       "    0.00020713652863632887,\n",
       "    0.00020712039228528738,\n",
       "    0.0002071120610460639,\n",
       "    0.00020710329639259725,\n",
       "    0.00020709678786806762,\n",
       "    0.00020709226115141064,\n",
       "    0.0002070874388795346],\n",
       "   'test_acc': [0.9529,\n",
       "    0.9702,\n",
       "    0.976,\n",
       "    0.9793,\n",
       "    0.9802,\n",
       "    0.9811,\n",
       "    0.9813,\n",
       "    0.9817,\n",
       "    0.9819,\n",
       "    0.9825,\n",
       "    0.9823,\n",
       "    0.9826,\n",
       "    0.9826,\n",
       "    0.9832,\n",
       "    0.983,\n",
       "    0.983,\n",
       "    0.9827,\n",
       "    0.9828,\n",
       "    0.983,\n",
       "    0.9829,\n",
       "    0.983,\n",
       "    0.9831,\n",
       "    0.983,\n",
       "    0.9829,\n",
       "    0.983,\n",
       "    0.9831,\n",
       "    0.983,\n",
       "    0.983,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831,\n",
       "    0.9831]},\n",
       "  'train_time': 2053.6402065753937},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 10],\n",
       "  'num_params': (7850, 7850),\n",
       "  'train_result': {'train_loss': [0.8421233098557654,\n",
       "    0.43164569456526575,\n",
       "    0.3735034915995091,\n",
       "    0.34753382370827046,\n",
       "    0.3322669876382706,\n",
       "    0.3231097666507072,\n",
       "    0.3167748229934814,\n",
       "    0.3113870587120665,\n",
       "    0.30847526852120744,\n",
       "    0.30562906125758554,\n",
       "    0.3036374304522859,\n",
       "    0.3021210862601057,\n",
       "    0.3005546380230721,\n",
       "    0.2996534983528421,\n",
       "    0.29896516508244453,\n",
       "    0.2983517363984534,\n",
       "    0.29763220808607466,\n",
       "    0.29714723007476074,\n",
       "    0.2970864619346375,\n",
       "    0.2969102990120015,\n",
       "    0.296647716392862,\n",
       "    0.2965875584394374,\n",
       "    0.29650661653660715,\n",
       "    0.296120741139067,\n",
       "    0.2958370672261461,\n",
       "    0.2961247168956919,\n",
       "    0.29580025343184774,\n",
       "    0.295836466867873,\n",
       "    0.2956689256302854,\n",
       "    0.2961679888532517,\n",
       "    0.2959250708843799,\n",
       "    0.29582208591572784,\n",
       "    0.29593658003401246,\n",
       "    0.29571718700388644,\n",
       "    0.2958541863142176,\n",
       "    0.2962983564493504,\n",
       "    0.29597844107353943,\n",
       "    0.2960702631701814,\n",
       "    0.2962788075208664,\n",
       "    0.2958624288122705],\n",
       "   'test_loss': [0.0018444594889879228,\n",
       "    0.0014823284432291986,\n",
       "    0.0013561929013580084,\n",
       "    0.0012860677804797888,\n",
       "    0.0012478830493986607,\n",
       "    0.0012188544645905495,\n",
       "    0.0012038084264844656,\n",
       "    0.001190579241886735,\n",
       "    0.0011813796970993281,\n",
       "    0.0011719305008649826,\n",
       "    0.0011669291526079178,\n",
       "    0.0011617844849824905,\n",
       "    0.0011588134728372098,\n",
       "    0.0011554408702999354,\n",
       "    0.0011540497165173293,\n",
       "    0.0011524097185581922,\n",
       "    0.001151200159266591,\n",
       "    0.0011499544359743596,\n",
       "    0.0011488938491791487,\n",
       "    0.0011482482593506574,\n",
       "    0.0011477563258260489,\n",
       "    0.0011473862731829286,\n",
       "    0.0011470440220087766,\n",
       "    0.0011467600557953119,\n",
       "    0.0011465213391929866,\n",
       "    0.001146381671540439,\n",
       "    0.0011462614722549916,\n",
       "    0.001146146972477436,\n",
       "    0.001146053303219378,\n",
       "    0.0011459912599995732,\n",
       "    0.001145934869721532,\n",
       "    0.0011458860907703637,\n",
       "    0.0011458495417609811,\n",
       "    0.0011458216443657875,\n",
       "    0.0011457986298948526,\n",
       "    0.0011457791920751333,\n",
       "    0.0011457632340490817,\n",
       "    0.0011457511907443404,\n",
       "    0.0011457421040162443,\n",
       "    0.0011457341857254505],\n",
       "   'test_acc': [0.8912,\n",
       "    0.904,\n",
       "    0.9093,\n",
       "    0.9124,\n",
       "    0.9134,\n",
       "    0.9156,\n",
       "    0.916,\n",
       "    0.9161,\n",
       "    0.9168,\n",
       "    0.9176,\n",
       "    0.9179,\n",
       "    0.9183,\n",
       "    0.9184,\n",
       "    0.9185,\n",
       "    0.919,\n",
       "    0.9193,\n",
       "    0.9193,\n",
       "    0.9195,\n",
       "    0.9193,\n",
       "    0.9191,\n",
       "    0.919,\n",
       "    0.9191,\n",
       "    0.9191,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919,\n",
       "    0.919]},\n",
       "  'train_time': 39.381596326828},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 16, 10],\n",
       "  'num_params': (12730, 12730),\n",
       "  'train_result': {'train_loss': [0.8789459891775822,\n",
       "    0.36498465284388115,\n",
       "    0.31592185066101397,\n",
       "    0.29516538825440913,\n",
       "    0.28342863841259736,\n",
       "    0.27581929323521065,\n",
       "    0.2694196808845439,\n",
       "    0.2643759769962189,\n",
       "    0.2605442749693039,\n",
       "    0.2579758027766613,\n",
       "    0.2556999044849517,\n",
       "    0.2537795446654584,\n",
       "    0.2525756925978559,\n",
       "    0.2513143549574182,\n",
       "    0.2503216323066265,\n",
       "    0.2497390072396461,\n",
       "    0.24928524430761945,\n",
       "    0.24892115003251014,\n",
       "    0.24840450800479727,\n",
       "    0.2481750470843721,\n",
       "    0.24796842311290984,\n",
       "    0.24767429219915513,\n",
       "    0.24750405226616148,\n",
       "    0.24747368496783237,\n",
       "    0.24721565569968934,\n",
       "    0.24751232069857576,\n",
       "    0.24735454818669786,\n",
       "    0.24711232090249974,\n",
       "    0.24742408401154456,\n",
       "    0.247034704621802,\n",
       "    0.24693601727485656,\n",
       "    0.2468593288609322,\n",
       "    0.24692327487975993,\n",
       "    0.2468727301409904,\n",
       "    0.24709222817674598,\n",
       "    0.24696364041338575,\n",
       "    0.24726975731393125,\n",
       "    0.24704733218284364,\n",
       "    0.24700382415284503,\n",
       "    0.24696207902532943],\n",
       "   'test_loss': [0.001589086962491274,\n",
       "    0.0012742166731506586,\n",
       "    0.001161720685660839,\n",
       "    0.001119700638949871,\n",
       "    0.001085430377535522,\n",
       "    0.0010631550073623658,\n",
       "    0.0010551598951220513,\n",
       "    0.0010381219500675797,\n",
       "    0.0010291381001472472,\n",
       "    0.0010200810860842467,\n",
       "    0.0010138799551874399,\n",
       "    0.0010067721104249359,\n",
       "    0.0010033688824623824,\n",
       "    0.0009993617670610547,\n",
       "    0.0009979057291522621,\n",
       "    0.0009956040818244218,\n",
       "    0.00099427740406245,\n",
       "    0.0009928829062730074,\n",
       "    0.0009922245319932698,\n",
       "    0.0009912416487932204,\n",
       "    0.0009905988553538918,\n",
       "    0.0009900192245841026,\n",
       "    0.000989580923691392,\n",
       "    0.00098927848264575,\n",
       "    0.000989073983579874,\n",
       "    0.0009888721223920583,\n",
       "    0.0009886996133252979,\n",
       "    0.0009885717315599321,\n",
       "    0.0009884478958323598,\n",
       "    0.0009883910410106182,\n",
       "    0.0009883227054029702,\n",
       "    0.0009882691200822592,\n",
       "    0.0009882161607965827,\n",
       "    0.0009881824972108007,\n",
       "    0.0009881565352901816,\n",
       "    0.000988132430240512,\n",
       "    0.000988117489218712,\n",
       "    0.000988104828633368,\n",
       "    0.0009880921613425017,\n",
       "    0.0009880837863311173],\n",
       "   'test_acc': [0.8959,\n",
       "    0.9121,\n",
       "    0.9176,\n",
       "    0.9204,\n",
       "    0.9225,\n",
       "    0.9239,\n",
       "    0.9251,\n",
       "    0.9256,\n",
       "    0.9253,\n",
       "    0.9272,\n",
       "    0.9268,\n",
       "    0.9275,\n",
       "    0.9276,\n",
       "    0.9277,\n",
       "    0.9283,\n",
       "    0.9282,\n",
       "    0.9286,\n",
       "    0.9279,\n",
       "    0.9285,\n",
       "    0.9283,\n",
       "    0.9283,\n",
       "    0.9281,\n",
       "    0.9283,\n",
       "    0.9283,\n",
       "    0.9283,\n",
       "    0.9284,\n",
       "    0.9285,\n",
       "    0.9285,\n",
       "    0.9285,\n",
       "    0.9286,\n",
       "    0.9285,\n",
       "    0.9285,\n",
       "    0.9286,\n",
       "    0.9286,\n",
       "    0.9285,\n",
       "    0.9286,\n",
       "    0.9286,\n",
       "    0.9286,\n",
       "    0.9286,\n",
       "    0.9286]},\n",
       "  'train_time': 43.26330351829529},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 32, 10],\n",
       "  'num_params': (25450, 25450),\n",
       "  'train_result': {'train_loss': [0.726551506176908,\n",
       "    0.31351808969010697,\n",
       "    0.2722810532184357,\n",
       "    0.25029636640497976,\n",
       "    0.23614803172172383,\n",
       "    0.22618839093979368,\n",
       "    0.2187351091745052,\n",
       "    0.21278233794455834,\n",
       "    0.20812948225660527,\n",
       "    0.20496630113809666,\n",
       "    0.20238762012821562,\n",
       "    0.1997249072853555,\n",
       "    0.19795445932986888,\n",
       "    0.19704981474800312,\n",
       "    0.19571689560692362,\n",
       "    0.19486298748153322,\n",
       "    0.19445813082634134,\n",
       "    0.19333983884846911,\n",
       "    0.19308148143773382,\n",
       "    0.19283395761505087,\n",
       "    0.19239438467837394,\n",
       "    0.19222077064691706,\n",
       "    0.19194031747731757,\n",
       "    0.19188638462665233,\n",
       "    0.19179727137088776,\n",
       "    0.19167055623962523,\n",
       "    0.19175868554318204,\n",
       "    0.19145271822493126,\n",
       "    0.19187902522848008,\n",
       "    0.1913099705855897,\n",
       "    0.19145877484945542,\n",
       "    0.1913634348422923,\n",
       "    0.19162292350479898,\n",
       "    0.19120390155213945,\n",
       "    0.1915672317147255,\n",
       "    0.19142819474986258,\n",
       "    0.19135993484486924,\n",
       "    0.19145455566492486,\n",
       "    0.19153289265455084,\n",
       "    0.1911658010584243],\n",
       "   'test_loss': [0.0013234941650182009,\n",
       "    0.0010921995870769024,\n",
       "    0.0009957342293113471,\n",
       "    0.0009420905603095889,\n",
       "    0.0008971053157001734,\n",
       "    0.0008706094508990646,\n",
       "    0.0008496781388297678,\n",
       "    0.0008336354468017817,\n",
       "    0.0008232666678726673,\n",
       "    0.0008111170187592506,\n",
       "    0.0008028101652860642,\n",
       "    0.0007965236317366361,\n",
       "    0.0007947069564834237,\n",
       "    0.0007895580047741533,\n",
       "    0.000786879925429821,\n",
       "    0.0007844950726255775,\n",
       "    0.0007823527924716473,\n",
       "    0.0007801450258120894,\n",
       "    0.0007798349890857935,\n",
       "    0.0007784819573163986,\n",
       "    0.0007773760992102325,\n",
       "    0.0007769344437867403,\n",
       "    0.000776519863307476,\n",
       "    0.0007761058945208788,\n",
       "    0.0007758785434067249,\n",
       "    0.0007755690822377801,\n",
       "    0.0007754209967330098,\n",
       "    0.0007752783604897559,\n",
       "    0.0007751300109550357,\n",
       "    0.0007750467894598841,\n",
       "    0.0007749599002301693,\n",
       "    0.0007748853862285614,\n",
       "    0.0007748490750789642,\n",
       "    0.000774805493094027,\n",
       "    0.0007747677953913808,\n",
       "    0.0007747416321188212,\n",
       "    0.0007747207315638661,\n",
       "    0.0007747028328478336,\n",
       "    0.0007746935034170746,\n",
       "    0.0007746806973591446],\n",
       "   'test_acc': [0.9101,\n",
       "    0.9228,\n",
       "    0.9279,\n",
       "    0.9307,\n",
       "    0.9354,\n",
       "    0.9363,\n",
       "    0.937,\n",
       "    0.9383,\n",
       "    0.9391,\n",
       "    0.9399,\n",
       "    0.9402,\n",
       "    0.9399,\n",
       "    0.9406,\n",
       "    0.9411,\n",
       "    0.9417,\n",
       "    0.9421,\n",
       "    0.9423,\n",
       "    0.9426,\n",
       "    0.9422,\n",
       "    0.9425,\n",
       "    0.9423,\n",
       "    0.9426,\n",
       "    0.9425,\n",
       "    0.9425,\n",
       "    0.9425,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9425,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426,\n",
       "    0.9426]},\n",
       "  'train_time': 43.281919717788696},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 64, 10],\n",
       "  'num_params': (50890, 50890),\n",
       "  'train_result': {'train_loss': [0.6094306243860975,\n",
       "    0.277905846973683,\n",
       "    0.23373599502634496,\n",
       "    0.20859642945071485,\n",
       "    0.19134705662727355,\n",
       "    0.17943327011580162,\n",
       "    0.17036969861451615,\n",
       "    0.16357588863119166,\n",
       "    0.15822240179206462,\n",
       "    0.15436938768054576,\n",
       "    0.1510837489303122,\n",
       "    0.1486014498675123,\n",
       "    0.14687714747926023,\n",
       "    0.14501881719903742,\n",
       "    0.14365821672563858,\n",
       "    0.142739273084605,\n",
       "    0.14219516553777328,\n",
       "    0.14147184564078108,\n",
       "    0.1408860021766196,\n",
       "    0.14049464774892687,\n",
       "    0.14038177268936278,\n",
       "    0.14014945483588157,\n",
       "    0.1395327372912397,\n",
       "    0.13962479257520208,\n",
       "    0.13953315758324683,\n",
       "    0.13936228590442779,\n",
       "    0.13915677419368258,\n",
       "    0.1390192484602015,\n",
       "    0.13891207620184473,\n",
       "    0.139278548036484,\n",
       "    0.13901318787260258,\n",
       "    0.13897955389098918,\n",
       "    0.1389223796573091,\n",
       "    0.1392570306963109,\n",
       "    0.13882419216506026,\n",
       "    0.1388558457189418,\n",
       "    0.13880674433200918,\n",
       "    0.13893333952477638,\n",
       "    0.13883316085693684,\n",
       "    0.13876135333421383],\n",
       "   'test_loss': [0.0011935922887176275,\n",
       "    0.0009676068868488074,\n",
       "    0.0008659257028251886,\n",
       "    0.000785649582836777,\n",
       "    0.0007433451252058149,\n",
       "    0.0007070395061746239,\n",
       "    0.0006832174160517752,\n",
       "    0.00066541221216321,\n",
       "    0.0006481749402359128,\n",
       "    0.0006388840515166521,\n",
       "    0.0006316648121923209,\n",
       "    0.0006266877536661923,\n",
       "    0.0006186827464029192,\n",
       "    0.0006154011264443397,\n",
       "    0.0006130698122084141,\n",
       "    0.0006101096024736762,\n",
       "    0.0006078507198020816,\n",
       "    0.0006062351233325899,\n",
       "    0.0006048483747988939,\n",
       "    0.0006040865110233427,\n",
       "    0.0006034826558083295,\n",
       "    0.0006026974987238645,\n",
       "    0.0006021513579413295,\n",
       "    0.0006017497569322586,\n",
       "    0.0006014504320919514,\n",
       "    0.0006011802289634943,\n",
       "    0.0006009642888791859,\n",
       "    0.0006008014127612114,\n",
       "    0.0006006796825677157,\n",
       "    0.0006005945968441665,\n",
       "    0.0006004912467673421,\n",
       "    0.0006004000860266388,\n",
       "    0.0006003550872206688,\n",
       "    0.0006003067458048463,\n",
       "    0.0006002679513767362,\n",
       "    0.0006002421515062451,\n",
       "    0.0006002223597839475,\n",
       "    0.0006002053757198155,\n",
       "    0.0006001900983974338,\n",
       "    0.0006001809692010283],\n",
       "   'test_acc': [0.9155,\n",
       "    0.9302,\n",
       "    0.9387,\n",
       "    0.9412,\n",
       "    0.9445,\n",
       "    0.9471,\n",
       "    0.9493,\n",
       "    0.9497,\n",
       "    0.9514,\n",
       "    0.9529,\n",
       "    0.9528,\n",
       "    0.9528,\n",
       "    0.9543,\n",
       "    0.9539,\n",
       "    0.954,\n",
       "    0.9542,\n",
       "    0.9545,\n",
       "    0.9546,\n",
       "    0.9547,\n",
       "    0.955,\n",
       "    0.9553,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552,\n",
       "    0.9552]},\n",
       "  'train_time': 44.23043966293335},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 128, 10],\n",
       "  'num_params': (101770, 101770),\n",
       "  'train_result': {'train_loss': [0.5137571618912068,\n",
       "    0.24173175223330234,\n",
       "    0.19599985616638305,\n",
       "    0.16901987806913701,\n",
       "    0.1501159313828387,\n",
       "    0.137270805905474,\n",
       "    0.12767565713283863,\n",
       "    0.12073257330884325,\n",
       "    0.11531800813180335,\n",
       "    0.11133784995751178,\n",
       "    0.10827180648103674,\n",
       "    0.10557442388318955,\n",
       "    0.10354871897304312,\n",
       "    0.10178485966109214,\n",
       "    0.10076532544607812,\n",
       "    0.09967145843708769,\n",
       "    0.09883954712051027,\n",
       "    0.09821422028731792,\n",
       "    0.09771135135533962,\n",
       "    0.09745831405545803,\n",
       "    0.0970281019489816,\n",
       "    0.09707480529521374,\n",
       "    0.0965284887067181,\n",
       "    0.09626265366343742,\n",
       "    0.0964125891632222,\n",
       "    0.09610266461968422,\n",
       "    0.09597263310817962,\n",
       "    0.09620440542063814,\n",
       "    0.09602495755286927,\n",
       "    0.09600324223333216,\n",
       "    0.0958056666432543,\n",
       "    0.09586749073672803,\n",
       "    0.09577800362034047,\n",
       "    0.09577683208787695,\n",
       "    0.09595629046572016,\n",
       "    0.09582329829956623,\n",
       "    0.09565254532276316,\n",
       "    0.09562488096825619,\n",
       "    0.09557000389124484,\n",
       "    0.09558489151457522],\n",
       "   'test_loss': [0.0010436856120824814,\n",
       "    0.0008341949738562108,\n",
       "    0.0007088249845430255,\n",
       "    0.0006526407073251903,\n",
       "    0.0005958909019827843,\n",
       "    0.0005545905052684247,\n",
       "    0.0005302887450903655,\n",
       "    0.0005098295940086246,\n",
       "    0.000496144973486662,\n",
       "    0.0004871658236719668,\n",
       "    0.00047714344151318075,\n",
       "    0.00047124344324693085,\n",
       "    0.00046655592499300836,\n",
       "    0.00046173490136861803,\n",
       "    0.00045961223505437373,\n",
       "    0.0004572752863168716,\n",
       "    0.00045469295755028725,\n",
       "    0.0004536409441381693,\n",
       "    0.0004526093543507159,\n",
       "    0.00045153596298769114,\n",
       "    0.00045084535451605915,\n",
       "    0.00045014339135959747,\n",
       "    0.0004498253744095564,\n",
       "    0.00044948254581540824,\n",
       "    0.0004491792713291943,\n",
       "    0.00044896652679890395,\n",
       "    0.00044877372570335865,\n",
       "    0.0004485981627367437,\n",
       "    0.00044848620546981694,\n",
       "    0.00044837487926706674,\n",
       "    0.00044830429144203664,\n",
       "    0.0004482424802146852,\n",
       "    0.0004481874453835189,\n",
       "    0.00044815041413530707,\n",
       "    0.0004481136747635901,\n",
       "    0.00044808077458292244,\n",
       "    0.00044805951630696653,\n",
       "    0.00044804352689534427,\n",
       "    0.0004480319583788514,\n",
       "    0.0004480187532491982],\n",
       "   'test_acc': [0.9259,\n",
       "    0.9376,\n",
       "    0.9482,\n",
       "    0.9528,\n",
       "    0.9568,\n",
       "    0.9588,\n",
       "    0.9607,\n",
       "    0.962,\n",
       "    0.9631,\n",
       "    0.9638,\n",
       "    0.9646,\n",
       "    0.9639,\n",
       "    0.964,\n",
       "    0.9648,\n",
       "    0.9649,\n",
       "    0.9656,\n",
       "    0.9655,\n",
       "    0.9653,\n",
       "    0.9654,\n",
       "    0.9658,\n",
       "    0.9658,\n",
       "    0.9659,\n",
       "    0.9659,\n",
       "    0.966,\n",
       "    0.9658,\n",
       "    0.9661,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966,\n",
       "    0.966]},\n",
       "  'train_time': 44.35863900184631},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 256, 10],\n",
       "  'num_params': (203530, 203530),\n",
       "  'train_result': {'train_loss': [0.4443603238526811,\n",
       "    0.2027256484044359,\n",
       "    0.15415699741941818,\n",
       "    0.1268907660182486,\n",
       "    0.1095111219648351,\n",
       "    0.098463783001012,\n",
       "    0.08958653243298226,\n",
       "    0.08325844689252529,\n",
       "    0.07870384361198608,\n",
       "    0.07468723997949285,\n",
       "    0.07224909879584261,\n",
       "    0.06970081711386113,\n",
       "    0.06804184663168927,\n",
       "    0.06668528872443007,\n",
       "    0.06560284771976319,\n",
       "    0.06488839660553222,\n",
       "    0.06394804014645993,\n",
       "    0.06360398332806344,\n",
       "    0.0629626251123053,\n",
       "    0.06282032930312005,\n",
       "    0.06235845245103887,\n",
       "    0.062208653653555726,\n",
       "    0.06190202945565924,\n",
       "    0.06182734508939246,\n",
       "    0.06165873708718635,\n",
       "    0.06158259533187176,\n",
       "    0.06148173949344361,\n",
       "    0.06144108993417405,\n",
       "    0.06148229386419692,\n",
       "    0.06144080651884384,\n",
       "    0.06128598729029615,\n",
       "    0.06133020726290155,\n",
       "    0.061332672652094924,\n",
       "    0.06126089469390981,\n",
       "    0.061155685964733995,\n",
       "    0.06124822477552485,\n",
       "    0.06125205565006175,\n",
       "    0.06118603006322333,\n",
       "    0.061127656928085264,\n",
       "    0.06118309400341612],\n",
       "   'test_loss': [0.0009286495316773653,\n",
       "    0.0006779891902580857,\n",
       "    0.0005663499169051647,\n",
       "    0.00048359360499307516,\n",
       "    0.00044771061427891255,\n",
       "    0.000418290644697845,\n",
       "    0.00040192862637341024,\n",
       "    0.00038608165765181184,\n",
       "    0.0003771669124718755,\n",
       "    0.00036952321929857135,\n",
       "    0.00036235346351750193,\n",
       "    0.0003578224199824035,\n",
       "    0.00035099714011885226,\n",
       "    0.00034894025633111595,\n",
       "    0.0003486010468099266,\n",
       "    0.0003470581199042499,\n",
       "    0.00034459228930063543,\n",
       "    0.00034303135401569305,\n",
       "    0.00034276511161588133,\n",
       "    0.00034213426816277206,\n",
       "    0.00034202099964022634,\n",
       "    0.00034179563564248384,\n",
       "    0.0003413561077788472,\n",
       "    0.0003409973938018084,\n",
       "    0.00034081694087944925,\n",
       "    0.0003405094129499048,\n",
       "    0.00034057501275092366,\n",
       "    0.0003404162021353841,\n",
       "    0.0003403217928484082,\n",
       "    0.0003402854152489454,\n",
       "    0.0003401939912699163,\n",
       "    0.0003401409754529595,\n",
       "    0.0003401024059858173,\n",
       "    0.00034005927750840783,\n",
       "    0.0003400479592382908,\n",
       "    0.00034002967667765916,\n",
       "    0.0003400204024743289,\n",
       "    0.0003400018431711942,\n",
       "    0.0003400015217717737,\n",
       "    0.00033999060494825244],\n",
       "   'test_acc': [0.9328,\n",
       "    0.9509,\n",
       "    0.958,\n",
       "    0.9648,\n",
       "    0.9662,\n",
       "    0.9692,\n",
       "    0.9699,\n",
       "    0.9716,\n",
       "    0.9719,\n",
       "    0.9727,\n",
       "    0.9733,\n",
       "    0.9733,\n",
       "    0.9746,\n",
       "    0.974,\n",
       "    0.9745,\n",
       "    0.9739,\n",
       "    0.9746,\n",
       "    0.9744,\n",
       "    0.9746,\n",
       "    0.9744,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9742,\n",
       "    0.9743,\n",
       "    0.9742,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9742,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9742,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743,\n",
       "    0.9743]},\n",
       "  'train_time': 44.43997931480408},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 32, 32, 10],\n",
       "  'num_params': (26506, 26506),\n",
       "  'train_result': {'train_loss': [0.8140240723782397,\n",
       "    0.30984747067410895,\n",
       "    0.2676093171885673,\n",
       "    0.2428495040599336,\n",
       "    0.22479975299632296,\n",
       "    0.21250598950588956,\n",
       "    0.20232713504674588,\n",
       "    0.1952532761908592,\n",
       "    0.19021187808285367,\n",
       "    0.18589062066154277,\n",
       "    0.18243021435560064,\n",
       "    0.17991021304054464,\n",
       "    0.17800751097024756,\n",
       "    0.17598002036201194,\n",
       "    0.17489151307877074,\n",
       "    0.17391873715405767,\n",
       "    0.172996730753716,\n",
       "    0.1724244306696222,\n",
       "    0.17200187317868496,\n",
       "    0.1715877967311981,\n",
       "    0.171435875746798,\n",
       "    0.17103433723145342,\n",
       "    0.17068125374139623,\n",
       "    0.17026528693894122,\n",
       "    0.17048440302940124,\n",
       "    0.17039201776397989,\n",
       "    0.17022165637067024,\n",
       "    0.17006225665198996,\n",
       "    0.16971202170912256,\n",
       "    0.17031820102574977,\n",
       "    0.17000617717808866,\n",
       "    0.16973036223269525,\n",
       "    0.1699130637214539,\n",
       "    0.16970304453626592,\n",
       "    0.1697719492493792,\n",
       "    0.16965758949518203,\n",
       "    0.16967699708456688,\n",
       "    0.16981222867331605,\n",
       "    0.1696370337554749,\n",
       "    0.16984517162150525],\n",
       "   'test_loss': [0.0013118120901286603,\n",
       "    0.001088771971128881,\n",
       "    0.001002867691591382,\n",
       "    0.0009188214268535375,\n",
       "    0.0008602401994168759,\n",
       "    0.0008231068151071668,\n",
       "    0.0007915439572185278,\n",
       "    0.0007748110763728618,\n",
       "    0.0007611111348494888,\n",
       "    0.0007388989981263876,\n",
       "    0.0007291016848757863,\n",
       "    0.0007260928807780147,\n",
       "    0.0007186400037258863,\n",
       "    0.0007131480593234301,\n",
       "    0.0007112855605781078,\n",
       "    0.0007072681544348598,\n",
       "    0.0007072539852932096,\n",
       "    0.0007045427408069372,\n",
       "    0.0007032547239214182,\n",
       "    0.0007018068756908178,\n",
       "    0.0007009403396397829,\n",
       "    0.0007002495419234037,\n",
       "    0.0006995337335392833,\n",
       "    0.0006993461981415749,\n",
       "    0.0006990797108039259,\n",
       "    0.0006987386722117662,\n",
       "    0.0006985237259417772,\n",
       "    0.000698359939455986,\n",
       "    0.000698243385180831,\n",
       "    0.0006981417573988437,\n",
       "    0.0006980622567236424,\n",
       "    0.0006979664001613855,\n",
       "    0.0006979317344725132,\n",
       "    0.0006978632057085633,\n",
       "    0.0006978193202987314,\n",
       "    0.0006978084169328212,\n",
       "    0.000697790677472949,\n",
       "    0.0006977694580331445,\n",
       "    0.0006977441266179085,\n",
       "    0.0006977310713380575],\n",
       "   'test_acc': [0.9089,\n",
       "    0.9218,\n",
       "    0.9293,\n",
       "    0.9344,\n",
       "    0.9383,\n",
       "    0.9398,\n",
       "    0.9415,\n",
       "    0.9424,\n",
       "    0.9423,\n",
       "    0.9447,\n",
       "    0.946,\n",
       "    0.945,\n",
       "    0.9451,\n",
       "    0.9467,\n",
       "    0.9463,\n",
       "    0.9468,\n",
       "    0.9463,\n",
       "    0.9469,\n",
       "    0.9466,\n",
       "    0.9468,\n",
       "    0.947,\n",
       "    0.9474,\n",
       "    0.9473,\n",
       "    0.9476,\n",
       "    0.9475,\n",
       "    0.9479,\n",
       "    0.9479,\n",
       "    0.948,\n",
       "    0.9479,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948,\n",
       "    0.948]},\n",
       "  'train_time': 44.26502466201782},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 64, 64, 10],\n",
       "  'num_params': (55050, 55050),\n",
       "  'train_result': {'train_loss': [0.6219851138743948,\n",
       "    0.24205672861413752,\n",
       "    0.19539903532317343,\n",
       "    0.16741974284040168,\n",
       "    0.15055414796509642,\n",
       "    0.13868537518255253,\n",
       "    0.13050387152966034,\n",
       "    0.1249712532505076,\n",
       "    0.1198969489082377,\n",
       "    0.11596462060796453,\n",
       "    0.11306764006297639,\n",
       "    0.11101084597250249,\n",
       "    0.10931863115823015,\n",
       "    0.10776189701988342,\n",
       "    0.10660281874080922,\n",
       "    0.10572389137554676,\n",
       "    0.10521700172982318,\n",
       "    0.1048064762449011,\n",
       "    0.10413854741986761,\n",
       "    0.1037102942612577,\n",
       "    0.10359554606232237,\n",
       "    0.1032530058571633,\n",
       "    0.10310184221635474,\n",
       "    0.10286590144672292,\n",
       "    0.10283981916752268,\n",
       "    0.10264293551445007,\n",
       "    0.10278112626773246,\n",
       "    0.10254556048423685,\n",
       "    0.102487600277713,\n",
       "    0.10250631076224306,\n",
       "    0.10240589729014864,\n",
       "    0.10229586971567033,\n",
       "    0.10225419349809911,\n",
       "    0.1022641086356437,\n",
       "    0.10249722271840624,\n",
       "    0.10236101486581436,\n",
       "    0.10234637189101665,\n",
       "    0.10253462547317464,\n",
       "    0.10223912392207916,\n",
       "    0.10239579856712767],\n",
       "   'test_loss': [0.0010378196908161043,\n",
       "    0.0008410836789757014,\n",
       "    0.0007003724282607436,\n",
       "    0.0006270647210069001,\n",
       "    0.0005870073666796088,\n",
       "    0.0005584732440300286,\n",
       "    0.0005504248498007656,\n",
       "    0.000513604983035475,\n",
       "    0.0005110591720789671,\n",
       "    0.0004985798420384526,\n",
       "    0.000492872722633183,\n",
       "    0.0004881788358092308,\n",
       "    0.0004866623280569911,\n",
       "    0.000482573945261538,\n",
       "    0.0004812547592446208,\n",
       "    0.0004777273539453745,\n",
       "    0.0004762731533497572,\n",
       "    0.0004744122326374054,\n",
       "    0.0004734026134945452,\n",
       "    0.0004731390363536775,\n",
       "    0.0004725210289470851,\n",
       "    0.00047204405227676036,\n",
       "    0.00047189065255224703,\n",
       "    0.00047144974153488876,\n",
       "    0.0004713254947215319,\n",
       "    0.0004711527902632952,\n",
       "    0.0004709820905700326,\n",
       "    0.00047085934234783054,\n",
       "    0.00047079385071992875,\n",
       "    0.0004707089160569012,\n",
       "    0.0004706495698541403,\n",
       "    0.0004705893318168819,\n",
       "    0.0004705535501241684,\n",
       "    0.0004705320439301431,\n",
       "    0.00047051032688468695,\n",
       "    0.00047049914710223673,\n",
       "    0.0004704792518168688,\n",
       "    0.0004704653136432171,\n",
       "    0.000470459252409637,\n",
       "    0.0004704523177817464],\n",
       "   'test_acc': [0.9249,\n",
       "    0.9383,\n",
       "    0.9478,\n",
       "    0.9521,\n",
       "    0.9551,\n",
       "    0.9568,\n",
       "    0.9576,\n",
       "    0.9608,\n",
       "    0.96,\n",
       "    0.9614,\n",
       "    0.9622,\n",
       "    0.9625,\n",
       "    0.962,\n",
       "    0.9625,\n",
       "    0.9629,\n",
       "    0.9627,\n",
       "    0.9632,\n",
       "    0.9628,\n",
       "    0.9632,\n",
       "    0.9631,\n",
       "    0.9637,\n",
       "    0.9633,\n",
       "    0.9635,\n",
       "    0.9634,\n",
       "    0.9637,\n",
       "    0.9633,\n",
       "    0.9633,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634,\n",
       "    0.9634]},\n",
       "  'train_time': 46.36068105697632},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 128, 128, 10],\n",
       "  'num_params': (118282, 118282),\n",
       "  'train_result': {'train_loss': [0.5097103386483294,\n",
       "    0.210533988127049,\n",
       "    0.16135534333421828,\n",
       "    0.13259302918264207,\n",
       "    0.115359798200587,\n",
       "    0.10222160817777858,\n",
       "    0.09305567383132082,\n",
       "    0.08595686340902714,\n",
       "    0.0808669980060547,\n",
       "    0.07673119610135859,\n",
       "    0.07368003935255903,\n",
       "    0.07129380511952207,\n",
       "    0.06926936653858803,\n",
       "    0.06762915964614838,\n",
       "    0.06650867840235537,\n",
       "    0.0655306485263591,\n",
       "    0.06458302998637899,\n",
       "    0.06398633122444153,\n",
       "    0.06340536220752178,\n",
       "    0.06322258410460137,\n",
       "    0.06286172559286686,\n",
       "    0.06261502293513176,\n",
       "    0.06225304798559939,\n",
       "    0.06208271404054571,\n",
       "    0.06196268930080089,\n",
       "    0.06193531101688426,\n",
       "    0.06174859497299854,\n",
       "    0.06170580782630342,\n",
       "    0.06160762255337644,\n",
       "    0.06155939427937599,\n",
       "    0.06167783095164502,\n",
       "    0.06146751012890897,\n",
       "    0.061455731482264846,\n",
       "    0.061476510168707116,\n",
       "    0.06145946831303708,\n",
       "    0.06149566653878131,\n",
       "    0.061470144234122115,\n",
       "    0.06159940348502169,\n",
       "    0.061564801546170354,\n",
       "    0.061387929510562975],\n",
       "   'test_loss': [0.0009399417947977782,\n",
       "    0.0006934020197950304,\n",
       "    0.000575208926666528,\n",
       "    0.0005118763700127602,\n",
       "    0.000467221137881279,\n",
       "    0.00044210995454341175,\n",
       "    0.000423709844565019,\n",
       "    0.00041284842467866837,\n",
       "    0.0003923945566173643,\n",
       "    0.0003858537830412388,\n",
       "    0.0003755806386936456,\n",
       "    0.00037334244740195574,\n",
       "    0.00037136982604861257,\n",
       "    0.0003685687078628689,\n",
       "    0.0003673439762555063,\n",
       "    0.0003625794489867985,\n",
       "    0.0003609938555629924,\n",
       "    0.00036107689207419755,\n",
       "    0.00035848348224535583,\n",
       "    0.0003587961190612987,\n",
       "    0.00035882803723216055,\n",
       "    0.00035847407695837317,\n",
       "    0.00035803578626364467,\n",
       "    0.00035750462892465294,\n",
       "    0.0003574433457106352,\n",
       "    0.0003572259970009327,\n",
       "    0.00035720061482861636,\n",
       "    0.0003571320900460705,\n",
       "    0.0003569532610476017,\n",
       "    0.0003568903096718714,\n",
       "    0.00035685222407337276,\n",
       "    0.0003568165346747264,\n",
       "    0.00035678185392171147,\n",
       "    0.0003567977556725964,\n",
       "    0.0003567511624423787,\n",
       "    0.0003567589295096695,\n",
       "    0.0003567413612501696,\n",
       "    0.000356725729489699,\n",
       "    0.00035671970760449764,\n",
       "    0.0003567049806471914],\n",
       "   'test_acc': [0.932,\n",
       "    0.9496,\n",
       "    0.957,\n",
       "    0.9621,\n",
       "    0.965,\n",
       "    0.9667,\n",
       "    0.9684,\n",
       "    0.9685,\n",
       "    0.9699,\n",
       "    0.9704,\n",
       "    0.9705,\n",
       "    0.9714,\n",
       "    0.971,\n",
       "    0.9714,\n",
       "    0.9713,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9712,\n",
       "    0.9712,\n",
       "    0.9716,\n",
       "    0.9715,\n",
       "    0.9715,\n",
       "    0.9716,\n",
       "    0.9715,\n",
       "    0.9716,\n",
       "    0.9715,\n",
       "    0.9716,\n",
       "    0.9716,\n",
       "    0.9716,\n",
       "    0.9716,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717,\n",
       "    0.9717]},\n",
       "  'train_time': 43.14708209037781},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 256, 256, 10],\n",
       "  'num_params': (269322, 269322),\n",
       "  'train_result': {'train_loss': [0.4128167858783235,\n",
       "    0.1604234034869265,\n",
       "    0.10828403332766066,\n",
       "    0.08294666866038708,\n",
       "    0.06720193537308815,\n",
       "    0.05620088841211288,\n",
       "    0.04796433623563102,\n",
       "    0.04211901075583189,\n",
       "    0.03773476091074817,\n",
       "    0.03467568407588183,\n",
       "    0.03206229659312583,\n",
       "    0.029805898864535576,\n",
       "    0.02817513808172117,\n",
       "    0.02706140052091251,\n",
       "    0.026067293163864535,\n",
       "    0.02504254110910474,\n",
       "    0.024625735054228534,\n",
       "    0.02393018303320129,\n",
       "    0.023560765625393772,\n",
       "    0.023180740073006204,\n",
       "    0.02308016270002786,\n",
       "    0.02274077575693422,\n",
       "    0.02257216793108494,\n",
       "    0.022427085315451976,\n",
       "    0.022311172786941554,\n",
       "    0.022226652921118,\n",
       "    0.022152221908277654,\n",
       "    0.022037124637752138,\n",
       "    0.02197364504112208,\n",
       "    0.02200109329906867,\n",
       "    0.02197152144929513,\n",
       "    0.021900318854270462,\n",
       "    0.021935383515789154,\n",
       "    0.021892068580664854,\n",
       "    0.021863878837370492,\n",
       "    0.021838172996773365,\n",
       "    0.021824739265077293,\n",
       "    0.021882411629516395,\n",
       "    0.021894927098950807,\n",
       "    0.021830951626551277],\n",
       "   'test_loss': [0.0007593620942905545,\n",
       "    0.0005067871244624257,\n",
       "    0.00043635685900226233,\n",
       "    0.0003453847515396774,\n",
       "    0.0003329514040146023,\n",
       "    0.00030203744414029644,\n",
       "    0.00028297442523762584,\n",
       "    0.0002785358828259632,\n",
       "    0.0002761839391198009,\n",
       "    0.00027739060448657253,\n",
       "    0.00026652374128461817,\n",
       "    0.000273183943744516,\n",
       "    0.00026044468554900957,\n",
       "    0.00026131188693689184,\n",
       "    0.00026052273479872383,\n",
       "    0.0002603287101490423,\n",
       "    0.0002595948187576141,\n",
       "    0.00026180711154593153,\n",
       "    0.0002607826172985369,\n",
       "    0.0002599537329049781,\n",
       "    0.00026059469667379743,\n",
       "    0.00026080190882785245,\n",
       "    0.00026033187718712723,\n",
       "    0.0002602748825447634,\n",
       "    0.00025991604330192786,\n",
       "    0.00026009831182309426,\n",
       "    0.00026015943159000016,\n",
       "    0.0002600524061708711,\n",
       "    0.00026023971003014595,\n",
       "    0.0002600678076240001,\n",
       "    0.0002600952670938568,\n",
       "    0.00026003071632876525,\n",
       "    0.0002600067343038973,\n",
       "    0.0002600421029928839,\n",
       "    0.0002600482367124641,\n",
       "    0.00026003624742734245,\n",
       "    0.00026002942930790596,\n",
       "    0.0002600435070169624,\n",
       "    0.0002600274451833684,\n",
       "    0.00026003217068791855],\n",
       "   'test_acc': [0.9418,\n",
       "    0.9633,\n",
       "    0.9673,\n",
       "    0.9734,\n",
       "    0.9734,\n",
       "    0.9759,\n",
       "    0.977,\n",
       "    0.9779,\n",
       "    0.9775,\n",
       "    0.9773,\n",
       "    0.9787,\n",
       "    0.9793,\n",
       "    0.9797,\n",
       "    0.979,\n",
       "    0.9799,\n",
       "    0.9796,\n",
       "    0.9795,\n",
       "    0.979,\n",
       "    0.9789,\n",
       "    0.9792,\n",
       "    0.9791,\n",
       "    0.9787,\n",
       "    0.9789,\n",
       "    0.9788,\n",
       "    0.979,\n",
       "    0.9789,\n",
       "    0.9792,\n",
       "    0.9793,\n",
       "    0.979,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791,\n",
       "    0.9791]},\n",
       "  'train_time': 46.928699254989624},\n",
       " {'model_type': 'mlp',\n",
       "  'width': [784, 512, 512, 10],\n",
       "  'num_params': (669706, 669706),\n",
       "  'train_result': {'train_loss': [0.3424259320535558,\n",
       "    0.11780025336019537,\n",
       "    0.07681834284770996,\n",
       "    0.05440692087595767,\n",
       "    0.039707658748994484,\n",
       "    0.03046918338204318,\n",
       "    0.023542936288930002,\n",
       "    0.01874123230140577,\n",
       "    0.015446209245698249,\n",
       "    0.013148839323920138,\n",
       "    0.011476976945599977,\n",
       "    0.010082893446087838,\n",
       "    0.009138198008641917,\n",
       "    0.008362587302566525,\n",
       "    0.00784974507046269,\n",
       "    0.007414221768564684,\n",
       "    0.006976054519652686,\n",
       "    0.006724687548790206,\n",
       "    0.0064644748047786825,\n",
       "    0.0062994661656743355,\n",
       "    0.006174261455840253,\n",
       "    0.005986533820272443,\n",
       "    0.005913549786473208,\n",
       "    0.005809197208764863,\n",
       "    0.005737054551099526,\n",
       "    0.005678256766058188,\n",
       "    0.0056259114255613465,\n",
       "    0.005579871092328524,\n",
       "    0.005554488862547627,\n",
       "    0.005549932419857446,\n",
       "    0.005505423536623253,\n",
       "    0.005489633003982934,\n",
       "    0.005489350603695245,\n",
       "    0.005461947606539631,\n",
       "    0.005452760319879397,\n",
       "    0.0054521710572249076,\n",
       "    0.005441892148054977,\n",
       "    0.0054399631298246215,\n",
       "    0.005441373468257804,\n",
       "    0.005434291158862253],\n",
       "   'test_loss': [0.0006113463019020855,\n",
       "    0.0003707384685520083,\n",
       "    0.00032293656931724397,\n",
       "    0.0002738031351065729,\n",
       "    0.0002845728025306016,\n",
       "    0.00027291823890409435,\n",
       "    0.00024290649739268702,\n",
       "    0.00024036664603263488,\n",
       "    0.00024002449262479787,\n",
       "    0.0002432945750595536,\n",
       "    0.00023792806332930923,\n",
       "    0.00023943923881888623,\n",
       "    0.00024204380476585357,\n",
       "    0.00024151852260692976,\n",
       "    0.00024394261283596278,\n",
       "    0.00024408380645909346,\n",
       "    0.00024421210511063694,\n",
       "    0.00024459661677101396,\n",
       "    0.00024346627922495828,\n",
       "    0.0002448192469702917,\n",
       "    0.0002445225811636192,\n",
       "    0.00024490415785621735,\n",
       "    0.0002447461190815375,\n",
       "    0.0002458418763926602,\n",
       "    0.00024572860260450396,\n",
       "    0.0002458804920577677,\n",
       "    0.0002459579413385654,\n",
       "    0.0002462524734895851,\n",
       "    0.00024646866386683543,\n",
       "    0.00024646587277457003,\n",
       "    0.0002465739285296877,\n",
       "    0.00024661350596215923,\n",
       "    0.00024660271074099,\n",
       "    0.0002465790746929997,\n",
       "    0.0002466184430522844,\n",
       "    0.00024663924471606154,\n",
       "    0.0002466587509676174,\n",
       "    0.0002466781841583725,\n",
       "    0.00024667750890585013,\n",
       "    0.0002466914867887681],\n",
       "   'test_acc': [0.9535,\n",
       "    0.9691,\n",
       "    0.974,\n",
       "    0.9772,\n",
       "    0.9772,\n",
       "    0.9783,\n",
       "    0.9811,\n",
       "    0.9807,\n",
       "    0.9814,\n",
       "    0.9813,\n",
       "    0.981,\n",
       "    0.9812,\n",
       "    0.9811,\n",
       "    0.9812,\n",
       "    0.9814,\n",
       "    0.9814,\n",
       "    0.9813,\n",
       "    0.9818,\n",
       "    0.9817,\n",
       "    0.9817,\n",
       "    0.9818,\n",
       "    0.9815,\n",
       "    0.9816,\n",
       "    0.9817,\n",
       "    0.9818,\n",
       "    0.9816,\n",
       "    0.9817,\n",
       "    0.9817,\n",
       "    0.9817,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818,\n",
       "    0.9818]},\n",
       "  'train_time': 43.43510174751282}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f7b08de-fbc2-442a-a948-620cd2023cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save results to file\n",
    "f = open('test_results_MNIST_2.pickle', 'wb')\n",
    "pickle.dump(results, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bf36a-3f62-43b8-958f-0a4d8aede913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a17310-d554-4137-8dbf-063cc0a4eced",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan_venv_2",
   "language": "python",
   "name": "pykan_venv_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
